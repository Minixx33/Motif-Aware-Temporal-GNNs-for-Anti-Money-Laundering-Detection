
================================================================================
Logging started at: 2025-12-01 00:18:03.712114
Log file: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans\seed2025_experiment_3\graphsage-t\seed2025_experiment_3_20251201_001803.txt
================================================================================

[INFO] Logging to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans\seed2025_experiment_3\graphsage-t\seed2025_experiment_3_20251201_001803.txt
================================================================================
EXPERIMENT CONFIG SUMMARY
================================================================================

[DATASET]
  Name:       HI-Small_Trans
  Theory:     baseline
  Intensity:  None

[MODEL]
  GraphSAGE-T
  Hidden dim: 128

[PATHS]
  Graphs:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs\HI-Small_Trans
  Splits:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits\HI-Small_Trans
  Results:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans\seed2025_experiment_3\graphsage-t
  Logs:       C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans\seed2025_experiment_3\graphsage-t
================================================================================

[DEVICE] cuda


======= GRAPHSAGE-T TRAINING (FP32) =======
Batch size:       8192
Eval batch size:  16384
Device:           cuda
===========================================


Starting training for 350 epochs...

Epoch 001 | train_loss=12.3522 val_loss=0.4167 P=0.053 R=0.022 F1=0.031 ROC-AUC=0.543 AUPR=0.003 time=52.00s
Epoch 002 | train_loss=0.5014 val_loss=0.3747 P=0.002 R=0.712 F1=0.004 ROC-AUC=0.675 AUPR=0.002 time=55.65s
Epoch 003 | train_loss=0.4237 val_loss=0.3444 P=0.002 R=0.736 F1=0.004 ROC-AUC=0.692 AUPR=0.002 time=50.06s
Epoch 004 | train_loss=0.3938 val_loss=0.3190 P=0.026 R=0.181 F1=0.045 ROC-AUC=0.805 AUPR=0.011 time=51.84s
Epoch 005 | train_loss=0.3646 val_loss=0.2953 P=0.035 R=0.120 F1=0.054 ROC-AUC=0.818 AUPR=0.013 time=51.05s
Epoch 006 | train_loss=0.3299 val_loss=0.2818 P=0.045 R=0.088 F1=0.059 ROC-AUC=0.813 AUPR=0.015 time=51.75s
Epoch 007 | train_loss=0.3363 val_loss=0.2810 P=0.047 R=0.105 F1=0.065 ROC-AUC=0.805 AUPR=0.019 time=53.00s
Epoch 008 | train_loss=0.2986 val_loss=0.2625 P=0.060 R=0.082 F1=0.070 ROC-AUC=0.832 AUPR=0.021 time=50.42s
Epoch 009 | train_loss=0.3223 val_loss=0.2513 P=0.077 R=0.145 F1=0.101 ROC-AUC=0.852 AUPR=0.034 time=49.91s
Epoch 010 | train_loss=0.2276 val_loss=0.1681 P=0.085 R=0.225 F1=0.124 ROC-AUC=0.925 AUPR=0.059 time=49.95s
Epoch 011 | train_loss=0.1932 val_loss=0.1384 P=0.177 R=0.222 F1=0.197 ROC-AUC=0.969 AUPR=0.113 time=53.44s
Epoch 012 | train_loss=0.2073 val_loss=0.1290 P=0.206 R=0.227 F1=0.216 ROC-AUC=0.973 AUPR=0.136 time=68.76s
Epoch 013 | train_loss=0.1690 val_loss=0.1234 P=0.214 R=0.251 F1=0.231 ROC-AUC=0.976 AUPR=0.147 time=67.05s
Epoch 014 | train_loss=0.1517 val_loss=0.1197 P=0.240 R=0.236 F1=0.238 ROC-AUC=0.976 AUPR=0.154 time=69.00s
Epoch 015 | train_loss=0.1757 val_loss=0.1269 P=0.283 R=0.217 F1=0.246 ROC-AUC=0.975 AUPR=0.159 time=61.96s
Epoch 016 | train_loss=0.1598 val_loss=0.1160 P=0.292 R=0.235 F1=0.260 ROC-AUC=0.977 AUPR=0.169 time=50.26s
Epoch 017 | train_loss=0.1534 val_loss=0.1752 P=0.235 R=0.220 F1=0.227 ROC-AUC=0.939 AUPR=0.138 time=52.28s
Epoch 018 | train_loss=0.1477 val_loss=0.1135 P=0.274 R=0.253 F1=0.263 ROC-AUC=0.978 AUPR=0.173 time=49.96s
Epoch 019 | train_loss=0.1440 val_loss=0.1124 P=0.293 R=0.233 F1=0.259 ROC-AUC=0.978 AUPR=0.175 time=49.96s
Epoch 020 | train_loss=0.1600 val_loss=0.1140 P=0.259 R=0.277 F1=0.268 ROC-AUC=0.978 AUPR=0.184 time=49.76s
Epoch 021 | train_loss=0.1543 val_loss=0.1119 P=0.313 R=0.249 F1=0.278 ROC-AUC=0.979 AUPR=0.190 time=49.94s
Epoch 022 | train_loss=0.1329 val_loss=0.1114 P=0.269 R=0.264 F1=0.267 ROC-AUC=0.978 AUPR=0.185 time=49.84s
Epoch 023 | train_loss=0.1896 val_loss=0.1298 P=0.316 R=0.232 F1=0.267 ROC-AUC=0.963 AUPR=0.179 time=50.27s
Epoch 024 | train_loss=0.1799 val_loss=0.1138 P=0.298 R=0.251 F1=0.273 ROC-AUC=0.977 AUPR=0.183 time=49.96s
Epoch 025 | train_loss=0.1583 val_loss=0.1204 P=0.277 R=0.264 F1=0.270 ROC-AUC=0.971 AUPR=0.175 time=50.19s
Epoch 026 | train_loss=0.1462 val_loss=0.1202 P=0.270 R=0.285 F1=0.277 ROC-AUC=0.973 AUPR=0.188 time=49.86s
Epoch 027 | train_loss=0.1741 val_loss=0.1195 P=0.286 R=0.254 F1=0.269 ROC-AUC=0.974 AUPR=0.183 time=50.54s
Epoch 028 | train_loss=0.2227 val_loss=0.1184 P=0.293 R=0.243 F1=0.266 ROC-AUC=0.973 AUPR=0.177 time=50.79s
Epoch 029 | train_loss=0.1668 val_loss=0.1173 P=0.298 R=0.249 F1=0.271 ROC-AUC=0.974 AUPR=0.182 time=50.98s
Epoch 030 | train_loss=0.1568 val_loss=0.1168 P=0.285 R=0.264 F1=0.274 ROC-AUC=0.974 AUPR=0.190 time=51.48s
Epoch 031 | train_loss=0.1424 val_loss=0.1162 P=0.317 R=0.246 F1=0.277 ROC-AUC=0.975 AUPR=0.195 time=51.29s
Epoch 032 | train_loss=0.1353 val_loss=0.1163 P=0.265 R=0.277 F1=0.271 ROC-AUC=0.975 AUPR=0.192 time=51.15s
Epoch 033 | train_loss=0.1506 val_loss=0.1153 P=0.314 R=0.242 F1=0.274 ROC-AUC=0.975 AUPR=0.192 time=51.25s
Epoch 034 | train_loss=0.1370 val_loss=0.1154 P=0.313 R=0.241 F1=0.273 ROC-AUC=0.975 AUPR=0.197 time=51.35s
Epoch 035 | train_loss=0.1610 val_loss=0.1153 P=0.390 R=0.199 F1=0.263 ROC-AUC=0.976 AUPR=0.189 time=49.83s
Epoch 036 | train_loss=0.1418 val_loss=0.1179 P=0.278 R=0.269 F1=0.274 ROC-AUC=0.975 AUPR=0.199 time=49.93s
Epoch 037 | train_loss=0.1393 val_loss=0.1142 P=0.335 R=0.226 F1=0.270 ROC-AUC=0.976 AUPR=0.196 time=50.25s
Epoch 038 | train_loss=0.1578 val_loss=0.1150 P=0.330 R=0.252 F1=0.286 ROC-AUC=0.976 AUPR=0.207 time=51.10s
Epoch 039 | train_loss=0.1374 val_loss=0.1134 P=0.284 R=0.265 F1=0.275 ROC-AUC=0.976 AUPR=0.197 time=50.27s
Epoch 040 | train_loss=0.1436 val_loss=0.1179 P=0.278 R=0.258 F1=0.267 ROC-AUC=0.976 AUPR=0.188 time=50.02s
Epoch 041 | train_loss=0.1494 val_loss=0.1134 P=0.340 R=0.226 F1=0.271 ROC-AUC=0.976 AUPR=0.194 time=49.89s
Epoch 042 | train_loss=0.1426 val_loss=0.1125 P=0.307 R=0.247 F1=0.274 ROC-AUC=0.977 AUPR=0.200 time=50.20s
Epoch 043 | train_loss=0.1539 val_loss=0.1127 P=0.317 R=0.248 F1=0.278 ROC-AUC=0.976 AUPR=0.202 time=49.89s
Epoch 044 | train_loss=0.1450 val_loss=0.1145 P=0.304 R=0.258 F1=0.279 ROC-AUC=0.977 AUPR=0.204 time=50.14s
Epoch 045 | train_loss=0.1403 val_loss=0.1153 P=0.288 R=0.284 F1=0.286 ROC-AUC=0.976 AUPR=0.218 time=51.68s
Epoch 046 | train_loss=0.1377 val_loss=0.1115 P=0.329 R=0.267 F1=0.295 ROC-AUC=0.977 AUPR=0.219 time=51.08s
Epoch 047 | train_loss=0.1439 val_loss=0.1117 P=0.367 R=0.245 F1=0.294 ROC-AUC=0.977 AUPR=0.219 time=50.81s
Epoch 048 | train_loss=0.1491 val_loss=0.1118 P=0.314 R=0.261 F1=0.285 ROC-AUC=0.977 AUPR=0.215 time=51.19s
Epoch 049 | train_loss=0.1290 val_loss=0.1125 P=0.337 R=0.262 F1=0.294 ROC-AUC=0.977 AUPR=0.220 time=51.72s
Epoch 050 | train_loss=0.1314 val_loss=0.1118 P=0.296 R=0.271 F1=0.283 ROC-AUC=0.977 AUPR=0.216 time=51.32s
Epoch 051 | train_loss=0.1486 val_loss=0.1120 P=0.309 R=0.239 F1=0.270 ROC-AUC=0.977 AUPR=0.204 time=50.19s
Epoch 052 | train_loss=0.1386 val_loss=0.1146 P=0.359 R=0.286 F1=0.318 ROC-AUC=0.976 AUPR=0.229 time=51.23s
Epoch 053 | train_loss=0.1421 val_loss=0.2002 P=0.332 R=0.222 F1=0.266 ROC-AUC=0.909 AUPR=0.199 time=51.18s
Epoch 054 | train_loss=0.1420 val_loss=0.1094 P=0.405 R=0.246 F1=0.306 ROC-AUC=0.979 AUPR=0.239 time=51.34s
Epoch 055 | train_loss=0.1381 val_loss=0.1074 P=0.393 R=0.257 F1=0.311 ROC-AUC=0.980 AUPR=0.243 time=51.63s
Epoch 056 | train_loss=0.1332 val_loss=0.1063 P=0.301 R=0.311 F1=0.306 ROC-AUC=0.979 AUPR=0.237 time=50.94s
Epoch 057 | train_loss=0.1557 val_loss=0.1058 P=0.308 R=0.304 F1=0.306 ROC-AUC=0.980 AUPR=0.245 time=51.15s
Epoch 058 | train_loss=0.1408 val_loss=0.1061 P=0.321 R=0.305 F1=0.313 ROC-AUC=0.980 AUPR=0.252 time=50.19s
Epoch 059 | train_loss=0.1276 val_loss=0.1050 P=0.322 R=0.276 F1=0.297 ROC-AUC=0.980 AUPR=0.242 time=50.34s
Epoch 060 | train_loss=0.1452 val_loss=0.1045 P=0.290 R=0.325 F1=0.306 ROC-AUC=0.980 AUPR=0.247 time=50.01s
Epoch 061 | train_loss=0.1504 val_loss=0.1042 P=0.425 R=0.247 F1=0.313 ROC-AUC=0.980 AUPR=0.255 time=50.09s
Epoch 062 | train_loss=0.1599 val_loss=0.1054 P=0.382 R=0.283 F1=0.325 ROC-AUC=0.980 AUPR=0.263 time=50.29s
Epoch 063 | train_loss=0.1267 val_loss=0.1053 P=0.302 R=0.299 F1=0.301 ROC-AUC=0.980 AUPR=0.245 time=49.93s
Epoch 064 | train_loss=0.1382 val_loss=0.1046 P=0.318 R=0.306 F1=0.312 ROC-AUC=0.981 AUPR=0.249 time=51.05s
Epoch 065 | train_loss=0.1573 val_loss=0.1087 P=0.395 R=0.279 F1=0.327 ROC-AUC=0.980 AUPR=0.272 time=50.95s
Epoch 066 | train_loss=0.1540 val_loss=0.1059 P=0.431 R=0.249 F1=0.316 ROC-AUC=0.981 AUPR=0.263 time=50.95s
Epoch 067 | train_loss=0.1397 val_loss=0.1064 P=0.328 R=0.301 F1=0.314 ROC-AUC=0.979 AUPR=0.253 time=51.00s
Epoch 068 | train_loss=0.1364 val_loss=0.1043 P=0.372 R=0.294 F1=0.329 ROC-AUC=0.980 AUPR=0.269 time=51.33s
Epoch 069 | train_loss=0.1594 val_loss=0.1055 P=0.393 R=0.294 F1=0.337 ROC-AUC=0.980 AUPR=0.271 time=51.06s
Epoch 070 | train_loss=0.1402 val_loss=0.1410 P=0.390 R=0.258 F1=0.310 ROC-AUC=0.957 AUPR=0.249 time=51.42s
Epoch 071 | train_loss=0.1683 val_loss=0.1029 P=0.378 R=0.284 F1=0.324 ROC-AUC=0.981 AUPR=0.269 time=51.26s
Epoch 072 | train_loss=0.1556 val_loss=0.1024 P=0.379 R=0.292 F1=0.330 ROC-AUC=0.981 AUPR=0.273 time=51.35s
Epoch 073 | train_loss=0.1651 val_loss=0.1438 P=0.341 R=0.319 F1=0.330 ROC-AUC=0.944 AUPR=0.277 time=50.34s
Epoch 074 | train_loss=0.2022 val_loss=0.1489 P=0.320 R=0.266 F1=0.291 ROC-AUC=0.937 AUPR=0.233 time=50.82s
Epoch 075 | train_loss=0.1746 val_loss=0.1031 P=0.384 R=0.292 F1=0.332 ROC-AUC=0.981 AUPR=0.277 time=51.31s
Epoch 076 | train_loss=0.1505 val_loss=0.1036 P=0.456 R=0.267 F1=0.337 ROC-AUC=0.981 AUPR=0.287 time=51.54s
Epoch 077 | train_loss=0.1694 val_loss=0.1008 P=0.391 R=0.293 F1=0.335 ROC-AUC=0.982 AUPR=0.284 time=51.42s
Epoch 078 | train_loss=0.1434 val_loss=0.1021 P=0.436 R=0.268 F1=0.332 ROC-AUC=0.982 AUPR=0.287 time=52.12s
Epoch 079 | train_loss=0.1365 val_loss=0.1004 P=0.421 R=0.302 F1=0.352 ROC-AUC=0.982 AUPR=0.297 time=50.93s
Epoch 080 | train_loss=0.1599 val_loss=0.3526 P=0.470 R=0.203 F1=0.283 ROC-AUC=0.874 AUPR=0.225 time=51.21s
Epoch 081 | train_loss=0.1328 val_loss=0.1051 P=0.459 R=0.246 F1=0.320 ROC-AUC=0.981 AUPR=0.274 time=50.89s
Epoch 082 | train_loss=0.1415 val_loss=0.0985 P=0.356 R=0.338 F1=0.347 ROC-AUC=0.983 AUPR=0.293 time=50.90s
Epoch 083 | train_loss=0.1480 val_loss=0.0986 P=0.344 R=0.349 F1=0.347 ROC-AUC=0.983 AUPR=0.296 time=50.67s
Epoch 084 | train_loss=0.1509 val_loss=0.0993 P=0.458 R=0.302 F1=0.364 ROC-AUC=0.982 AUPR=0.304 time=51.16s
Epoch 085 | train_loss=0.1400 val_loss=0.0985 P=0.374 R=0.345 F1=0.359 ROC-AUC=0.982 AUPR=0.308 time=50.72s
Epoch 086 | train_loss=0.1187 val_loss=0.1011 P=0.432 R=0.310 F1=0.361 ROC-AUC=0.982 AUPR=0.313 time=50.74s
Epoch 087 | train_loss=0.1378 val_loss=0.0978 P=0.376 R=0.337 F1=0.355 ROC-AUC=0.983 AUPR=0.309 time=50.81s
Epoch 088 | train_loss=0.1192 val_loss=0.0998 P=0.379 R=0.331 F1=0.353 ROC-AUC=0.982 AUPR=0.312 time=50.14s
Epoch 089 | train_loss=0.1335 val_loss=0.1007 P=0.396 R=0.327 F1=0.359 ROC-AUC=0.982 AUPR=0.306 time=49.86s
Epoch 090 | train_loss=0.1308 val_loss=0.0975 P=0.391 R=0.328 F1=0.357 ROC-AUC=0.983 AUPR=0.308 time=50.36s
Epoch 091 | train_loss=0.1468 val_loss=0.0988 P=0.482 R=0.271 F1=0.347 ROC-AUC=0.982 AUPR=0.304 time=49.99s
Epoch 092 | train_loss=0.1365 val_loss=0.0971 P=0.386 R=0.318 F1=0.349 ROC-AUC=0.983 AUPR=0.306 time=51.15s
Epoch 093 | train_loss=0.1289 val_loss=0.0970 P=0.450 R=0.292 F1=0.354 ROC-AUC=0.983 AUPR=0.303 time=51.30s
Epoch 094 | train_loss=0.1127 val_loss=0.0978 P=0.382 R=0.318 F1=0.347 ROC-AUC=0.982 AUPR=0.293 time=51.64s
Epoch 095 | train_loss=0.1234 val_loss=0.0988 P=0.439 R=0.311 F1=0.364 ROC-AUC=0.982 AUPR=0.309 time=50.91s
Epoch 096 | train_loss=0.1354 val_loss=0.0993 P=0.511 R=0.284 F1=0.365 ROC-AUC=0.982 AUPR=0.320 time=51.37s
Epoch 097 | train_loss=0.1157 val_loss=0.0968 P=0.446 R=0.289 F1=0.351 ROC-AUC=0.983 AUPR=0.304 time=50.98s
Epoch 098 | train_loss=0.1131 val_loss=0.0976 P=0.392 R=0.333 F1=0.360 ROC-AUC=0.983 AUPR=0.309 time=50.64s
Epoch 099 | train_loss=0.1428 val_loss=0.0971 P=0.437 R=0.317 F1=0.367 ROC-AUC=0.983 AUPR=0.315 time=51.40s
Epoch 100 | train_loss=0.1684 val_loss=0.0961 P=0.392 R=0.347 F1=0.368 ROC-AUC=0.983 AUPR=0.319 time=49.95s
Epoch 101 | train_loss=0.1269 val_loss=0.0968 P=0.418 R=0.323 F1=0.365 ROC-AUC=0.983 AUPR=0.315 time=50.19s
Epoch 102 | train_loss=0.1223 val_loss=0.0979 P=0.414 R=0.324 F1=0.364 ROC-AUC=0.982 AUPR=0.300 time=51.05s
Epoch 103 | train_loss=0.1173 val_loss=0.0964 P=0.508 R=0.273 F1=0.355 ROC-AUC=0.983 AUPR=0.319 time=50.56s
Epoch 104 | train_loss=0.1082 val_loss=0.0966 P=0.470 R=0.299 F1=0.366 ROC-AUC=0.983 AUPR=0.322 time=50.72s
Epoch 105 | train_loss=0.1384 val_loss=0.0968 P=0.369 R=0.347 F1=0.358 ROC-AUC=0.983 AUPR=0.315 time=51.18s
Epoch 106 | train_loss=0.1187 val_loss=0.0992 P=0.411 R=0.335 F1=0.369 ROC-AUC=0.983 AUPR=0.321 time=50.88s
Epoch 107 | train_loss=0.1148 val_loss=0.0967 P=0.417 R=0.333 F1=0.370 ROC-AUC=0.983 AUPR=0.325 time=51.96s
Epoch 108 | train_loss=0.1237 val_loss=0.0963 P=0.389 R=0.340 F1=0.363 ROC-AUC=0.984 AUPR=0.315 time=50.76s
Epoch 109 | train_loss=0.1577 val_loss=0.0981 P=0.517 R=0.278 F1=0.362 ROC-AUC=0.983 AUPR=0.318 time=51.12s
Epoch 110 | train_loss=0.1316 val_loss=1.0965 P=0.347 R=0.308 F1=0.326 ROC-AUC=0.858 AUPR=0.270 time=49.95s
Epoch 111 | train_loss=0.1651 val_loss=0.0959 P=0.428 R=0.321 F1=0.367 ROC-AUC=0.983 AUPR=0.325 time=50.60s
Epoch 112 | train_loss=0.1384 val_loss=0.0976 P=0.387 R=0.326 F1=0.354 ROC-AUC=0.983 AUPR=0.305 time=50.87s
Epoch 113 | train_loss=0.1255 val_loss=0.0980 P=0.463 R=0.312 F1=0.373 ROC-AUC=0.983 AUPR=0.314 time=49.71s
Epoch 114 | train_loss=0.1151 val_loss=0.0958 P=0.417 R=0.319 F1=0.362 ROC-AUC=0.983 AUPR=0.323 time=50.00s
Epoch 115 | train_loss=0.1167 val_loss=0.0991 P=0.477 R=0.306 F1=0.373 ROC-AUC=0.982 AUPR=0.329 time=50.59s
Epoch 116 | train_loss=0.1092 val_loss=0.0952 P=0.420 R=0.343 F1=0.377 ROC-AUC=0.984 AUPR=0.323 time=50.59s
Epoch 117 | train_loss=0.1283 val_loss=0.0962 P=0.432 R=0.313 F1=0.363 ROC-AUC=0.984 AUPR=0.320 time=50.55s
Epoch 118 | train_loss=0.1489 val_loss=0.0966 P=0.437 R=0.306 F1=0.360 ROC-AUC=0.984 AUPR=0.317 time=51.06s
Epoch 119 | train_loss=0.1384 val_loss=0.0956 P=0.442 R=0.318 F1=0.370 ROC-AUC=0.984 AUPR=0.326 time=50.96s
Epoch 120 | train_loss=0.1494 val_loss=0.0957 P=0.407 R=0.338 F1=0.369 ROC-AUC=0.983 AUPR=0.319 time=50.90s
Epoch 121 | train_loss=0.1075 val_loss=0.1656 P=0.372 R=0.289 F1=0.325 ROC-AUC=0.941 AUPR=0.283 time=50.87s
Epoch 122 | train_loss=0.1237 val_loss=0.0986 P=0.426 R=0.340 F1=0.378 ROC-AUC=0.983 AUPR=0.326 time=49.77s
Epoch 123 | train_loss=0.1456 val_loss=0.7150 P=0.329 R=0.312 F1=0.320 ROC-AUC=0.861 AUPR=0.260 time=50.83s
Epoch 124 | train_loss=0.1196 val_loss=0.0971 P=0.399 R=0.325 F1=0.358 ROC-AUC=0.983 AUPR=0.312 time=51.05s
Epoch 125 | train_loss=0.1341 val_loss=0.4226 P=0.340 R=0.301 F1=0.320 ROC-AUC=0.892 AUPR=0.264 time=51.00s
Epoch 126 | train_loss=0.1002 val_loss=0.0952 P=0.486 R=0.304 F1=0.374 ROC-AUC=0.984 AUPR=0.326 time=49.72s
Epoch 127 | train_loss=0.1287 val_loss=0.0957 P=0.505 R=0.296 F1=0.373 ROC-AUC=0.983 AUPR=0.331 time=50.15s
Epoch 128 | train_loss=0.1262 val_loss=0.0958 P=0.477 R=0.316 F1=0.380 ROC-AUC=0.984 AUPR=0.326 time=50.15s
Epoch 129 | train_loss=0.1124 val_loss=0.0975 P=0.396 R=0.342 F1=0.367 ROC-AUC=0.983 AUPR=0.325 time=49.92s
Epoch 130 | train_loss=0.1477 val_loss=0.0950 P=0.426 R=0.327 F1=0.370 ROC-AUC=0.983 AUPR=0.327 time=50.11s
Epoch 131 | train_loss=0.1239 val_loss=0.0959 P=0.456 R=0.299 F1=0.361 ROC-AUC=0.983 AUPR=0.324 time=50.28s
Epoch 132 | train_loss=0.1574 val_loss=0.0997 P=0.422 R=0.336 F1=0.374 ROC-AUC=0.983 AUPR=0.336 time=50.14s
Epoch 133 | train_loss=0.1244 val_loss=0.2269 P=0.240 R=0.288 F1=0.262 ROC-AUC=0.925 AUPR=0.147 time=50.13s
Epoch 134 | train_loss=0.1234 val_loss=0.0967 P=0.449 R=0.324 F1=0.377 ROC-AUC=0.983 AUPR=0.332 time=51.60s
Epoch 135 | train_loss=0.1117 val_loss=0.0993 P=0.434 R=0.332 F1=0.376 ROC-AUC=0.983 AUPR=0.325 time=50.85s
Epoch 136 | train_loss=0.1411 val_loss=0.0957 P=0.413 R=0.323 F1=0.363 ROC-AUC=0.984 AUPR=0.321 time=51.41s
Epoch 137 | train_loss=0.1410 val_loss=0.0953 P=0.464 R=0.319 F1=0.378 ROC-AUC=0.984 AUPR=0.333 time=51.39s
Epoch 138 | train_loss=0.1285 val_loss=0.0966 P=0.405 R=0.343 F1=0.371 ROC-AUC=0.983 AUPR=0.327 time=49.88s
Epoch 139 | train_loss=0.1015 val_loss=0.0956 P=0.410 R=0.347 F1=0.376 ROC-AUC=0.984 AUPR=0.332 time=50.63s
Epoch 140 | train_loss=0.1492 val_loss=0.0977 P=0.457 R=0.319 F1=0.376 ROC-AUC=0.983 AUPR=0.319 time=51.46s
Epoch 141 | train_loss=0.1320 val_loss=0.0946 P=0.450 R=0.315 F1=0.370 ROC-AUC=0.984 AUPR=0.328 time=51.77s
Epoch 142 | train_loss=0.1144 val_loss=0.0955 P=0.546 R=0.282 F1=0.372 ROC-AUC=0.983 AUPR=0.329 time=51.01s
Epoch 143 | train_loss=0.1353 val_loss=0.0954 P=0.470 R=0.330 F1=0.388 ROC-AUC=0.983 AUPR=0.336 time=51.14s
Epoch 144 | train_loss=0.1046 val_loss=0.0940 P=0.487 R=0.297 F1=0.369 ROC-AUC=0.984 AUPR=0.338 time=51.19s
Epoch 145 | train_loss=0.1207 val_loss=0.0961 P=0.425 R=0.319 F1=0.365 ROC-AUC=0.984 AUPR=0.327 time=50.79s
Epoch 146 | train_loss=0.1182 val_loss=0.0979 P=0.414 R=0.358 F1=0.384 ROC-AUC=0.983 AUPR=0.329 time=50.53s
Epoch 147 | train_loss=0.1224 val_loss=0.0965 P=0.465 R=0.310 F1=0.372 ROC-AUC=0.983 AUPR=0.323 time=50.78s
Epoch 148 | train_loss=0.1046 val_loss=0.0951 P=0.402 R=0.353 F1=0.376 ROC-AUC=0.983 AUPR=0.338 time=51.03s
Epoch 149 | train_loss=0.1129 val_loss=0.0958 P=0.490 R=0.318 F1=0.385 ROC-AUC=0.984 AUPR=0.339 time=50.97s
Epoch 150 | train_loss=0.1189 val_loss=0.0949 P=0.432 R=0.347 F1=0.385 ROC-AUC=0.984 AUPR=0.333 time=51.67s
Epoch 151 | train_loss=0.1457 val_loss=0.0941 P=0.510 R=0.301 F1=0.379 ROC-AUC=0.984 AUPR=0.336 time=51.06s
Epoch 152 | train_loss=0.1258 val_loss=0.0978 P=0.450 R=0.315 F1=0.370 ROC-AUC=0.983 AUPR=0.322 time=51.29s
Epoch 153 | train_loss=0.1423 val_loss=0.0947 P=0.429 R=0.351 F1=0.386 ROC-AUC=0.984 AUPR=0.338 time=51.59s
Epoch 154 | train_loss=0.1277 val_loss=0.0949 P=0.443 R=0.329 F1=0.378 ROC-AUC=0.984 AUPR=0.335 time=51.55s
Epoch 155 | train_loss=0.1335 val_loss=0.0965 P=0.535 R=0.312 F1=0.394 ROC-AUC=0.984 AUPR=0.340 time=51.28s
Epoch 156 | train_loss=0.1078 val_loss=0.0955 P=0.485 R=0.318 F1=0.384 ROC-AUC=0.984 AUPR=0.333 time=51.02s
Epoch 157 | train_loss=0.1257 val_loss=0.0948 P=0.487 R=0.302 F1=0.373 ROC-AUC=0.984 AUPR=0.333 time=50.73s
Epoch 158 | train_loss=0.1461 val_loss=0.0960 P=0.488 R=0.290 F1=0.363 ROC-AUC=0.984 AUPR=0.319 time=51.45s
Epoch 159 | train_loss=0.1258 val_loss=0.0992 P=0.468 R=0.327 F1=0.385 ROC-AUC=0.983 AUPR=0.338 time=50.02s
Epoch 160 | train_loss=0.1286 val_loss=0.0947 P=0.396 R=0.365 F1=0.380 ROC-AUC=0.984 AUPR=0.338 time=49.88s
Epoch 161 | train_loss=0.1881 val_loss=0.2883 P=0.400 R=0.281 F1=0.330 ROC-AUC=0.912 AUPR=0.274 time=49.96s
Epoch 162 | train_loss=0.1625 val_loss=0.0996 P=0.430 R=0.353 F1=0.388 ROC-AUC=0.983 AUPR=0.338 time=49.98s
Epoch 163 | train_loss=0.1287 val_loss=0.0990 P=0.400 R=0.314 F1=0.352 ROC-AUC=0.983 AUPR=0.312 time=50.04s
Epoch 164 | train_loss=0.1309 val_loss=0.0987 P=0.487 R=0.319 F1=0.385 ROC-AUC=0.983 AUPR=0.336 time=50.00s
Epoch 165 | train_loss=0.1155 val_loss=0.0955 P=0.477 R=0.332 F1=0.392 ROC-AUC=0.983 AUPR=0.343 time=49.70s
Epoch 166 | train_loss=0.1085 val_loss=1.1559 P=0.434 R=0.279 F1=0.340 ROC-AUC=0.845 AUPR=0.282 time=49.85s
Epoch 167 | train_loss=0.1256 val_loss=0.0964 P=0.425 R=0.317 F1=0.363 ROC-AUC=0.983 AUPR=0.328 time=49.90s
Epoch 168 | train_loss=0.1206 val_loss=0.0956 P=0.481 R=0.337 F1=0.396 ROC-AUC=0.983 AUPR=0.348 time=50.54s
Epoch 169 | train_loss=0.1144 val_loss=0.0952 P=0.419 R=0.353 F1=0.383 ROC-AUC=0.984 AUPR=0.337 time=50.46s
Epoch 170 | train_loss=0.1304 val_loss=0.0941 P=0.434 R=0.327 F1=0.373 ROC-AUC=0.984 AUPR=0.333 time=51.27s
Epoch 171 | train_loss=0.1273 val_loss=0.1029 P=0.482 R=0.319 F1=0.384 ROC-AUC=0.983 AUPR=0.328 time=50.75s
Epoch 172 | train_loss=0.1081 val_loss=0.0941 P=0.463 R=0.325 F1=0.382 ROC-AUC=0.984 AUPR=0.331 time=51.33s
Epoch 173 | train_loss=0.1458 val_loss=0.0971 P=0.488 R=0.314 F1=0.382 ROC-AUC=0.983 AUPR=0.332 time=51.26s
Epoch 174 | train_loss=0.0999 val_loss=0.0960 P=0.513 R=0.314 F1=0.389 ROC-AUC=0.983 AUPR=0.346 time=50.68s
Epoch 175 | train_loss=0.1822 val_loss=0.0983 P=0.468 R=0.319 F1=0.379 ROC-AUC=0.983 AUPR=0.330 time=50.54s
Epoch 176 | train_loss=0.1464 val_loss=0.0969 P=0.440 R=0.344 F1=0.386 ROC-AUC=0.983 AUPR=0.335 time=51.63s
Epoch 177 | train_loss=0.2096 val_loss=0.1039 P=0.521 R=0.308 F1=0.387 ROC-AUC=0.982 AUPR=0.338 time=51.09s
Epoch 178 | train_loss=0.2118 val_loss=0.0962 P=0.399 R=0.359 F1=0.378 ROC-AUC=0.983 AUPR=0.334 time=51.08s
Epoch 179 | train_loss=0.1051 val_loss=0.2197 P=0.397 R=0.269 F1=0.321 ROC-AUC=0.933 AUPR=0.271 time=51.28s
Epoch 180 | train_loss=0.1557 val_loss=0.0941 P=0.478 R=0.318 F1=0.381 ROC-AUC=0.984 AUPR=0.344 time=50.83s
Epoch 181 | train_loss=0.1374 val_loss=0.0951 P=0.443 R=0.338 F1=0.383 ROC-AUC=0.984 AUPR=0.331 time=50.98s
Epoch 182 | train_loss=0.1368 val_loss=0.0942 P=0.475 R=0.323 F1=0.385 ROC-AUC=0.984 AUPR=0.337 time=51.03s
Epoch 183 | train_loss=0.1342 val_loss=0.0971 P=0.524 R=0.308 F1=0.388 ROC-AUC=0.983 AUPR=0.343 time=51.51s
Epoch 184 | train_loss=0.1120 val_loss=0.0977 P=0.521 R=0.315 F1=0.392 ROC-AUC=0.983 AUPR=0.348 time=50.84s
Epoch 185 | train_loss=0.1340 val_loss=0.0955 P=0.448 R=0.334 F1=0.383 ROC-AUC=0.984 AUPR=0.347 time=51.50s
Epoch 186 | train_loss=0.1738 val_loss=0.0945 P=0.486 R=0.305 F1=0.375 ROC-AUC=0.984 AUPR=0.340 time=51.12s
Epoch 187 | train_loss=0.1403 val_loss=0.0960 P=0.466 R=0.319 F1=0.379 ROC-AUC=0.983 AUPR=0.334 time=51.14s
Epoch 188 | train_loss=0.1437 val_loss=0.0950 P=0.520 R=0.297 F1=0.378 ROC-AUC=0.983 AUPR=0.337 time=51.17s
Epoch 189 | train_loss=0.1710 val_loss=0.0961 P=0.519 R=0.313 F1=0.390 ROC-AUC=0.983 AUPR=0.349 time=51.27s
Epoch 190 | train_loss=0.1183 val_loss=0.0976 P=0.453 R=0.345 F1=0.391 ROC-AUC=0.984 AUPR=0.346 time=50.83s
Epoch 191 | train_loss=0.1250 val_loss=0.0958 P=0.533 R=0.302 F1=0.386 ROC-AUC=0.983 AUPR=0.343 time=51.15s
Epoch 192 | train_loss=0.1775 val_loss=0.0956 P=0.465 R=0.319 F1=0.379 ROC-AUC=0.983 AUPR=0.334 time=50.56s
Epoch 193 | train_loss=0.1060 val_loss=0.0948 P=0.507 R=0.298 F1=0.375 ROC-AUC=0.984 AUPR=0.341 time=50.38s
Epoch 194 | train_loss=0.1369 val_loss=0.0982 P=0.567 R=0.295 F1=0.388 ROC-AUC=0.983 AUPR=0.344 time=50.68s
Epoch 195 | train_loss=0.1676 val_loss=0.0970 P=0.467 R=0.333 F1=0.389 ROC-AUC=0.983 AUPR=0.336 time=50.94s
Epoch 196 | train_loss=0.1550 val_loss=0.0998 P=0.441 R=0.352 F1=0.392 ROC-AUC=0.983 AUPR=0.341 time=51.07s
Epoch 197 | train_loss=0.1227 val_loss=0.0949 P=0.521 R=0.326 F1=0.401 ROC-AUC=0.984 AUPR=0.343 time=49.91s
Epoch 198 | train_loss=0.1311 val_loss=0.0950 P=0.505 R=0.315 F1=0.388 ROC-AUC=0.984 AUPR=0.350 time=51.21s
Epoch 199 | train_loss=0.1228 val_loss=0.0951 P=0.477 R=0.317 F1=0.381 ROC-AUC=0.983 AUPR=0.339 time=51.18s
Epoch 200 | train_loss=0.1331 val_loss=0.0957 P=0.426 R=0.341 F1=0.379 ROC-AUC=0.983 AUPR=0.340 time=50.30s
Epoch 201 | train_loss=0.1294 val_loss=0.0959 P=0.479 R=0.325 F1=0.388 ROC-AUC=0.983 AUPR=0.340 time=50.09s
Epoch 202 | train_loss=0.1354 val_loss=0.0971 P=0.505 R=0.309 F1=0.383 ROC-AUC=0.984 AUPR=0.343 time=49.69s
Epoch 203 | train_loss=0.1195 val_loss=0.1741 P=0.409 R=0.310 F1=0.353 ROC-AUC=0.956 AUPR=0.303 time=50.20s
Epoch 204 | train_loss=0.1299 val_loss=0.0959 P=0.514 R=0.324 F1=0.398 ROC-AUC=0.984 AUPR=0.347 time=49.99s
Epoch 205 | train_loss=0.1174 val_loss=0.1473 P=0.450 R=0.308 F1=0.366 ROC-AUC=0.964 AUPR=0.313 time=50.10s
Epoch 206 | train_loss=0.1487 val_loss=0.0950 P=0.389 R=0.375 F1=0.382 ROC-AUC=0.983 AUPR=0.340 time=49.81s
Epoch 207 | train_loss=0.1292 val_loss=0.0986 P=0.450 R=0.329 F1=0.380 ROC-AUC=0.983 AUPR=0.340 time=49.82s
Epoch 208 | train_loss=0.1325 val_loss=0.0957 P=0.515 R=0.307 F1=0.385 ROC-AUC=0.984 AUPR=0.338 time=49.88s
Epoch 209 | train_loss=0.1208 val_loss=0.0965 P=0.503 R=0.313 F1=0.386 ROC-AUC=0.983 AUPR=0.349 time=49.95s
Epoch 210 | train_loss=0.1751 val_loss=0.0984 P=0.469 R=0.328 F1=0.386 ROC-AUC=0.982 AUPR=0.346 time=49.72s
Epoch 211 | train_loss=0.1138 val_loss=0.0968 P=0.485 R=0.347 F1=0.405 ROC-AUC=0.983 AUPR=0.347 time=49.90s
Epoch 212 | train_loss=0.1140 val_loss=0.0945 P=0.434 R=0.344 F1=0.384 ROC-AUC=0.984 AUPR=0.340 time=50.09s
Epoch 213 | train_loss=0.1408 val_loss=0.0957 P=0.450 R=0.336 F1=0.385 ROC-AUC=0.984 AUPR=0.337 time=50.03s
Epoch 214 | train_loss=0.1834 val_loss=0.0963 P=0.432 R=0.324 F1=0.370 ROC-AUC=0.983 AUPR=0.322 time=50.64s
Epoch 215 | train_loss=0.1136 val_loss=0.0937 P=0.425 R=0.348 F1=0.383 ROC-AUC=0.984 AUPR=0.345 time=49.88s
Epoch 216 | train_loss=0.1207 val_loss=0.0952 P=0.517 R=0.312 F1=0.389 ROC-AUC=0.984 AUPR=0.343 time=49.93s
Epoch 217 | train_loss=0.1552 val_loss=0.0948 P=0.373 R=0.397 F1=0.384 ROC-AUC=0.984 AUPR=0.336 time=49.95s
Epoch 218 | train_loss=0.1445 val_loss=0.0968 P=0.497 R=0.329 F1=0.396 ROC-AUC=0.983 AUPR=0.346 time=49.76s
Epoch 219 | train_loss=0.1440 val_loss=0.0939 P=0.467 R=0.331 F1=0.387 ROC-AUC=0.984 AUPR=0.336 time=49.70s
Epoch 220 | train_loss=0.1154 val_loss=0.0951 P=0.481 R=0.323 F1=0.387 ROC-AUC=0.984 AUPR=0.341 time=49.95s
Epoch 221 | train_loss=0.1880 val_loss=0.0948 P=0.474 R=0.329 F1=0.389 ROC-AUC=0.984 AUPR=0.340 time=50.06s
Epoch 222 | train_loss=0.1289 val_loss=0.0960 P=0.494 R=0.305 F1=0.377 ROC-AUC=0.983 AUPR=0.333 time=50.13s
Epoch 223 | train_loss=0.1277 val_loss=0.0968 P=0.452 R=0.339 F1=0.387 ROC-AUC=0.983 AUPR=0.339 time=49.82s

Early stopping at epoch 223

Total training time: 11376.89s (189.6 min)

Loading best model from epoch 198...
Evaluating final model...
======================================================================
EVALUATION RESULTS: seed2025_experiment_3 TRAIN
======================================================================

STANDARD METRICS:
  Precision:        0.4557
  Recall:           0.3641
  F1-Score:         0.4048
  ROC-AUC:          0.9893
  AUPR:             0.3759
  Balanced Acc:     0.6818

IMBALANCED-AWARE METRICS:
  MCC:              0.4068
  Cohen Kappa:      0.4043
  Specificity:      0.9996

THRESHOLD: 0.965

CONFUSION MATRIX:
  True Negatives:   3042550
  False Positives:  1351
  False Negatives:  1975
  True Positives:   1131

TOP-K PRECISION:
  precision_at_100: 0.9400
  precision_at_500: 0.7960
  precision_at_1000: 0.6830
======================================================================
======================================================================
EVALUATION RESULTS: seed2025_experiment_3 VAL
======================================================================

STANDARD METRICS:
  Precision:        0.5054
  Recall:           0.3147
  F1-Score:         0.3879
  ROC-AUC:          0.9839
  AUPR:             0.3496
  Balanced Acc:     0.6572

IMBALANCED-AWARE METRICS:
  MCC:              0.3983
  Cohen Kappa:      0.3874
  Specificity:      0.9997

THRESHOLD: 0.975

CONFUSION MATRIX:
  True Negatives:   1014314
  False Positives:  319
  False Negatives:  710
  True Positives:   326

TOP-K PRECISION:
  precision_at_100: 0.9000
  precision_at_500: 0.5860
  precision_at_1000: 0.3880
======================================================================
======================================================================
EVALUATION RESULTS: seed2025_experiment_3 TEST
======================================================================

STANDARD METRICS:
  Precision:        0.4547
  Recall:           0.3246
  F1-Score:         0.3788
  ROC-AUC:          0.9808
  AUPR:             0.3291
  Balanced Acc:     0.6621

IMBALANCED-AWARE METRICS:
  MCC:              0.3837
  Cohen Kappa:      0.3783
  Specificity:      0.9996

THRESHOLD: 0.970

CONFUSION MATRIX:
  True Negatives:   1014231
  False Positives:  403
  False Negatives:  699
  True Positives:   336

TOP-K PRECISION:
  precision_at_100: 0.8500
  precision_at_500: 0.5500
  precision_at_1000: 0.3840
======================================================================

Saving results...
 Saved metrics to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans\seed2025_experiment_3\graphsage-t\metrics.json
 Saved prediction probabilities
 Saved experiment config

======================================================================
GraphSAGE-T Training Complete!
Results saved to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans\seed2025_experiment_3\graphsage-t
======================================================================

================================================================================
Logging ended at: 2025-12-01 03:29:01.936618
================================================================================
