
================================================================================
Logging started at: 2025-12-03 09:03:24.958054
Log file: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed2_ablation_no_temp\dyrep\seed2_ablation_no_temp_20251203_090324.txt
================================================================================

[INFO] Logging to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed2_ablation_no_temp\dyrep\seed2_ablation_no_temp_20251203_090324.txt
================================================================================
EXPERIMENT CONFIG SUMMARY
================================================================================

[DATASET]
  Name:       HI-Small_Trans_RAT_medium
  Theory:     RAT
  Intensity:  medium

[MODEL]
  DyRep
  Hidden dim: 128

[PATHS]
  Graphs:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs\HI-Small_Trans_RAT_medium
  Splits:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits\HI-Small_Trans_RAT_medium
  Results:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed2_ablation_no_temp\dyrep
  Logs:       C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed2_ablation_no_temp\dyrep
================================================================================

[DEVICE] cuda

[INFO] Using default graph directory: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs_dyrep\HI-Small_Trans_RAT_medium__no_temp

======= DYREP-STYLE EVENT MODEL TRAINING (FP32) =======
Graph folder:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs_dyrep\HI-Small_Trans_RAT_medium__no_temp
Splits folder:   C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits_dyrep\HI-Small_Trans_RAT_medium
Results folder:  C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed2_ablation_no_temp\dyrep
Batch size:      8192
Eval batch size: 16384
Device:          cuda
=======================================================

Num nodes:        515,080
Num events/edges: 5,078,415
Node feat dim:    12
Edge feat dim:    50
Event types:      7

Split sizes:
  Train: 3,047,049
  Val:   1,015,683
  Test:  1,015,683

pos_weight (train) = 100.000

Starting training for up to 350 epochs...

Epoch 001 | train_loss=17.5059 val_loss=0.9964 P=0.060 R=0.207 F1=0.093 ROC-AUC=0.821 AUPR=0.034 time=20.77s
Epoch 002 | train_loss=0.9684 val_loss=1.5483 P=0.048 R=0.179 F1=0.076 ROC-AUC=0.845 AUPR=0.031 time=20.72s
Epoch 003 | train_loss=0.8059 val_loss=2.5108 P=0.059 R=0.232 F1=0.095 ROC-AUC=0.856 AUPR=0.044 time=21.42s
Epoch 004 | train_loss=0.8110 val_loss=0.1672 P=0.071 R=0.311 F1=0.116 ROC-AUC=0.954 AUPR=0.056 time=21.39s
Epoch 005 | train_loss=0.4624 val_loss=0.7282 P=0.098 R=0.172 F1=0.125 ROC-AUC=0.884 AUPR=0.057 time=21.12s
Epoch 006 | train_loss=0.6024 val_loss=0.2881 P=0.092 R=0.287 F1=0.140 ROC-AUC=0.909 AUPR=0.077 time=21.34s
Epoch 007 | train_loss=0.4906 val_loss=0.1441 P=0.173 R=0.220 F1=0.194 ROC-AUC=0.969 AUPR=0.125 time=21.11s
Epoch 008 | train_loss=0.5301 val_loss=2.1753 P=0.104 R=0.238 F1=0.145 ROC-AUC=0.863 AUPR=0.077 time=20.80s
Epoch 009 | train_loss=0.5005 val_loss=6.0447 P=0.201 R=0.206 F1=0.203 ROC-AUC=0.864 AUPR=0.135 time=21.48s
Epoch 010 | train_loss=0.4569 val_loss=0.2730 P=0.130 R=0.286 F1=0.178 ROC-AUC=0.910 AUPR=0.095 time=20.82s
Epoch 011 | train_loss=0.2859 val_loss=0.1319 P=0.165 R=0.230 F1=0.192 ROC-AUC=0.972 AUPR=0.106 time=21.97s
Epoch 012 | train_loss=0.3702 val_loss=1.1764 P=0.137 R=0.257 F1=0.179 ROC-AUC=0.869 AUPR=0.103 time=21.78s
Epoch 013 | train_loss=0.3696 val_loss=0.1288 P=0.148 R=0.224 F1=0.178 ROC-AUC=0.972 AUPR=0.099 time=22.52s
Epoch 014 | train_loss=0.2475 val_loss=0.4600 P=0.137 R=0.214 F1=0.167 ROC-AUC=0.905 AUPR=0.093 time=22.54s
Epoch 015 | train_loss=0.2462 val_loss=0.1234 P=0.166 R=0.249 F1=0.199 ROC-AUC=0.975 AUPR=0.132 time=22.99s
Epoch 016 | train_loss=0.3098 val_loss=0.1252 P=0.122 R=0.292 F1=0.172 ROC-AUC=0.975 AUPR=0.095 time=22.42s
Epoch 017 | train_loss=0.2978 val_loss=0.7909 P=0.148 R=0.253 F1=0.187 ROC-AUC=0.878 AUPR=0.108 time=22.89s
Epoch 018 | train_loss=0.2729 val_loss=0.2909 P=0.011 R=0.823 F1=0.022 ROC-AUC=0.934 AUPR=0.019 time=23.90s
Epoch 019 | train_loss=0.1912 val_loss=0.1217 P=0.233 R=0.203 F1=0.217 ROC-AUC=0.976 AUPR=0.137 time=22.60s
Epoch 020 | train_loss=0.1877 val_loss=0.3051 P=0.155 R=0.205 F1=0.177 ROC-AUC=0.912 AUPR=0.108 time=21.86s
Epoch 021 | train_loss=0.3371 val_loss=0.1178 P=0.185 R=0.243 F1=0.210 ROC-AUC=0.977 AUPR=0.134 time=22.98s
Epoch 022 | train_loss=0.2157 val_loss=0.1152 P=0.213 R=0.226 F1=0.219 ROC-AUC=0.978 AUPR=0.149 time=23.13s
Epoch 023 | train_loss=0.1731 val_loss=0.1181 P=0.178 R=0.225 F1=0.199 ROC-AUC=0.977 AUPR=0.121 time=22.60s
Epoch 024 | train_loss=0.1692 val_loss=0.1126 P=0.188 R=0.275 F1=0.223 ROC-AUC=0.979 AUPR=0.150 time=22.91s
Epoch 025 | train_loss=0.2084 val_loss=0.1172 P=0.152 R=0.270 F1=0.194 ROC-AUC=0.977 AUPR=0.117 time=22.41s
Epoch 026 | train_loss=0.2211 val_loss=0.1348 P=0.140 R=0.231 F1=0.174 ROC-AUC=0.971 AUPR=0.095 time=23.39s
Epoch 027 | train_loss=0.1410 val_loss=0.1112 P=0.214 R=0.254 F1=0.232 ROC-AUC=0.979 AUPR=0.175 time=23.37s
Epoch 028 | train_loss=0.2094 val_loss=0.1167 P=0.197 R=0.229 F1=0.212 ROC-AUC=0.977 AUPR=0.144 time=21.62s
Epoch 029 | train_loss=0.1744 val_loss=0.1103 P=0.226 R=0.269 F1=0.246 ROC-AUC=0.980 AUPR=0.168 time=22.58s
Epoch 030 | train_loss=0.1241 val_loss=0.1129 P=0.231 R=0.204 F1=0.217 ROC-AUC=0.979 AUPR=0.163 time=22.29s
Epoch 031 | train_loss=0.1250 val_loss=0.1082 P=0.205 R=0.284 F1=0.238 ROC-AUC=0.980 AUPR=0.158 time=22.57s
Epoch 032 | train_loss=0.1957 val_loss=0.1115 P=0.194 R=0.299 F1=0.236 ROC-AUC=0.979 AUPR=0.162 time=22.86s
Epoch 033 | train_loss=0.1699 val_loss=0.1144 P=0.208 R=0.229 F1=0.218 ROC-AUC=0.979 AUPR=0.154 time=22.58s
Epoch 034 | train_loss=0.1517 val_loss=0.1110 P=0.223 R=0.243 F1=0.232 ROC-AUC=0.979 AUPR=0.168 time=23.12s
Epoch 035 | train_loss=0.1317 val_loss=0.1065 P=0.214 R=0.298 F1=0.249 ROC-AUC=0.980 AUPR=0.197 time=22.55s
Epoch 036 | train_loss=0.1402 val_loss=0.1098 P=0.219 R=0.253 F1=0.235 ROC-AUC=0.980 AUPR=0.180 time=21.55s
Epoch 037 | train_loss=0.1150 val_loss=0.1180 P=0.165 R=0.291 F1=0.211 ROC-AUC=0.977 AUPR=0.135 time=22.54s
Epoch 038 | train_loss=0.1413 val_loss=0.1091 P=0.258 R=0.238 F1=0.247 ROC-AUC=0.980 AUPR=0.192 time=22.70s
Epoch 039 | train_loss=0.1509 val_loss=0.1074 P=0.206 R=0.305 F1=0.246 ROC-AUC=0.981 AUPR=0.187 time=22.79s
Epoch 040 | train_loss=0.0990 val_loss=0.1089 P=0.236 R=0.254 F1=0.245 ROC-AUC=0.980 AUPR=0.184 time=22.67s
Epoch 041 | train_loss=0.1986 val_loss=0.1082 P=0.216 R=0.291 F1=0.248 ROC-AUC=0.980 AUPR=0.191 time=22.54s
Epoch 042 | train_loss=0.1321 val_loss=0.1158 P=0.224 R=0.213 F1=0.218 ROC-AUC=0.978 AUPR=0.160 time=22.83s
Epoch 043 | train_loss=0.1792 val_loss=0.1079 P=0.197 R=0.308 F1=0.240 ROC-AUC=0.980 AUPR=0.177 time=22.83s
Epoch 044 | train_loss=0.1058 val_loss=0.1112 P=0.218 R=0.304 F1=0.254 ROC-AUC=0.979 AUPR=0.193 time=22.58s
Epoch 045 | train_loss=0.1696 val_loss=0.1068 P=0.243 R=0.301 F1=0.269 ROC-AUC=0.981 AUPR=0.219 time=22.29s
Epoch 046 | train_loss=0.0822 val_loss=0.1122 P=0.209 R=0.284 F1=0.241 ROC-AUC=0.979 AUPR=0.173 time=21.42s
Epoch 047 | train_loss=0.1291 val_loss=0.1104 P=0.240 R=0.280 F1=0.258 ROC-AUC=0.979 AUPR=0.188 time=22.74s
Epoch 048 | train_loss=0.0810 val_loss=0.1295 P=0.194 R=0.266 F1=0.224 ROC-AUC=0.974 AUPR=0.158 time=22.51s
Epoch 049 | train_loss=0.0964 val_loss=0.1054 P=0.257 R=0.273 F1=0.265 ROC-AUC=0.981 AUPR=0.211 time=22.54s
Epoch 050 | train_loss=0.1162 val_loss=0.1125 P=0.228 R=0.249 F1=0.238 ROC-AUC=0.978 AUPR=0.180 time=22.55s
Epoch 051 | train_loss=0.0946 val_loss=0.1024 P=0.285 R=0.303 F1=0.294 ROC-AUC=0.982 AUPR=0.256 time=22.75s
Epoch 052 | train_loss=0.0795 val_loss=0.1128 P=0.241 R=0.275 F1=0.257 ROC-AUC=0.979 AUPR=0.209 time=21.09s
Epoch 053 | train_loss=0.1147 val_loss=0.1217 P=0.238 R=0.282 F1=0.258 ROC-AUC=0.977 AUPR=0.204 time=21.53s
Epoch 054 | train_loss=0.1552 val_loss=0.1135 P=0.282 R=0.257 F1=0.269 ROC-AUC=0.979 AUPR=0.224 time=21.66s
Epoch 055 | train_loss=0.0799 val_loss=0.3300 P=0.237 R=0.299 F1=0.265 ROC-AUC=0.917 AUPR=0.221 time=21.23s
Epoch 056 | train_loss=0.1284 val_loss=0.1054 P=0.340 R=0.274 F1=0.303 ROC-AUC=0.981 AUPR=0.269 time=21.60s
Epoch 057 | train_loss=0.0853 val_loss=0.1391 P=0.290 R=0.229 F1=0.256 ROC-AUC=0.972 AUPR=0.205 time=21.00s
Epoch 058 | train_loss=0.0776 val_loss=0.1075 P=0.367 R=0.289 F1=0.323 ROC-AUC=0.980 AUPR=0.273 time=21.77s
Epoch 059 | train_loss=0.0693 val_loss=0.1182 P=0.276 R=0.262 F1=0.269 ROC-AUC=0.977 AUPR=0.222 time=21.55s
Epoch 060 | train_loss=0.0690 val_loss=0.1093 P=0.375 R=0.235 F1=0.289 ROC-AUC=0.979 AUPR=0.251 time=21.60s
Epoch 061 | train_loss=0.0685 val_loss=0.1570 P=0.206 R=0.282 F1=0.238 ROC-AUC=0.979 AUPR=0.194 time=21.74s
Epoch 062 | train_loss=0.2985 val_loss=0.1255 P=0.270 R=0.293 F1=0.281 ROC-AUC=0.975 AUPR=0.242 time=22.03s
Epoch 063 | train_loss=0.0688 val_loss=0.1328 P=0.326 R=0.220 F1=0.263 ROC-AUC=0.974 AUPR=0.224 time=21.67s
Epoch 064 | train_loss=0.1395 val_loss=0.1374 P=0.311 R=0.251 F1=0.278 ROC-AUC=0.973 AUPR=0.236 time=21.74s
Epoch 065 | train_loss=0.0690 val_loss=0.1638 P=0.257 R=0.289 F1=0.272 ROC-AUC=0.966 AUPR=0.228 time=21.44s
Epoch 066 | train_loss=0.0945 val_loss=0.1419 P=0.242 R=0.228 F1=0.235 ROC-AUC=0.973 AUPR=0.196 time=21.52s
Epoch 067 | train_loss=0.0876 val_loss=0.1088 P=0.453 R=0.234 F1=0.309 ROC-AUC=0.979 AUPR=0.280 time=21.49s
Epoch 068 | train_loss=0.0666 val_loss=0.1183 P=0.358 R=0.299 F1=0.325 ROC-AUC=0.978 AUPR=0.285 time=21.16s
Epoch 069 | train_loss=0.1318 val_loss=0.1162 P=0.295 R=0.300 F1=0.298 ROC-AUC=0.977 AUPR=0.274 time=22.04s
Epoch 070 | train_loss=0.0712 val_loss=0.1112 P=0.362 R=0.298 F1=0.327 ROC-AUC=0.978 AUPR=0.289 time=21.65s
Epoch 071 | train_loss=0.0893 val_loss=0.1837 P=0.246 R=0.266 F1=0.256 ROC-AUC=0.962 AUPR=0.220 time=20.97s
Epoch 072 | train_loss=0.1552 val_loss=0.1647 P=0.273 R=0.229 F1=0.249 ROC-AUC=0.965 AUPR=0.215 time=21.84s
Epoch 073 | train_loss=0.2514 val_loss=0.1661 P=0.362 R=0.233 F1=0.283 ROC-AUC=0.965 AUPR=0.239 time=22.03s
Epoch 074 | train_loss=0.0915 val_loss=0.1507 P=0.281 R=0.274 F1=0.278 ROC-AUC=0.968 AUPR=0.241 time=21.70s
Epoch 075 | train_loss=0.1178 val_loss=0.1354 P=0.361 R=0.253 F1=0.298 ROC-AUC=0.973 AUPR=0.264 time=22.00s
Epoch 076 | train_loss=0.1110 val_loss=0.1402 P=0.524 R=0.226 F1=0.316 ROC-AUC=0.973 AUPR=0.281 time=21.75s
Epoch 077 | train_loss=0.0561 val_loss=0.1158 P=0.432 R=0.258 F1=0.323 ROC-AUC=0.977 AUPR=0.286 time=21.57s
Epoch 078 | train_loss=0.0974 val_loss=0.1979 P=0.285 R=0.201 F1=0.235 ROC-AUC=0.957 AUPR=0.180 time=21.43s
Epoch 079 | train_loss=0.1603 val_loss=0.1050 P=0.336 R=0.316 F1=0.326 ROC-AUC=0.981 AUPR=0.294 time=22.16s
Epoch 080 | train_loss=0.1069 val_loss=0.1624 P=0.260 R=0.246 F1=0.253 ROC-AUC=0.967 AUPR=0.211 time=21.07s
Epoch 081 | train_loss=0.2115 val_loss=0.1784 P=0.237 R=0.238 F1=0.237 ROC-AUC=0.963 AUPR=0.198 time=21.45s
Epoch 082 | train_loss=0.1377 val_loss=0.1868 P=0.318 R=0.262 F1=0.287 ROC-AUC=0.958 AUPR=0.237 time=21.29s
Epoch 083 | train_loss=0.1178 val_loss=1.2398 P=0.265 R=0.185 F1=0.218 ROC-AUC=0.885 AUPR=0.176 time=21.82s
Epoch 084 | train_loss=0.1571 val_loss=0.1177 P=0.382 R=0.239 F1=0.294 ROC-AUC=0.978 AUPR=0.261 time=21.91s
Epoch 085 | train_loss=0.4020 val_loss=0.1207 P=0.489 R=0.240 F1=0.322 ROC-AUC=0.978 AUPR=0.278 time=21.93s
Epoch 086 | train_loss=0.1252 val_loss=2.0761 P=0.399 R=0.233 F1=0.294 ROC-AUC=0.867 AUPR=0.258 time=21.67s
Epoch 087 | train_loss=0.1698 val_loss=0.2138 P=0.279 R=0.182 F1=0.220 ROC-AUC=0.952 AUPR=0.160 time=21.72s
Epoch 088 | train_loss=0.0603 val_loss=0.1564 P=0.342 R=0.199 F1=0.251 ROC-AUC=0.967 AUPR=0.197 time=21.59s
Epoch 089 | train_loss=0.0629 val_loss=0.1300 P=0.491 R=0.236 F1=0.319 ROC-AUC=0.976 AUPR=0.273 time=21.71s
Epoch 090 | train_loss=0.1352 val_loss=0.1231 P=0.483 R=0.277 F1=0.352 ROC-AUC=0.977 AUPR=0.294 time=22.00s
Epoch 091 | train_loss=0.5077 val_loss=0.1314 P=0.283 R=0.245 F1=0.263 ROC-AUC=0.974 AUPR=0.220 time=21.28s
Epoch 092 | train_loss=0.3305 val_loss=0.1827 P=0.311 R=0.181 F1=0.229 ROC-AUC=0.959 AUPR=0.171 time=21.52s
Epoch 093 | train_loss=0.0946 val_loss=5.6339 P=0.355 R=0.213 F1=0.266 ROC-AUC=0.863 AUPR=0.216 time=21.58s
Epoch 094 | train_loss=0.1982 val_loss=0.1855 P=0.278 R=0.210 F1=0.239 ROC-AUC=0.958 AUPR=0.193 time=21.86s
Epoch 095 | train_loss=0.0731 val_loss=0.1314 P=0.414 R=0.201 F1=0.271 ROC-AUC=0.974 AUPR=0.228 time=21.90s
Epoch 096 | train_loss=0.0630 val_loss=0.1668 P=0.435 R=0.172 F1=0.246 ROC-AUC=0.965 AUPR=0.207 time=21.86s
Epoch 097 | train_loss=0.1323 val_loss=0.1110 P=0.387 R=0.276 F1=0.323 ROC-AUC=0.979 AUPR=0.283 time=21.80s
Epoch 098 | train_loss=0.4501 val_loss=4.0313 P=0.527 R=0.164 F1=0.250 ROC-AUC=0.863 AUPR=0.198 time=21.57s
Epoch 099 | train_loss=0.3155 val_loss=0.1549 P=0.280 R=0.206 F1=0.237 ROC-AUC=0.966 AUPR=0.171 time=21.61s
Epoch 100 | train_loss=0.0666 val_loss=0.1337 P=0.391 R=0.235 F1=0.293 ROC-AUC=0.974 AUPR=0.251 time=21.51s
Epoch 101 | train_loss=0.2399 val_loss=0.1118 P=0.489 R=0.227 F1=0.310 ROC-AUC=0.978 AUPR=0.265 time=21.59s
Epoch 102 | train_loss=0.1271 val_loss=0.1187 P=0.388 R=0.242 F1=0.298 ROC-AUC=0.978 AUPR=0.253 time=21.51s
Epoch 103 | train_loss=0.1278 val_loss=0.1551 P=0.329 R=0.231 F1=0.272 ROC-AUC=0.965 AUPR=0.227 time=21.53s
Epoch 104 | train_loss=0.5577 val_loss=1.1216 P=0.475 R=0.185 F1=0.266 ROC-AUC=0.870 AUPR=0.225 time=21.86s
Epoch 105 | train_loss=0.2351 val_loss=0.1400 P=0.371 R=0.238 F1=0.290 ROC-AUC=0.971 AUPR=0.250 time=21.41s

Early stopping at epoch 105 (no val AUPR improvement for 15 epochs)

Total training time: 2316.50s (38.6 min)

Loading best model from epoch 90...
Evaluating final model on train/val/test...
======================================================================
EVALUATION RESULTS: seed2_ablation_no_temp TRAIN
======================================================================

STANDARD METRICS:
  Precision:        0.8086
  Recall:           0.7611
  F1-Score:         0.7841
  ROC-AUC:          0.9910
  AUPR:             0.7511
  Balanced Acc:     0.8805

IMBALANCED-AWARE METRICS:
  MCC:              0.7843
  Cohen Kappa:      0.7840
  Specificity:      0.9999

THRESHOLD: 0.882

CONFUSION MATRIX:
  True Negatives:   3044337
  False Positives:  414
  False Negatives:  549
  True Positives:   1749

TOP-K PRECISION:
  precision_at_100: 0.9800
  precision_at_500: 0.9500
  precision_at_1000: 0.8950
======================================================================
======================================================================
EVALUATION RESULTS: seed2_ablation_no_temp VAL
======================================================================

STANDARD METRICS:
  Precision:        0.4831
  Recall:           0.2773
  F1-Score:         0.3523
  ROC-AUC:          0.9774
  AUPR:             0.2936
  Balanced Acc:     0.6385

IMBALANCED-AWARE METRICS:
  MCC:              0.3655
  Cohen Kappa:      0.3518
  Specificity:      0.9997

THRESHOLD: 0.892

CONFUSION MATRIX:
  True Negatives:   1014280
  False Positives:  321
  False Negatives:  782
  True Positives:   300

TOP-K PRECISION:
  precision_at_100: 0.9000
  precision_at_500: 0.5340
  precision_at_1000: 0.3430
======================================================================
======================================================================
EVALUATION RESULTS: seed2_ablation_no_temp TEST
======================================================================

STANDARD METRICS:
  Precision:        0.3796
  Recall:           0.3651
  F1-Score:         0.3722
  ROC-AUC:          0.9809
  AUPR:             0.3266
  Balanced Acc:     0.6820

IMBALANCED-AWARE METRICS:
  MCC:              0.3712
  Cohen Kappa:      0.3711
  Specificity:      0.9989

THRESHOLD: 0.847

CONFUSION MATRIX:
  True Negatives:   1012814
  False Positives:  1072
  False Negatives:  1141
  True Positives:   656

TOP-K PRECISION:
  precision_at_100: 0.8700
  precision_at_500: 0.6160
  precision_at_1000: 0.4940
======================================================================

Saving results...
  - Saved metrics to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed2_ablation_no_temp\dyrep\metrics.json
  - Saved prediction probabilities
  - Saved experiment config

======================================================================
DyRep-style Training Complete!
Results saved to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed2_ablation_no_temp\dyrep
======================================================================

================================================================================
Logging ended at: 2025-12-03 09:43:12.171805
================================================================================
