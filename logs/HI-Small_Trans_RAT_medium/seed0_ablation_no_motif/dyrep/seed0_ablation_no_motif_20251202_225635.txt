
================================================================================
Logging started at: 2025-12-02 22:56:35.017368
Log file: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed0_ablation_no_motif\dyrep\seed0_ablation_no_motif_20251202_225635.txt
================================================================================

[INFO] Logging to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed0_ablation_no_motif\dyrep\seed0_ablation_no_motif_20251202_225635.txt
================================================================================
EXPERIMENT CONFIG SUMMARY
================================================================================

[DATASET]
  Name:       HI-Small_Trans_RAT_medium
  Theory:     RAT
  Intensity:  medium

[MODEL]
  DyRep
  Hidden dim: 128

[PATHS]
  Graphs:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs\HI-Small_Trans_RAT_medium
  Splits:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits\HI-Small_Trans_RAT_medium
  Results:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed0_ablation_no_motif\dyrep
  Logs:       C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed0_ablation_no_motif\dyrep
================================================================================

[DEVICE] cuda

[INFO] Using default graph directory: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs_dyrep\HI-Small_Trans_RAT_medium__no_motif

======= DYREP-STYLE EVENT MODEL TRAINING (FP32) =======
Graph folder:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs_dyrep\HI-Small_Trans_RAT_medium__no_motif
Splits folder:   C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits_dyrep\HI-Small_Trans_RAT_medium
Results folder:  C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed0_ablation_no_motif\dyrep
Batch size:      8192
Eval batch size: 16384
Device:          cuda
=======================================================

Num nodes:        515,080
Num events/edges: 5,078,415
Node feat dim:    12
Edge feat dim:    54
Event types:      7

Split sizes:
  Train: 3,047,049
  Val:   1,015,683
  Test:  1,015,683

pos_weight (train) = 100.000

Starting training for up to 350 epochs...

Epoch 001 | train_loss=14.1077 val_loss=0.8869 P=0.040 R=0.424 F1=0.073 ROC-AUC=0.787 AUPR=0.027 time=20.97s
Epoch 002 | train_loss=1.0297 val_loss=0.7213 P=0.101 R=0.181 F1=0.130 ROC-AUC=0.862 AUPR=0.067 time=21.43s
Epoch 003 | train_loss=0.7113 val_loss=0.1997 P=0.085 R=0.287 F1=0.131 ROC-AUC=0.927 AUPR=0.050 time=21.97s
Epoch 004 | train_loss=0.8052 val_loss=0.1872 P=0.116 R=0.156 F1=0.133 ROC-AUC=0.935 AUPR=0.048 time=21.90s
Epoch 005 | train_loss=0.5253 val_loss=0.1636 P=0.124 R=0.175 F1=0.145 ROC-AUC=0.951 AUPR=0.067 time=21.89s
Epoch 006 | train_loss=0.5968 val_loss=0.1599 P=0.108 R=0.259 F1=0.152 ROC-AUC=0.955 AUPR=0.065 time=21.48s
Epoch 007 | train_loss=0.5389 val_loss=0.9404 P=0.159 R=0.240 F1=0.191 ROC-AUC=0.870 AUPR=0.107 time=21.82s
Epoch 008 | train_loss=0.5150 val_loss=1.4257 P=0.135 R=0.232 F1=0.171 ROC-AUC=0.864 AUPR=0.079 time=21.77s
Epoch 009 | train_loss=0.6505 val_loss=2.6510 P=0.198 R=0.155 F1=0.174 ROC-AUC=0.863 AUPR=0.101 time=21.55s
Epoch 010 | train_loss=0.4257 val_loss=0.1283 P=0.193 R=0.204 F1=0.198 ROC-AUC=0.975 AUPR=0.104 time=22.10s
Epoch 011 | train_loss=0.3288 val_loss=0.1253 P=0.244 R=0.207 F1=0.224 ROC-AUC=0.976 AUPR=0.143 time=21.85s
Epoch 012 | train_loss=0.3248 val_loss=0.1225 P=0.188 R=0.233 F1=0.208 ROC-AUC=0.976 AUPR=0.128 time=22.03s
Epoch 013 | train_loss=0.3389 val_loss=0.1596 P=0.143 R=0.195 F1=0.165 ROC-AUC=0.960 AUPR=0.085 time=21.76s
Epoch 014 | train_loss=0.1962 val_loss=0.1178 P=0.287 R=0.230 F1=0.255 ROC-AUC=0.978 AUPR=0.184 time=21.98s
Epoch 015 | train_loss=0.4155 val_loss=1.1370 P=0.206 R=0.240 F1=0.222 ROC-AUC=0.869 AUPR=0.140 time=21.69s
Epoch 016 | train_loss=0.1708 val_loss=0.1155 P=0.265 R=0.226 F1=0.244 ROC-AUC=0.978 AUPR=0.152 time=21.85s
Epoch 017 | train_loss=0.2879 val_loss=0.1258 P=0.201 R=0.242 F1=0.220 ROC-AUC=0.975 AUPR=0.136 time=21.83s
Epoch 018 | train_loss=0.2669 val_loss=0.1165 P=0.243 R=0.220 F1=0.231 ROC-AUC=0.978 AUPR=0.167 time=21.88s
Epoch 019 | train_loss=0.2695 val_loss=0.1143 P=0.225 R=0.258 F1=0.240 ROC-AUC=0.978 AUPR=0.165 time=21.74s
Epoch 020 | train_loss=0.1880 val_loss=2.7957 P=0.219 R=0.274 F1=0.243 ROC-AUC=0.867 AUPR=0.152 time=21.66s
Epoch 021 | train_loss=0.3186 val_loss=0.1167 P=0.225 R=0.265 F1=0.244 ROC-AUC=0.978 AUPR=0.170 time=21.85s
Epoch 022 | train_loss=0.1972 val_loss=0.1137 P=0.212 R=0.277 F1=0.240 ROC-AUC=0.981 AUPR=0.172 time=22.65s
Epoch 023 | train_loss=0.1337 val_loss=0.1147 P=0.245 R=0.258 F1=0.251 ROC-AUC=0.978 AUPR=0.172 time=22.37s
Epoch 024 | train_loss=0.1490 val_loss=0.1070 P=0.265 R=0.282 F1=0.273 ROC-AUC=0.982 AUPR=0.209 time=23.06s
Epoch 025 | train_loss=0.1485 val_loss=0.1125 P=0.299 R=0.238 F1=0.265 ROC-AUC=0.980 AUPR=0.195 time=21.63s
Epoch 026 | train_loss=0.1542 val_loss=0.1105 P=0.267 R=0.237 F1=0.251 ROC-AUC=0.979 AUPR=0.183 time=22.02s
Epoch 027 | train_loss=0.1325 val_loss=0.1044 P=0.314 R=0.251 F1=0.279 ROC-AUC=0.982 AUPR=0.213 time=21.69s
Epoch 028 | train_loss=0.1591 val_loss=0.1028 P=0.224 R=0.283 F1=0.250 ROC-AUC=0.982 AUPR=0.185 time=21.94s
Epoch 029 | train_loss=0.1556 val_loss=0.1128 P=0.229 R=0.310 F1=0.263 ROC-AUC=0.981 AUPR=0.204 time=21.74s
Epoch 030 | train_loss=0.1568 val_loss=0.1038 P=0.301 R=0.275 F1=0.288 ROC-AUC=0.982 AUPR=0.228 time=21.65s
Epoch 031 | train_loss=0.1221 val_loss=0.1210 P=0.190 R=0.295 F1=0.231 ROC-AUC=0.979 AUPR=0.176 time=21.77s
Epoch 032 | train_loss=0.1057 val_loss=0.1097 P=0.263 R=0.285 F1=0.274 ROC-AUC=0.982 AUPR=0.204 time=22.05s
Epoch 033 | train_loss=0.1037 val_loss=0.1119 P=0.258 R=0.262 F1=0.260 ROC-AUC=0.979 AUPR=0.177 time=22.16s
Epoch 034 | train_loss=0.2497 val_loss=0.1079 P=0.279 R=0.226 F1=0.250 ROC-AUC=0.981 AUPR=0.181 time=21.82s
Epoch 035 | train_loss=0.1162 val_loss=0.1073 P=0.324 R=0.275 F1=0.298 ROC-AUC=0.982 AUPR=0.233 time=21.81s
Epoch 036 | train_loss=0.1002 val_loss=0.1007 P=0.356 R=0.282 F1=0.315 ROC-AUC=0.983 AUPR=0.258 time=21.85s
Epoch 037 | train_loss=0.1266 val_loss=0.1076 P=0.367 R=0.271 F1=0.312 ROC-AUC=0.982 AUPR=0.250 time=21.63s
Epoch 038 | train_loss=0.1308 val_loss=0.1028 P=0.269 R=0.262 F1=0.265 ROC-AUC=0.983 AUPR=0.201 time=22.04s
Epoch 039 | train_loss=0.1331 val_loss=0.1132 P=0.220 R=0.298 F1=0.253 ROC-AUC=0.979 AUPR=0.192 time=22.45s
Epoch 040 | train_loss=0.1237 val_loss=0.1068 P=0.267 R=0.270 F1=0.269 ROC-AUC=0.982 AUPR=0.206 time=21.75s
Epoch 041 | train_loss=0.1003 val_loss=0.1047 P=0.249 R=0.303 F1=0.274 ROC-AUC=0.982 AUPR=0.223 time=21.52s
Epoch 042 | train_loss=0.1023 val_loss=0.0981 P=0.385 R=0.274 F1=0.321 ROC-AUC=0.983 AUPR=0.268 time=22.14s
Epoch 043 | train_loss=0.1131 val_loss=0.1000 P=0.365 R=0.275 F1=0.314 ROC-AUC=0.983 AUPR=0.254 time=21.44s
Epoch 044 | train_loss=0.0835 val_loss=0.1057 P=0.353 R=0.281 F1=0.313 ROC-AUC=0.982 AUPR=0.258 time=21.85s
Epoch 045 | train_loss=0.1086 val_loss=0.1091 P=0.294 R=0.232 F1=0.259 ROC-AUC=0.981 AUPR=0.204 time=21.72s
Epoch 046 | train_loss=0.1817 val_loss=0.1136 P=0.221 R=0.317 F1=0.261 ROC-AUC=0.980 AUPR=0.208 time=21.83s
Epoch 047 | train_loss=0.0912 val_loss=0.1109 P=0.314 R=0.280 F1=0.296 ROC-AUC=0.981 AUPR=0.236 time=22.23s
Epoch 048 | train_loss=0.1904 val_loss=0.1068 P=0.243 R=0.267 F1=0.254 ROC-AUC=0.981 AUPR=0.209 time=21.81s
Epoch 049 | train_loss=0.0886 val_loss=0.1134 P=0.349 R=0.262 F1=0.299 ROC-AUC=0.980 AUPR=0.246 time=21.38s
Epoch 050 | train_loss=0.1140 val_loss=0.1006 P=0.355 R=0.276 F1=0.311 ROC-AUC=0.983 AUPR=0.266 time=21.81s
Epoch 051 | train_loss=0.1641 val_loss=0.1020 P=0.327 R=0.295 F1=0.310 ROC-AUC=0.982 AUPR=0.261 time=22.16s
Epoch 052 | train_loss=0.0961 val_loss=0.1071 P=0.285 R=0.322 F1=0.302 ROC-AUC=0.982 AUPR=0.260 time=21.72s
Epoch 053 | train_loss=0.1096 val_loss=0.0963 P=0.410 R=0.285 F1=0.336 ROC-AUC=0.984 AUPR=0.293 time=21.88s
Epoch 054 | train_loss=0.0790 val_loss=0.1062 P=0.357 R=0.238 F1=0.286 ROC-AUC=0.982 AUPR=0.245 time=20.98s
Epoch 055 | train_loss=0.1194 val_loss=0.2144 P=0.314 R=0.280 F1=0.296 ROC-AUC=0.966 AUPR=0.241 time=21.54s
Epoch 056 | train_loss=0.0790 val_loss=0.1113 P=0.345 R=0.247 F1=0.288 ROC-AUC=0.980 AUPR=0.249 time=21.70s
Epoch 057 | train_loss=0.1053 val_loss=0.1100 P=0.253 R=0.309 F1=0.278 ROC-AUC=0.981 AUPR=0.250 time=21.54s
Epoch 058 | train_loss=0.0829 val_loss=0.1008 P=0.348 R=0.277 F1=0.308 ROC-AUC=0.982 AUPR=0.277 time=21.70s
Epoch 059 | train_loss=0.1600 val_loss=0.1036 P=0.382 R=0.297 F1=0.334 ROC-AUC=0.983 AUPR=0.302 time=21.31s
Epoch 060 | train_loss=0.1014 val_loss=0.0985 P=0.311 R=0.299 F1=0.304 ROC-AUC=0.983 AUPR=0.271 time=20.98s
Epoch 061 | train_loss=0.0845 val_loss=0.1049 P=0.360 R=0.295 F1=0.324 ROC-AUC=0.981 AUPR=0.295 time=21.55s
Epoch 062 | train_loss=0.1687 val_loss=0.1061 P=0.372 R=0.283 F1=0.321 ROC-AUC=0.982 AUPR=0.286 time=21.85s
Epoch 063 | train_loss=0.0736 val_loss=0.1253 P=0.326 R=0.250 F1=0.283 ROC-AUC=0.977 AUPR=0.247 time=21.58s
Epoch 064 | train_loss=0.0951 val_loss=0.1014 P=0.440 R=0.252 F1=0.321 ROC-AUC=0.982 AUPR=0.292 time=21.73s
Epoch 065 | train_loss=0.1167 val_loss=0.1174 P=0.275 R=0.249 F1=0.261 ROC-AUC=0.979 AUPR=0.234 time=21.86s
Epoch 066 | train_loss=0.1328 val_loss=0.1027 P=0.415 R=0.241 F1=0.305 ROC-AUC=0.982 AUPR=0.281 time=21.93s
Epoch 067 | train_loss=0.0932 val_loss=0.1275 P=0.332 R=0.232 F1=0.273 ROC-AUC=0.977 AUPR=0.240 time=21.73s
Epoch 068 | train_loss=0.1971 val_loss=2.5645 P=0.292 R=0.271 F1=0.281 ROC-AUC=0.874 AUPR=0.249 time=21.49s
Epoch 069 | train_loss=0.1289 val_loss=0.1426 P=0.314 R=0.274 F1=0.292 ROC-AUC=0.973 AUPR=0.255 time=21.63s
Epoch 070 | train_loss=0.0858 val_loss=0.0990 P=0.458 R=0.304 F1=0.366 ROC-AUC=0.983 AUPR=0.340 time=21.83s
Epoch 071 | train_loss=0.0834 val_loss=0.1123 P=0.412 R=0.296 F1=0.344 ROC-AUC=0.980 AUPR=0.308 time=21.83s
Epoch 072 | train_loss=0.0854 val_loss=0.1187 P=0.371 R=0.294 F1=0.328 ROC-AUC=0.978 AUPR=0.299 time=22.00s
Epoch 073 | train_loss=0.0664 val_loss=0.1239 P=0.373 R=0.270 F1=0.313 ROC-AUC=0.977 AUPR=0.279 time=21.88s
Epoch 074 | train_loss=0.1887 val_loss=0.1145 P=0.367 R=0.325 F1=0.345 ROC-AUC=0.979 AUPR=0.315 time=21.67s
Epoch 075 | train_loss=0.0656 val_loss=0.1162 P=0.409 R=0.294 F1=0.342 ROC-AUC=0.978 AUPR=0.323 time=21.99s
Epoch 076 | train_loss=0.0624 val_loss=0.1125 P=0.305 R=0.293 F1=0.299 ROC-AUC=0.979 AUPR=0.270 time=21.95s
Epoch 077 | train_loss=0.1088 val_loss=0.1332 P=0.336 R=0.303 F1=0.319 ROC-AUC=0.975 AUPR=0.279 time=21.21s
Epoch 078 | train_loss=0.0852 val_loss=0.1634 P=0.314 R=0.259 F1=0.284 ROC-AUC=0.969 AUPR=0.237 time=21.29s
Epoch 079 | train_loss=0.1468 val_loss=0.1086 P=0.392 R=0.291 F1=0.334 ROC-AUC=0.980 AUPR=0.305 time=22.24s
Epoch 080 | train_loss=0.0701 val_loss=0.1271 P=0.430 R=0.296 F1=0.350 ROC-AUC=0.976 AUPR=0.319 time=22.81s
Epoch 081 | train_loss=0.2626 val_loss=0.1309 P=0.319 R=0.315 F1=0.317 ROC-AUC=0.975 AUPR=0.288 time=22.08s
Epoch 082 | train_loss=0.0610 val_loss=0.1112 P=0.414 R=0.318 F1=0.360 ROC-AUC=0.980 AUPR=0.323 time=21.99s
Epoch 083 | train_loss=0.1066 val_loss=0.1117 P=0.388 R=0.299 F1=0.338 ROC-AUC=0.980 AUPR=0.311 time=22.18s
Epoch 084 | train_loss=0.1077 val_loss=0.1211 P=0.362 R=0.335 F1=0.348 ROC-AUC=0.978 AUPR=0.320 time=22.18s
Epoch 085 | train_loss=0.1352 val_loss=0.1377 P=0.314 R=0.315 F1=0.314 ROC-AUC=0.974 AUPR=0.283 time=21.72s

Early stopping at epoch 85 (no val AUPR improvement for 15 epochs)

Total training time: 1863.56s (31.1 min)

Loading best model from epoch 70...
Evaluating final model on train/val/test...
======================================================================
EVALUATION RESULTS: seed0_ablation_no_motif TRAIN
======================================================================

STANDARD METRICS:
  Precision:        0.4105
  Recall:           0.3873
  F1-Score:         0.3986
  ROC-AUC:          0.9895
  AUPR:             0.3902
  Balanced Acc:     0.6934

IMBALANCED-AWARE METRICS:
  MCC:              0.3983
  Cohen Kappa:      0.3981
  Specificity:      0.9996

THRESHOLD: 0.946

CONFUSION MATRIX:
  True Negatives:   3043473
  False Positives:  1278
  False Negatives:  1408
  True Positives:   890

TOP-K PRECISION:
  precision_at_100: 0.9800
  precision_at_500: 0.7860
  precision_at_1000: 0.6050
======================================================================
======================================================================
EVALUATION RESULTS: seed0_ablation_no_motif VAL
======================================================================

STANDARD METRICS:
  Precision:        0.4582
  Recall:           0.3041
  F1-Score:         0.3656
  ROC-AUC:          0.9832
  AUPR:             0.3404
  Balanced Acc:     0.6518

IMBALANCED-AWARE METRICS:
  MCC:              0.3727
  Cohen Kappa:      0.3650
  Specificity:      0.9996

THRESHOLD: 0.951

CONFUSION MATRIX:
  True Negatives:   1014212
  False Positives:  389
  False Negatives:  753
  True Positives:   329

TOP-K PRECISION:
  precision_at_100: 0.9400
  precision_at_500: 0.5760
  precision_at_1000: 0.3680
======================================================================
======================================================================
EVALUATION RESULTS: seed0_ablation_no_motif TEST
======================================================================

STANDARD METRICS:
  Precision:        0.5000
  Recall:           0.4073
  F1-Score:         0.4489
  ROC-AUC:          0.9844
  AUPR:             0.4424
  Balanced Acc:     0.7033

IMBALANCED-AWARE METRICS:
  MCC:              0.4504
  Cohen Kappa:      0.4481
  Specificity:      0.9993

THRESHOLD: 0.936

CONFUSION MATRIX:
  True Negatives:   1013154
  False Positives:  732
  False Negatives:  1065
  True Positives:   732

TOP-K PRECISION:
  precision_at_100: 0.9800
  precision_at_500: 0.8120
  precision_at_1000: 0.6080
======================================================================

Saving results...
  - Saved metrics to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed0_ablation_no_motif\dyrep\metrics.json
  - Saved prediction probabilities
  - Saved experiment config

======================================================================
DyRep-style Training Complete!
Results saved to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed0_ablation_no_motif\dyrep
======================================================================

================================================================================
Logging ended at: 2025-12-02 23:28:49.127144
================================================================================
