
================================================================================
Logging started at: 2025-12-01 09:56:30.549784
Log file: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed2025_experiment_3\graphsage-t\seed2025_experiment_3_20251201_095630.txt
================================================================================

[INFO] Logging to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed2025_experiment_3\graphsage-t\seed2025_experiment_3_20251201_095630.txt
================================================================================
EXPERIMENT CONFIG SUMMARY
================================================================================

[DATASET]
  Name:       HI-Small_Trans_RAT_medium
  Theory:     RAT
  Intensity:  medium

[MODEL]
  GraphSAGE-T
  Hidden dim: 128

[PATHS]
  Graphs:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs\HI-Small_Trans_RAT_medium
  Splits:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits\HI-Small_Trans_RAT_medium
  Results:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed2025_experiment_3\graphsage-t
  Logs:       C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed2025_experiment_3\graphsage-t
================================================================================

[DEVICE] cuda


======= GRAPHSAGE-T TRAINING (FP32) =======
Batch size:       8192
Eval batch size:  16384
Device:           cuda
===========================================


Starting training for 350 epochs...

Epoch 001 | train_loss=15.3112 val_loss=0.4386 P=0.002 R=0.306 F1=0.004 ROC-AUC=0.616 AUPR=0.001 time=49.09s
Epoch 002 | train_loss=0.5185 val_loss=0.3543 P=0.002 R=0.158 F1=0.004 ROC-AUC=0.691 AUPR=0.002 time=49.17s
Epoch 003 | train_loss=0.4252 val_loss=0.3617 P=0.033 R=0.120 F1=0.052 ROC-AUC=0.733 AUPR=0.009 time=49.01s
Epoch 004 | train_loss=0.4081 val_loss=0.3361 P=0.063 R=0.109 F1=0.080 ROC-AUC=0.769 AUPR=0.019 time=49.24s
Epoch 005 | train_loss=0.3539 val_loss=0.2862 P=0.067 R=0.119 F1=0.085 ROC-AUC=0.810 AUPR=0.023 time=49.29s
Epoch 006 | train_loss=0.3464 val_loss=0.2745 P=0.077 R=0.126 F1=0.095 ROC-AUC=0.813 AUPR=0.027 time=49.02s
Epoch 007 | train_loss=0.3290 val_loss=0.2703 P=0.095 R=0.147 F1=0.115 ROC-AUC=0.818 AUPR=0.032 time=49.93s
Epoch 008 | train_loss=0.3419 val_loss=0.2550 P=0.086 R=0.144 F1=0.108 ROC-AUC=0.840 AUPR=0.035 time=50.43s
Epoch 009 | train_loss=0.2931 val_loss=0.2453 P=0.104 R=0.145 F1=0.121 ROC-AUC=0.856 AUPR=0.041 time=50.35s
Epoch 010 | train_loss=0.2918 val_loss=0.2355 P=0.099 R=0.177 F1=0.127 ROC-AUC=0.868 AUPR=0.045 time=50.07s
Epoch 011 | train_loss=0.2983 val_loss=0.1610 P=0.270 R=0.185 F1=0.220 ROC-AUC=0.950 AUPR=0.133 time=50.12s
Epoch 012 | train_loss=0.2602 val_loss=0.1255 P=0.238 R=0.284 F1=0.259 ROC-AUC=0.972 AUPR=0.175 time=50.34s
Epoch 013 | train_loss=0.1716 val_loss=0.1397 P=0.287 R=0.268 F1=0.278 ROC-AUC=0.947 AUPR=0.195 time=48.79s
Epoch 014 | train_loss=0.1953 val_loss=0.1328 P=0.243 R=0.320 F1=0.277 ROC-AUC=0.958 AUPR=0.194 time=48.95s
Epoch 015 | train_loss=0.1766 val_loss=0.1159 P=0.312 R=0.275 F1=0.292 ROC-AUC=0.976 AUPR=0.211 time=49.03s
Epoch 016 | train_loss=0.1516 val_loss=0.1082 P=0.322 R=0.326 F1=0.324 ROC-AUC=0.979 AUPR=0.232 time=48.78s
Epoch 017 | train_loss=0.1476 val_loss=0.1043 P=0.317 R=0.334 F1=0.325 ROC-AUC=0.980 AUPR=0.227 time=48.99s
Epoch 018 | train_loss=0.1321 val_loss=0.1024 P=0.328 R=0.316 F1=0.322 ROC-AUC=0.981 AUPR=0.241 time=49.03s
Epoch 019 | train_loss=0.1578 val_loss=0.1135 P=0.295 R=0.360 F1=0.324 ROC-AUC=0.973 AUPR=0.234 time=49.03s
Epoch 020 | train_loss=0.3341 val_loss=0.1097 P=0.297 R=0.315 F1=0.306 ROC-AUC=0.978 AUPR=0.216 time=48.89s
Epoch 021 | train_loss=0.1265 val_loss=0.1062 P=0.326 R=0.332 F1=0.329 ROC-AUC=0.979 AUPR=0.240 time=48.76s
Epoch 022 | train_loss=0.1336 val_loss=0.3959 P=0.291 R=0.296 F1=0.293 ROC-AUC=0.892 AUPR=0.208 time=48.82s
Epoch 023 | train_loss=0.1101 val_loss=0.1027 P=0.292 R=0.376 F1=0.329 ROC-AUC=0.981 AUPR=0.247 time=48.95s
Epoch 024 | train_loss=0.1180 val_loss=0.1020 P=0.378 R=0.301 F1=0.335 ROC-AUC=0.981 AUPR=0.258 time=49.02s
Epoch 025 | train_loss=0.1435 val_loss=0.1253 P=0.295 R=0.362 F1=0.325 ROC-AUC=0.967 AUPR=0.251 time=48.80s
Epoch 026 | train_loss=0.1520 val_loss=0.0997 P=0.322 R=0.366 F1=0.343 ROC-AUC=0.982 AUPR=0.262 time=49.00s
Epoch 027 | train_loss=0.1071 val_loss=0.0982 P=0.334 R=0.365 F1=0.349 ROC-AUC=0.982 AUPR=0.279 time=49.04s
Epoch 028 | train_loss=0.1022 val_loss=0.0975 P=0.353 R=0.339 F1=0.346 ROC-AUC=0.982 AUPR=0.270 time=48.88s
Epoch 029 | train_loss=0.1021 val_loss=0.0975 P=0.370 R=0.344 F1=0.356 ROC-AUC=0.982 AUPR=0.271 time=48.90s
Epoch 030 | train_loss=0.1672 val_loss=0.0967 P=0.365 R=0.327 F1=0.345 ROC-AUC=0.982 AUPR=0.270 time=49.20s
Epoch 031 | train_loss=0.1256 val_loss=0.1006 P=0.326 R=0.383 F1=0.352 ROC-AUC=0.981 AUPR=0.275 time=48.99s
Epoch 032 | train_loss=0.1046 val_loss=0.0958 P=0.376 R=0.352 F1=0.364 ROC-AUC=0.983 AUPR=0.291 time=48.71s
Epoch 033 | train_loss=0.1548 val_loss=0.0972 P=0.383 R=0.343 F1=0.362 ROC-AUC=0.983 AUPR=0.287 time=48.93s
Epoch 034 | train_loss=0.1070 val_loss=0.0964 P=0.387 R=0.348 F1=0.367 ROC-AUC=0.983 AUPR=0.291 time=48.86s
Epoch 035 | train_loss=0.1390 val_loss=0.0947 P=0.344 R=0.391 F1=0.366 ROC-AUC=0.983 AUPR=0.296 time=49.03s
Epoch 036 | train_loss=0.0992 val_loss=0.0939 P=0.353 R=0.394 F1=0.372 ROC-AUC=0.984 AUPR=0.308 time=49.19s
Epoch 037 | train_loss=0.1059 val_loss=0.0950 P=0.406 R=0.333 F1=0.366 ROC-AUC=0.983 AUPR=0.296 time=49.18s
Epoch 038 | train_loss=0.1101 val_loss=0.0935 P=0.402 R=0.343 F1=0.370 ROC-AUC=0.983 AUPR=0.298 time=49.08s
Epoch 039 | train_loss=0.1242 val_loss=0.0935 P=0.369 R=0.391 F1=0.379 ROC-AUC=0.983 AUPR=0.309 time=48.84s
Epoch 040 | train_loss=0.1747 val_loss=0.2834 P=0.392 R=0.325 F1=0.356 ROC-AUC=0.911 AUPR=0.276 time=48.86s
Epoch 041 | train_loss=0.1400 val_loss=0.0954 P=0.419 R=0.363 F1=0.389 ROC-AUC=0.983 AUPR=0.325 time=48.98s
Epoch 042 | train_loss=0.0995 val_loss=0.0935 P=0.422 R=0.355 F1=0.386 ROC-AUC=0.984 AUPR=0.326 time=48.84s
Epoch 043 | train_loss=0.1324 val_loss=0.0948 P=0.446 R=0.346 F1=0.389 ROC-AUC=0.983 AUPR=0.329 time=48.87s
Epoch 044 | train_loss=0.1294 val_loss=0.0930 P=0.473 R=0.338 F1=0.394 ROC-AUC=0.984 AUPR=0.337 time=49.10s
Epoch 045 | train_loss=0.1018 val_loss=0.0955 P=0.397 R=0.386 F1=0.392 ROC-AUC=0.983 AUPR=0.326 time=48.86s
Epoch 046 | train_loss=0.1002 val_loss=0.0929 P=0.388 R=0.406 F1=0.397 ROC-AUC=0.984 AUPR=0.331 time=49.28s
Epoch 047 | train_loss=0.1077 val_loss=0.0919 P=0.365 R=0.415 F1=0.389 ROC-AUC=0.984 AUPR=0.336 time=48.76s
Epoch 048 | train_loss=0.1057 val_loss=1.6342 P=0.394 R=0.400 F1=0.397 ROC-AUC=0.881 AUPR=0.331 time=48.69s
Epoch 049 | train_loss=0.1133 val_loss=0.1250 P=0.433 R=0.370 F1=0.399 ROC-AUC=0.971 AUPR=0.332 time=48.92s
Epoch 050 | train_loss=0.1308 val_loss=0.0919 P=0.422 R=0.367 F1=0.393 ROC-AUC=0.984 AUPR=0.339 time=49.05s
Epoch 051 | train_loss=0.0955 val_loss=0.0933 P=0.472 R=0.332 F1=0.390 ROC-AUC=0.984 AUPR=0.342 time=49.05s
Epoch 052 | train_loss=0.0980 val_loss=0.0923 P=0.432 R=0.345 F1=0.383 ROC-AUC=0.984 AUPR=0.326 time=49.06s
Epoch 053 | train_loss=0.1072 val_loss=0.0910 P=0.423 R=0.388 F1=0.405 ROC-AUC=0.984 AUPR=0.353 time=48.98s
Epoch 054 | train_loss=0.1244 val_loss=0.0914 P=0.423 R=0.382 F1=0.401 ROC-AUC=0.984 AUPR=0.351 time=48.95s
Epoch 055 | train_loss=0.1888 val_loss=0.0933 P=0.479 R=0.346 F1=0.402 ROC-AUC=0.983 AUPR=0.349 time=48.84s
Epoch 056 | train_loss=0.1154 val_loss=0.0910 P=0.445 R=0.379 F1=0.409 ROC-AUC=0.984 AUPR=0.357 time=48.85s
Epoch 057 | train_loss=0.0999 val_loss=0.0909 P=0.438 R=0.367 F1=0.399 ROC-AUC=0.984 AUPR=0.348 time=49.07s
Epoch 058 | train_loss=0.1029 val_loss=0.0913 P=0.477 R=0.345 F1=0.400 ROC-AUC=0.984 AUPR=0.352 time=48.98s
Epoch 059 | train_loss=0.1206 val_loss=0.0905 P=0.445 R=0.392 F1=0.417 ROC-AUC=0.984 AUPR=0.363 time=48.95s
Epoch 060 | train_loss=0.1494 val_loss=0.0917 P=0.412 R=0.393 F1=0.402 ROC-AUC=0.984 AUPR=0.352 time=48.87s
Epoch 061 | train_loss=0.0957 val_loss=0.0923 P=0.449 R=0.375 F1=0.408 ROC-AUC=0.984 AUPR=0.357 time=48.75s
Epoch 062 | train_loss=0.1005 val_loss=0.0919 P=0.372 R=0.432 F1=0.400 ROC-AUC=0.984 AUPR=0.356 time=48.88s
Epoch 063 | train_loss=0.1151 val_loss=0.0954 P=0.491 R=0.347 F1=0.407 ROC-AUC=0.984 AUPR=0.355 time=48.86s
Epoch 064 | train_loss=0.1005 val_loss=0.0924 P=0.393 R=0.397 F1=0.395 ROC-AUC=0.984 AUPR=0.354 time=49.12s
Epoch 065 | train_loss=0.1258 val_loss=0.1169 P=0.455 R=0.375 F1=0.411 ROC-AUC=0.977 AUPR=0.368 time=48.90s
Epoch 066 | train_loss=0.0919 val_loss=0.0910 P=0.444 R=0.379 F1=0.409 ROC-AUC=0.984 AUPR=0.370 time=48.94s
Epoch 067 | train_loss=0.1268 val_loss=0.0923 P=0.445 R=0.372 F1=0.405 ROC-AUC=0.984 AUPR=0.356 time=49.11s
Epoch 068 | train_loss=0.1015 val_loss=0.0915 P=0.453 R=0.388 F1=0.418 ROC-AUC=0.984 AUPR=0.371 time=49.20s
Epoch 069 | train_loss=0.1016 val_loss=0.0913 P=0.498 R=0.365 F1=0.421 ROC-AUC=0.984 AUPR=0.374 time=48.99s
Epoch 070 | train_loss=0.1530 val_loss=0.0939 P=0.488 R=0.354 F1=0.411 ROC-AUC=0.984 AUPR=0.366 time=48.96s
Epoch 071 | train_loss=0.1011 val_loss=0.0902 P=0.486 R=0.365 F1=0.417 ROC-AUC=0.984 AUPR=0.378 time=49.09s
Epoch 072 | train_loss=0.1197 val_loss=0.0911 P=0.494 R=0.361 F1=0.417 ROC-AUC=0.984 AUPR=0.379 time=48.76s
Epoch 073 | train_loss=0.1034 val_loss=0.0905 P=0.429 R=0.403 F1=0.415 ROC-AUC=0.985 AUPR=0.378 time=48.95s
Epoch 074 | train_loss=0.0953 val_loss=0.0913 P=0.472 R=0.371 F1=0.415 ROC-AUC=0.984 AUPR=0.374 time=49.07s
Epoch 075 | train_loss=0.1027 val_loss=0.0894 P=0.400 R=0.427 F1=0.413 ROC-AUC=0.985 AUPR=0.381 time=49.08s
Epoch 076 | train_loss=0.1139 val_loss=0.0901 P=0.477 R=0.376 F1=0.421 ROC-AUC=0.985 AUPR=0.382 time=48.83s
Epoch 077 | train_loss=0.1037 val_loss=0.0899 P=0.470 R=0.394 F1=0.428 ROC-AUC=0.984 AUPR=0.396 time=48.84s
Epoch 078 | train_loss=0.0923 val_loss=0.0916 P=0.476 R=0.379 F1=0.422 ROC-AUC=0.984 AUPR=0.375 time=48.77s
Epoch 079 | train_loss=0.1450 val_loss=0.0898 P=0.483 R=0.365 F1=0.416 ROC-AUC=0.984 AUPR=0.380 time=49.10s
Epoch 080 | train_loss=0.1015 val_loss=0.0906 P=0.440 R=0.418 F1=0.429 ROC-AUC=0.984 AUPR=0.386 time=48.99s
Epoch 081 | train_loss=0.1018 val_loss=0.0901 P=0.502 R=0.368 F1=0.425 ROC-AUC=0.984 AUPR=0.383 time=49.01s
Epoch 082 | train_loss=0.1670 val_loss=0.0901 P=0.487 R=0.388 F1=0.432 ROC-AUC=0.984 AUPR=0.390 time=48.75s
Epoch 083 | train_loss=0.1535 val_loss=0.0947 P=0.478 R=0.376 F1=0.421 ROC-AUC=0.983 AUPR=0.378 time=48.95s
Epoch 084 | train_loss=0.0933 val_loss=0.0901 P=0.467 R=0.394 F1=0.427 ROC-AUC=0.985 AUPR=0.393 time=49.06s
Epoch 085 | train_loss=0.1130 val_loss=0.0943 P=0.519 R=0.363 F1=0.427 ROC-AUC=0.984 AUPR=0.385 time=48.76s
Epoch 086 | train_loss=0.1087 val_loss=0.1112 P=0.476 R=0.394 F1=0.431 ROC-AUC=0.979 AUPR=0.390 time=48.88s
Epoch 087 | train_loss=0.1393 val_loss=0.0906 P=0.451 R=0.394 F1=0.421 ROC-AUC=0.984 AUPR=0.383 time=48.96s
Epoch 088 | train_loss=0.1435 val_loss=0.0913 P=0.476 R=0.362 F1=0.411 ROC-AUC=0.984 AUPR=0.375 time=49.17s
Epoch 089 | train_loss=0.1033 val_loss=0.0929 P=0.498 R=0.369 F1=0.424 ROC-AUC=0.984 AUPR=0.387 time=48.98s
Epoch 090 | train_loss=0.0965 val_loss=0.0915 P=0.493 R=0.379 F1=0.429 ROC-AUC=0.984 AUPR=0.391 time=49.08s
Epoch 091 | train_loss=0.1616 val_loss=0.0913 P=0.437 R=0.376 F1=0.405 ROC-AUC=0.984 AUPR=0.370 time=48.94s
Epoch 092 | train_loss=0.0959 val_loss=0.0920 P=0.509 R=0.363 F1=0.424 ROC-AUC=0.984 AUPR=0.391 time=48.89s
Epoch 093 | train_loss=0.1367 val_loss=0.0925 P=0.490 R=0.368 F1=0.420 ROC-AUC=0.984 AUPR=0.377 time=48.68s
Epoch 094 | train_loss=0.1691 val_loss=0.1344 P=0.468 R=0.363 F1=0.409 ROC-AUC=0.965 AUPR=0.374 time=49.02s
Epoch 095 | train_loss=0.1110 val_loss=0.0900 P=0.529 R=0.381 F1=0.443 ROC-AUC=0.984 AUPR=0.403 time=49.03s
Epoch 096 | train_loss=0.1164 val_loss=0.0891 P=0.448 R=0.401 F1=0.423 ROC-AUC=0.985 AUPR=0.383 time=49.01s
Epoch 097 | train_loss=0.1607 val_loss=0.0947 P=0.472 R=0.387 F1=0.425 ROC-AUC=0.984 AUPR=0.391 time=48.97s
Epoch 098 | train_loss=0.1139 val_loss=0.0873 P=0.519 R=0.386 F1=0.443 ROC-AUC=0.985 AUPR=0.408 time=48.65s
Epoch 099 | train_loss=0.1069 val_loss=0.0871 P=0.514 R=0.402 F1=0.451 ROC-AUC=0.985 AUPR=0.420 time=48.80s
Epoch 100 | train_loss=0.1021 val_loss=0.1019 P=0.530 R=0.397 F1=0.454 ROC-AUC=0.983 AUPR=0.419 time=48.56s
Epoch 101 | train_loss=0.1177 val_loss=0.0862 P=0.531 R=0.394 F1=0.452 ROC-AUC=0.985 AUPR=0.424 time=48.96s
Epoch 102 | train_loss=0.1037 val_loss=0.0874 P=0.533 R=0.386 F1=0.448 ROC-AUC=0.985 AUPR=0.416 time=48.97s
Epoch 103 | train_loss=0.1197 val_loss=0.0886 P=0.504 R=0.414 F1=0.455 ROC-AUC=0.985 AUPR=0.422 time=49.01s
Epoch 104 | train_loss=0.1115 val_loss=0.0885 P=0.547 R=0.377 F1=0.447 ROC-AUC=0.985 AUPR=0.418 time=48.88s
Epoch 105 | train_loss=0.1106 val_loss=0.0873 P=0.529 R=0.382 F1=0.444 ROC-AUC=0.985 AUPR=0.419 time=48.99s
Epoch 106 | train_loss=0.1093 val_loss=0.0872 P=0.593 R=0.386 F1=0.468 ROC-AUC=0.985 AUPR=0.434 time=48.78s
Epoch 107 | train_loss=0.1002 val_loss=0.0872 P=0.548 R=0.402 F1=0.464 ROC-AUC=0.985 AUPR=0.433 time=48.75s
Epoch 108 | train_loss=0.1020 val_loss=0.0896 P=0.586 R=0.368 F1=0.452 ROC-AUC=0.985 AUPR=0.430 time=48.92s
Epoch 109 | train_loss=0.0928 val_loss=0.0869 P=0.586 R=0.390 F1=0.468 ROC-AUC=0.985 AUPR=0.443 time=48.97s
Epoch 110 | train_loss=0.0962 val_loss=0.0866 P=0.508 R=0.442 F1=0.473 ROC-AUC=0.985 AUPR=0.450 time=49.05s
Epoch 111 | train_loss=0.0891 val_loss=0.0881 P=0.607 R=0.367 F1=0.457 ROC-AUC=0.985 AUPR=0.431 time=48.93s
Epoch 112 | train_loss=0.1041 val_loss=0.0871 P=0.604 R=0.364 F1=0.454 ROC-AUC=0.985 AUPR=0.434 time=48.97s
Epoch 113 | train_loss=0.1376 val_loss=0.0872 P=0.506 R=0.417 F1=0.457 ROC-AUC=0.985 AUPR=0.433 time=48.71s
Epoch 114 | train_loss=0.1033 val_loss=0.0935 P=0.578 R=0.388 F1=0.464 ROC-AUC=0.985 AUPR=0.434 time=48.58s
Epoch 115 | train_loss=0.0947 val_loss=0.0903 P=0.579 R=0.385 F1=0.463 ROC-AUC=0.985 AUPR=0.433 time=48.89s
Epoch 116 | train_loss=0.1010 val_loss=0.0871 P=0.498 R=0.427 F1=0.459 ROC-AUC=0.985 AUPR=0.438 time=48.99s
Epoch 117 | train_loss=0.1260 val_loss=0.0855 P=0.579 R=0.396 F1=0.470 ROC-AUC=0.986 AUPR=0.448 time=49.10s
Epoch 118 | train_loss=0.1039 val_loss=0.2546 P=0.572 R=0.353 F1=0.437 ROC-AUC=0.921 AUPR=0.400 time=48.90s
Epoch 119 | train_loss=0.1016 val_loss=0.0875 P=0.610 R=0.397 F1=0.481 ROC-AUC=0.986 AUPR=0.458 time=49.04s
Epoch 120 | train_loss=0.1087 val_loss=0.0851 P=0.528 R=0.433 F1=0.476 ROC-AUC=0.986 AUPR=0.454 time=49.45s
Epoch 121 | train_loss=0.1046 val_loss=0.0856 P=0.544 R=0.424 F1=0.476 ROC-AUC=0.986 AUPR=0.433 time=50.26s
Epoch 122 | train_loss=0.0961 val_loss=0.0876 P=0.544 R=0.410 F1=0.468 ROC-AUC=0.985 AUPR=0.445 time=49.39s
Epoch 123 | train_loss=0.1281 val_loss=0.0880 P=0.514 R=0.415 F1=0.459 ROC-AUC=0.985 AUPR=0.429 time=49.79s
Epoch 124 | train_loss=0.0898 val_loss=0.0905 P=0.629 R=0.364 F1=0.461 ROC-AUC=0.986 AUPR=0.436 time=49.56s
Epoch 125 | train_loss=0.0951 val_loss=0.0859 P=0.556 R=0.422 F1=0.480 ROC-AUC=0.986 AUPR=0.450 time=49.78s
Epoch 126 | train_loss=0.1042 val_loss=0.0872 P=0.503 R=0.419 F1=0.457 ROC-AUC=0.985 AUPR=0.437 time=49.93s
Epoch 127 | train_loss=0.0850 val_loss=0.0870 P=0.616 R=0.374 F1=0.465 ROC-AUC=0.986 AUPR=0.443 time=50.13s
Epoch 128 | train_loss=0.0882 val_loss=0.0860 P=0.611 R=0.376 F1=0.466 ROC-AUC=0.986 AUPR=0.443 time=48.79s
Epoch 129 | train_loss=0.0932 val_loss=0.0856 P=0.553 R=0.432 F1=0.485 ROC-AUC=0.986 AUPR=0.458 time=49.09s
Epoch 130 | train_loss=0.1137 val_loss=0.0855 P=0.623 R=0.386 F1=0.477 ROC-AUC=0.986 AUPR=0.452 time=48.57s
Epoch 131 | train_loss=0.1024 val_loss=0.0862 P=0.571 R=0.405 F1=0.474 ROC-AUC=0.986 AUPR=0.452 time=48.89s
Epoch 132 | train_loss=0.1470 val_loss=0.0902 P=0.567 R=0.387 F1=0.460 ROC-AUC=0.985 AUPR=0.436 time=48.89s
Epoch 133 | train_loss=0.0892 val_loss=0.0879 P=0.575 R=0.380 F1=0.458 ROC-AUC=0.985 AUPR=0.430 time=48.90s
Epoch 134 | train_loss=0.1336 val_loss=0.0884 P=0.549 R=0.425 F1=0.479 ROC-AUC=0.985 AUPR=0.445 time=49.11s
Epoch 135 | train_loss=0.1141 val_loss=0.0871 P=0.537 R=0.434 F1=0.480 ROC-AUC=0.986 AUPR=0.446 time=48.89s
Epoch 136 | train_loss=0.0917 val_loss=0.0868 P=0.624 R=0.391 F1=0.481 ROC-AUC=0.985 AUPR=0.459 time=49.16s
Epoch 137 | train_loss=0.1043 val_loss=0.0849 P=0.604 R=0.416 F1=0.493 ROC-AUC=0.986 AUPR=0.461 time=49.89s
Epoch 138 | train_loss=0.1089 val_loss=0.0886 P=0.518 R=0.441 F1=0.476 ROC-AUC=0.985 AUPR=0.452 time=50.21s
Epoch 139 | train_loss=0.0854 val_loss=0.0879 P=0.547 R=0.441 F1=0.489 ROC-AUC=0.986 AUPR=0.462 time=50.00s
Epoch 140 | train_loss=0.1014 val_loss=0.0877 P=0.539 R=0.424 F1=0.475 ROC-AUC=0.986 AUPR=0.442 time=50.23s
Epoch 141 | train_loss=0.1139 val_loss=0.0857 P=0.527 R=0.438 F1=0.478 ROC-AUC=0.986 AUPR=0.458 time=48.79s
Epoch 142 | train_loss=0.1337 val_loss=0.0889 P=0.644 R=0.395 F1=0.490 ROC-AUC=0.985 AUPR=0.472 time=48.71s
Epoch 143 | train_loss=0.0922 val_loss=0.0859 P=0.565 R=0.434 F1=0.491 ROC-AUC=0.986 AUPR=0.469 time=49.68s
Epoch 144 | train_loss=0.0894 val_loss=0.0870 P=0.562 R=0.394 F1=0.463 ROC-AUC=0.985 AUPR=0.449 time=49.80s
Epoch 145 | train_loss=0.0997 val_loss=0.1016 P=0.565 R=0.412 F1=0.477 ROC-AUC=0.981 AUPR=0.442 time=49.77s
Epoch 146 | train_loss=0.1276 val_loss=0.0843 P=0.640 R=0.390 F1=0.485 ROC-AUC=0.986 AUPR=0.468 time=49.95s
Epoch 147 | train_loss=0.0825 val_loss=0.0892 P=0.552 R=0.369 F1=0.442 ROC-AUC=0.985 AUPR=0.426 time=49.80s
Epoch 148 | train_loss=0.0918 val_loss=0.0858 P=0.514 R=0.446 F1=0.478 ROC-AUC=0.986 AUPR=0.456 time=49.67s
Epoch 149 | train_loss=0.1196 val_loss=0.0850 P=0.556 R=0.443 F1=0.493 ROC-AUC=0.986 AUPR=0.469 time=49.75s
Epoch 150 | train_loss=0.1275 val_loss=0.0857 P=0.575 R=0.420 F1=0.485 ROC-AUC=0.986 AUPR=0.467 time=49.76s
Epoch 151 | train_loss=0.0852 val_loss=0.0873 P=0.578 R=0.412 F1=0.481 ROC-AUC=0.986 AUPR=0.456 time=49.50s
Epoch 152 | train_loss=0.1296 val_loss=1.0972 P=0.512 R=0.364 F1=0.425 ROC-AUC=0.845 AUPR=0.369 time=49.79s
Epoch 153 | train_loss=0.1192 val_loss=0.0865 P=0.490 R=0.476 F1=0.483 ROC-AUC=0.985 AUPR=0.464 time=49.74s
Epoch 154 | train_loss=0.0961 val_loss=0.0843 P=0.590 R=0.409 F1=0.483 ROC-AUC=0.986 AUPR=0.467 time=48.94s
Epoch 155 | train_loss=0.1354 val_loss=0.0862 P=0.557 R=0.446 F1=0.495 ROC-AUC=0.986 AUPR=0.470 time=49.74s
Epoch 156 | train_loss=0.0948 val_loss=0.0876 P=0.641 R=0.389 F1=0.484 ROC-AUC=0.985 AUPR=0.469 time=49.95s
Epoch 157 | train_loss=0.0922 val_loss=0.0847 P=0.577 R=0.394 F1=0.468 ROC-AUC=0.986 AUPR=0.456 time=49.95s
Epoch 158 | train_loss=0.0937 val_loss=0.0897 P=0.537 R=0.464 F1=0.498 ROC-AUC=0.985 AUPR=0.469 time=49.62s
Epoch 159 | train_loss=0.1216 val_loss=0.0898 P=0.577 R=0.441 F1=0.500 ROC-AUC=0.985 AUPR=0.471 time=48.83s
Epoch 160 | train_loss=0.1078 val_loss=0.0857 P=0.671 R=0.391 F1=0.494 ROC-AUC=0.986 AUPR=0.475 time=48.88s
Epoch 161 | train_loss=0.1632 val_loss=0.0834 P=0.575 R=0.435 F1=0.496 ROC-AUC=0.987 AUPR=0.473 time=49.01s
Epoch 162 | train_loss=0.1150 val_loss=0.0859 P=0.580 R=0.419 F1=0.487 ROC-AUC=0.986 AUPR=0.465 time=49.55s
Epoch 163 | train_loss=0.2354 val_loss=0.0874 P=0.613 R=0.426 F1=0.502 ROC-AUC=0.986 AUPR=0.477 time=50.14s
Epoch 164 | train_loss=0.0877 val_loss=0.0842 P=0.561 R=0.429 F1=0.486 ROC-AUC=0.986 AUPR=0.464 time=49.92s
Epoch 165 | train_loss=0.1066 val_loss=0.1894 P=0.584 R=0.405 F1=0.479 ROC-AUC=0.945 AUPR=0.436 time=49.32s
Epoch 166 | train_loss=0.1390 val_loss=0.0885 P=0.556 R=0.419 F1=0.478 ROC-AUC=0.985 AUPR=0.460 time=49.55s
Epoch 167 | train_loss=0.1204 val_loss=0.7793 P=0.612 R=0.307 F1=0.409 ROC-AUC=0.850 AUPR=0.356 time=48.66s
Epoch 168 | train_loss=0.1422 val_loss=0.0848 P=0.529 R=0.446 F1=0.484 ROC-AUC=0.986 AUPR=0.461 time=48.79s
Epoch 169 | train_loss=0.0900 val_loss=0.0916 P=0.558 R=0.434 F1=0.488 ROC-AUC=0.985 AUPR=0.464 time=48.64s
Epoch 170 | train_loss=0.1014 val_loss=0.2123 P=0.567 R=0.431 F1=0.490 ROC-AUC=0.943 AUPR=0.434 time=48.80s
Epoch 171 | train_loss=0.1011 val_loss=0.0878 P=0.538 R=0.438 F1=0.483 ROC-AUC=0.986 AUPR=0.467 time=48.73s
Epoch 172 | train_loss=0.1029 val_loss=0.0907 P=0.507 R=0.451 F1=0.477 ROC-AUC=0.985 AUPR=0.456 time=48.57s
Epoch 173 | train_loss=0.1279 val_loss=0.0857 P=0.567 R=0.452 F1=0.503 ROC-AUC=0.986 AUPR=0.474 time=48.77s
Epoch 174 | train_loss=0.1149 val_loss=0.0842 P=0.582 R=0.430 F1=0.494 ROC-AUC=0.986 AUPR=0.476 time=48.84s
Epoch 175 | train_loss=0.0974 val_loss=0.0856 P=0.604 R=0.431 F1=0.503 ROC-AUC=0.986 AUPR=0.476 time=48.94s
Epoch 176 | train_loss=0.1036 val_loss=0.0851 P=0.565 R=0.431 F1=0.488 ROC-AUC=0.986 AUPR=0.473 time=48.50s
Epoch 177 | train_loss=0.2047 val_loss=0.0856 P=0.624 R=0.409 F1=0.494 ROC-AUC=0.986 AUPR=0.474 time=48.85s
Epoch 178 | train_loss=0.1144 val_loss=0.0847 P=0.637 R=0.395 F1=0.487 ROC-AUC=0.986 AUPR=0.469 time=49.28s
Epoch 179 | train_loss=0.0895 val_loss=0.0877 P=0.533 R=0.431 F1=0.477 ROC-AUC=0.986 AUPR=0.454 time=49.76s
Epoch 180 | train_loss=0.1424 val_loss=0.0865 P=0.533 R=0.440 F1=0.482 ROC-AUC=0.986 AUPR=0.465 time=49.77s
Epoch 181 | train_loss=0.1034 val_loss=0.0879 P=0.623 R=0.403 F1=0.489 ROC-AUC=0.986 AUPR=0.470 time=49.69s
Epoch 182 | train_loss=0.1215 val_loss=0.0856 P=0.504 R=0.477 F1=0.490 ROC-AUC=0.986 AUPR=0.476 time=49.72s
Epoch 183 | train_loss=0.0974 val_loss=0.8048 P=0.502 R=0.382 F1=0.434 ROC-AUC=0.879 AUPR=0.382 time=50.38s
Epoch 184 | train_loss=0.1493 val_loss=0.0855 P=0.550 R=0.451 F1=0.495 ROC-AUC=0.986 AUPR=0.469 time=49.75s
Epoch 185 | train_loss=0.1017 val_loss=0.0863 P=0.577 R=0.429 F1=0.492 ROC-AUC=0.986 AUPR=0.473 time=50.47s
Epoch 186 | train_loss=0.1123 val_loss=0.0839 P=0.621 R=0.412 F1=0.495 ROC-AUC=0.986 AUPR=0.474 time=49.67s
Epoch 187 | train_loss=0.1865 val_loss=0.5221 P=0.507 R=0.391 F1=0.441 ROC-AUC=0.905 AUPR=0.406 time=50.29s
Epoch 188 | train_loss=0.1853 val_loss=0.0858 P=0.570 R=0.427 F1=0.488 ROC-AUC=0.986 AUPR=0.472 time=49.56s

Early stopping at epoch 188

Total training time: 9243.96s (154.1 min)

Loading best model from epoch 163...
Evaluating final model...
======================================================================
EVALUATION RESULTS: seed2025_experiment_3 TRAIN
======================================================================

STANDARD METRICS:
  Precision:        0.6465
  Recall:           0.4363
  F1-Score:         0.5210
  ROC-AUC:          0.9930
  AUPR:             0.5229
  Balanced Acc:     0.7180

IMBALANCED-AWARE METRICS:
  MCC:              0.5307
  Cohen Kappa:      0.5206
  Specificity:      0.9998

THRESHOLD: 0.975

CONFUSION MATRIX:
  True Negatives:   3043202
  False Positives:  741
  False Negatives:  1751
  True Positives:   1355

TOP-K PRECISION:
  precision_at_100: 0.9900
  precision_at_500: 0.9400
  precision_at_1000: 0.8680
======================================================================
======================================================================
EVALUATION RESULTS: seed2025_experiment_3 VAL
======================================================================

STANDARD METRICS:
  Precision:        0.6125
  Recall:           0.4257
  F1-Score:         0.5023
  ROC-AUC:          0.9857
  AUPR:             0.4768
  Balanced Acc:     0.7127

IMBALANCED-AWARE METRICS:
  MCC:              0.5102
  Cohen Kappa:      0.5019
  Specificity:      0.9997

THRESHOLD: 0.975

CONFUSION MATRIX:
  True Negatives:   1014368
  False Positives:  279
  False Negatives:  595
  True Positives:   441

TOP-K PRECISION:
  precision_at_100: 0.9600
  precision_at_500: 0.7320
  precision_at_1000: 0.4920
======================================================================
======================================================================
EVALUATION RESULTS: seed2025_experiment_3 TEST
======================================================================

STANDARD METRICS:
  Precision:        0.6185
  Recall:           0.4135
  F1-Score:         0.4957
  ROC-AUC:          0.9848
  AUPR:             0.4670
  Balanced Acc:     0.7066

IMBALANCED-AWARE METRICS:
  MCC:              0.5053
  Cohen Kappa:      0.4952
  Specificity:      0.9997

THRESHOLD: 0.975

CONFUSION MATRIX:
  True Negatives:   1014384
  False Positives:  264
  False Negatives:  607
  True Positives:   428

TOP-K PRECISION:
  precision_at_100: 0.9500
  precision_at_500: 0.7340
  precision_at_1000: 0.4930
======================================================================

Saving results...
 Saved metrics to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed2025_experiment_3\graphsage-t\metrics.json
 Saved prediction probabilities
 Saved experiment config

======================================================================
GraphSAGE-T Training Complete!
Results saved to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed2025_experiment_3\graphsage-t
======================================================================

================================================================================
Logging ended at: 2025-12-01 12:31:54.878896
================================================================================
