
================================================================================
Logging started at: 2026-02-03 04:29:12.890128
Log file: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed4_seed4_experiment\graphsage-t\seed4_seed4_experiment_20260203_042912.txt
================================================================================

[INFO] Logging to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed4_seed4_experiment\graphsage-t\seed4_seed4_experiment_20260203_042912.txt
================================================================================
EXPERIMENT CONFIG SUMMARY
================================================================================

[DATASET]
  Name:       HI-Small_Trans_RAT_medium
  Theory:     RAT
  Intensity:  medium

[MODEL]
  GraphSAGE-T
  Hidden dim: 128

[PATHS]
  Graphs:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs\HI-Small_Trans_RAT_medium
  Splits:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits\HI-Small_Trans_RAT_medium
  Results:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed4_seed4_experiment\graphsage-t
  Logs:       C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed4_seed4_experiment\graphsage-t
================================================================================

[DEVICE] cuda


======= GRAPHSAGE-T TRAINING (FP32) =======
Batch size:       8192
Eval batch size:  16384
Device:           cuda
===========================================


Starting training for 350 epochs...

Epoch 001 | train_loss=11.1844 val_loss=0.4043 P=0.002 R=0.132 F1=0.003 ROC-AUC=0.600 AUPR=0.001 time=66.89s
Epoch 002 | train_loss=0.4863 val_loss=0.3511 P=0.049 R=0.042 F1=0.045 ROC-AUC=0.721 AUPR=0.006 time=66.75s
Epoch 003 | train_loss=0.4132 val_loss=0.3597 P=0.066 R=0.078 F1=0.071 ROC-AUC=0.723 AUPR=0.015 time=66.54s
Epoch 004 | train_loss=0.3730 val_loss=0.3099 P=0.078 R=0.090 F1=0.083 ROC-AUC=0.772 AUPR=0.019 time=67.83s
Epoch 005 | train_loss=0.3675 val_loss=0.2935 P=0.064 R=0.098 F1=0.078 ROC-AUC=0.793 AUPR=0.018 time=67.56s
Epoch 006 | train_loss=0.3393 val_loss=0.2874 P=0.075 R=0.132 F1=0.096 ROC-AUC=0.801 AUPR=0.026 time=67.86s
Epoch 007 | train_loss=0.3215 val_loss=0.2711 P=0.109 R=0.103 F1=0.106 ROC-AUC=0.811 AUPR=0.029 time=67.09s
Epoch 008 | train_loss=0.3039 val_loss=0.2606 P=0.105 R=0.123 F1=0.113 ROC-AUC=0.834 AUPR=0.034 time=65.95s
Epoch 009 | train_loss=0.2798 val_loss=0.2429 P=0.100 R=0.161 F1=0.123 ROC-AUC=0.844 AUPR=0.042 time=67.67s
Epoch 010 | train_loss=0.2686 val_loss=0.2305 P=0.130 R=0.179 F1=0.151 ROC-AUC=0.858 AUPR=0.056 time=67.18s
Epoch 011 | train_loss=0.2624 val_loss=0.1313 P=0.218 R=0.275 F1=0.243 ROC-AUC=0.970 AUPR=0.142 time=66.42s
Epoch 012 | train_loss=0.1630 val_loss=0.1235 P=0.291 R=0.291 F1=0.291 ROC-AUC=0.973 AUPR=0.204 time=66.40s
Epoch 013 | train_loss=0.1821 val_loss=0.1107 P=0.328 R=0.285 F1=0.305 ROC-AUC=0.978 AUPR=0.217 time=67.37s
Epoch 014 | train_loss=0.1510 val_loss=0.1258 P=0.297 R=0.321 F1=0.309 ROC-AUC=0.958 AUPR=0.220 time=66.17s
Epoch 015 | train_loss=0.1389 val_loss=0.1033 P=0.287 R=0.336 F1=0.309 ROC-AUC=0.981 AUPR=0.227 time=66.25s
Epoch 016 | train_loss=0.1515 val_loss=0.1099 P=0.324 R=0.303 F1=0.313 ROC-AUC=0.978 AUPR=0.239 time=65.89s
Epoch 017 | train_loss=0.1565 val_loss=0.1002 P=0.282 R=0.370 F1=0.320 ROC-AUC=0.981 AUPR=0.244 time=66.79s
Epoch 018 | train_loss=0.1115 val_loss=0.0986 P=0.301 R=0.367 F1=0.331 ROC-AUC=0.982 AUPR=0.254 time=66.77s
Epoch 019 | train_loss=0.1317 val_loss=0.0986 P=0.315 R=0.324 F1=0.319 ROC-AUC=0.982 AUPR=0.248 time=65.02s
Epoch 020 | train_loss=0.1073 val_loss=0.0964 P=0.376 R=0.294 F1=0.330 ROC-AUC=0.983 AUPR=0.256 time=64.41s
Epoch 021 | train_loss=0.1219 val_loss=0.0962 P=0.361 R=0.322 F1=0.341 ROC-AUC=0.983 AUPR=0.265 time=66.27s
Epoch 022 | train_loss=0.1031 val_loss=0.0957 P=0.313 R=0.374 F1=0.341 ROC-AUC=0.983 AUPR=0.258 time=66.20s
Epoch 023 | train_loss=0.1268 val_loss=0.0957 P=0.371 R=0.325 F1=0.347 ROC-AUC=0.983 AUPR=0.279 time=66.58s
Epoch 024 | train_loss=0.1242 val_loss=0.1062 P=0.331 R=0.350 F1=0.340 ROC-AUC=0.978 AUPR=0.264 time=66.60s
Epoch 025 | train_loss=0.1569 val_loss=0.1032 P=0.336 R=0.356 F1=0.346 ROC-AUC=0.980 AUPR=0.279 time=67.08s
Epoch 026 | train_loss=0.1215 val_loss=0.1045 P=0.303 R=0.379 F1=0.337 ROC-AUC=0.981 AUPR=0.269 time=66.16s
Epoch 027 | train_loss=0.1764 val_loss=0.1547 P=0.338 R=0.360 F1=0.349 ROC-AUC=0.929 AUPR=0.277 time=66.14s
Epoch 028 | train_loss=0.1141 val_loss=0.1000 P=0.365 R=0.341 F1=0.353 ROC-AUC=0.981 AUPR=0.293 time=66.84s
Epoch 029 | train_loss=0.1099 val_loss=0.0989 P=0.376 R=0.352 F1=0.364 ROC-AUC=0.982 AUPR=0.296 time=66.11s
Epoch 030 | train_loss=0.1447 val_loss=0.0995 P=0.377 R=0.327 F1=0.350 ROC-AUC=0.982 AUPR=0.288 time=66.47s
Epoch 031 | train_loss=0.1084 val_loss=0.0979 P=0.373 R=0.330 F1=0.350 ROC-AUC=0.982 AUPR=0.292 time=67.63s
Epoch 032 | train_loss=0.1034 val_loss=0.0966 P=0.441 R=0.316 F1=0.368 ROC-AUC=0.983 AUPR=0.315 time=66.93s
Epoch 033 | train_loss=0.1597 val_loss=0.0977 P=0.392 R=0.363 F1=0.377 ROC-AUC=0.982 AUPR=0.323 time=66.70s
Epoch 034 | train_loss=0.1346 val_loss=0.0964 P=0.395 R=0.346 F1=0.369 ROC-AUC=0.982 AUPR=0.305 time=66.33s
Epoch 035 | train_loss=0.1262 val_loss=0.0952 P=0.406 R=0.352 F1=0.377 ROC-AUC=0.983 AUPR=0.329 time=66.18s
Epoch 036 | train_loss=0.1468 val_loss=0.0974 P=0.433 R=0.332 F1=0.376 ROC-AUC=0.982 AUPR=0.317 time=65.44s
Epoch 037 | train_loss=0.1337 val_loss=0.0969 P=0.395 R=0.383 F1=0.389 ROC-AUC=0.983 AUPR=0.329 time=66.85s
Epoch 038 | train_loss=0.0976 val_loss=0.0942 P=0.462 R=0.326 F1=0.383 ROC-AUC=0.983 AUPR=0.330 time=67.70s
Epoch 039 | train_loss=0.0975 val_loss=0.0931 P=0.431 R=0.353 F1=0.388 ROC-AUC=0.984 AUPR=0.334 time=66.66s
Epoch 040 | train_loss=0.1065 val_loss=0.0929 P=0.406 R=0.386 F1=0.396 ROC-AUC=0.983 AUPR=0.339 time=66.62s
Epoch 041 | train_loss=0.1199 val_loss=0.0946 P=0.422 R=0.378 F1=0.399 ROC-AUC=0.983 AUPR=0.345 time=67.03s
Epoch 042 | train_loss=0.1774 val_loss=0.0944 P=0.444 R=0.342 F1=0.386 ROC-AUC=0.983 AUPR=0.336 time=66.41s
Epoch 043 | train_loss=0.2051 val_loss=0.0933 P=0.448 R=0.347 F1=0.391 ROC-AUC=0.983 AUPR=0.345 time=63.02s
Epoch 044 | train_loss=0.0971 val_loss=0.0929 P=0.410 R=0.381 F1=0.395 ROC-AUC=0.984 AUPR=0.342 time=65.05s
Epoch 045 | train_loss=0.1083 val_loss=0.0945 P=0.389 R=0.405 F1=0.397 ROC-AUC=0.983 AUPR=0.351 time=66.15s
Epoch 046 | train_loss=0.1055 val_loss=0.0924 P=0.440 R=0.368 F1=0.401 ROC-AUC=0.984 AUPR=0.347 time=66.54s
Epoch 047 | train_loss=0.1024 val_loss=0.0939 P=0.453 R=0.366 F1=0.405 ROC-AUC=0.983 AUPR=0.355 time=67.57s
Epoch 048 | train_loss=0.1152 val_loss=0.0935 P=0.487 R=0.355 F1=0.411 ROC-AUC=0.984 AUPR=0.364 time=66.14s
Epoch 049 | train_loss=0.1002 val_loss=0.0919 P=0.482 R=0.345 F1=0.402 ROC-AUC=0.984 AUPR=0.355 time=63.92s
Epoch 050 | train_loss=0.1242 val_loss=0.1679 P=0.495 R=0.354 F1=0.413 ROC-AUC=0.943 AUPR=0.369 time=66.26s
Epoch 051 | train_loss=0.1518 val_loss=0.0932 P=0.446 R=0.366 F1=0.402 ROC-AUC=0.984 AUPR=0.357 time=66.41s
Epoch 052 | train_loss=0.0937 val_loss=0.0918 P=0.482 R=0.344 F1=0.401 ROC-AUC=0.984 AUPR=0.357 time=67.67s
Epoch 053 | train_loss=0.0990 val_loss=0.0945 P=0.422 R=0.376 F1=0.398 ROC-AUC=0.983 AUPR=0.352 time=67.70s
Epoch 054 | train_loss=0.1057 val_loss=0.0925 P=0.443 R=0.375 F1=0.406 ROC-AUC=0.984 AUPR=0.363 time=67.09s
Epoch 055 | train_loss=0.1454 val_loss=0.0955 P=0.477 R=0.349 F1=0.403 ROC-AUC=0.983 AUPR=0.362 time=66.65s
Epoch 056 | train_loss=0.0975 val_loss=0.0933 P=0.486 R=0.340 F1=0.400 ROC-AUC=0.984 AUPR=0.354 time=66.67s
Epoch 057 | train_loss=0.1150 val_loss=0.0920 P=0.423 R=0.391 F1=0.406 ROC-AUC=0.984 AUPR=0.361 time=66.53s
Epoch 058 | train_loss=0.1100 val_loss=0.0931 P=0.519 R=0.335 F1=0.407 ROC-AUC=0.984 AUPR=0.363 time=66.30s
Epoch 059 | train_loss=0.0919 val_loss=0.0915 P=0.527 R=0.336 F1=0.410 ROC-AUC=0.984 AUPR=0.374 time=67.69s
Epoch 060 | train_loss=0.1010 val_loss=0.0909 P=0.455 R=0.371 F1=0.409 ROC-AUC=0.985 AUPR=0.369 time=66.18s
Epoch 061 | train_loss=0.1126 val_loss=0.0947 P=0.413 R=0.403 F1=0.408 ROC-AUC=0.983 AUPR=0.370 time=68.08s
Epoch 062 | train_loss=0.1553 val_loss=0.0897 P=0.502 R=0.354 F1=0.415 ROC-AUC=0.985 AUPR=0.384 time=67.29s
Epoch 063 | train_loss=0.1375 val_loss=0.0926 P=0.465 R=0.375 F1=0.416 ROC-AUC=0.984 AUPR=0.374 time=66.15s
Epoch 064 | train_loss=0.0906 val_loss=0.0918 P=0.471 R=0.350 F1=0.402 ROC-AUC=0.984 AUPR=0.371 time=66.11s
Epoch 065 | train_loss=0.0894 val_loss=0.0902 P=0.436 R=0.398 F1=0.416 ROC-AUC=0.985 AUPR=0.382 time=66.46s
Epoch 066 | train_loss=0.0931 val_loss=0.0901 P=0.495 R=0.382 F1=0.431 ROC-AUC=0.984 AUPR=0.392 time=68.59s
Epoch 067 | train_loss=0.1763 val_loss=0.0906 P=0.422 R=0.416 F1=0.419 ROC-AUC=0.984 AUPR=0.383 time=66.94s
Epoch 068 | train_loss=0.0966 val_loss=0.0906 P=0.534 R=0.347 F1=0.420 ROC-AUC=0.984 AUPR=0.381 time=67.19s
Epoch 069 | train_loss=0.0859 val_loss=0.0941 P=0.537 R=0.327 F1=0.407 ROC-AUC=0.984 AUPR=0.372 time=68.13s
Epoch 070 | train_loss=0.1703 val_loss=0.0916 P=0.464 R=0.357 F1=0.404 ROC-AUC=0.984 AUPR=0.372 time=67.44s
Epoch 071 | train_loss=0.0905 val_loss=0.0907 P=0.497 R=0.360 F1=0.418 ROC-AUC=0.984 AUPR=0.385 time=66.47s
Epoch 072 | train_loss=0.0961 val_loss=0.0900 P=0.439 R=0.391 F1=0.413 ROC-AUC=0.984 AUPR=0.388 time=65.13s
Epoch 073 | train_loss=0.0924 val_loss=0.0914 P=0.519 R=0.360 F1=0.425 ROC-AUC=0.984 AUPR=0.395 time=66.25s
Epoch 074 | train_loss=0.0896 val_loss=0.0903 P=0.520 R=0.359 F1=0.425 ROC-AUC=0.984 AUPR=0.395 time=66.72s
Epoch 075 | train_loss=0.1166 val_loss=0.0915 P=0.500 R=0.362 F1=0.420 ROC-AUC=0.984 AUPR=0.389 time=66.44s
Epoch 076 | train_loss=0.1110 val_loss=0.0905 P=0.427 R=0.420 F1=0.424 ROC-AUC=0.984 AUPR=0.393 time=67.02s
Epoch 077 | train_loss=0.0975 val_loss=0.0914 P=0.470 R=0.360 F1=0.408 ROC-AUC=0.984 AUPR=0.381 time=66.91s
Epoch 078 | train_loss=0.1468 val_loss=0.0933 P=0.542 R=0.319 F1=0.401 ROC-AUC=0.983 AUPR=0.376 time=66.02s
Epoch 079 | train_loss=0.1160 val_loss=0.0920 P=0.457 R=0.379 F1=0.415 ROC-AUC=0.984 AUPR=0.383 time=65.91s
Epoch 080 | train_loss=0.1202 val_loss=0.0911 P=0.540 R=0.348 F1=0.424 ROC-AUC=0.984 AUPR=0.392 time=66.92s
Epoch 081 | train_loss=0.1692 val_loss=0.0910 P=0.441 R=0.409 F1=0.424 ROC-AUC=0.984 AUPR=0.402 time=67.12s
Epoch 082 | train_loss=0.1352 val_loss=0.0923 P=0.475 R=0.375 F1=0.419 ROC-AUC=0.984 AUPR=0.385 time=67.26s
Epoch 083 | train_loss=0.1929 val_loss=0.1005 P=0.412 R=0.370 F1=0.390 ROC-AUC=0.981 AUPR=0.358 time=67.14s
Epoch 084 | train_loss=0.1583 val_loss=0.0893 P=0.476 R=0.370 F1=0.416 ROC-AUC=0.985 AUPR=0.386 time=66.32s
Epoch 085 | train_loss=0.1253 val_loss=0.0928 P=0.479 R=0.369 F1=0.417 ROC-AUC=0.984 AUPR=0.390 time=64.56s
Epoch 086 | train_loss=0.1032 val_loss=0.0909 P=0.487 R=0.376 F1=0.425 ROC-AUC=0.985 AUPR=0.399 time=64.10s
Epoch 087 | train_loss=0.0966 val_loss=0.0905 P=0.454 R=0.415 F1=0.434 ROC-AUC=0.984 AUPR=0.398 time=67.84s
Epoch 088 | train_loss=0.1997 val_loss=0.0900 P=0.499 R=0.362 F1=0.420 ROC-AUC=0.985 AUPR=0.396 time=65.83s
Epoch 089 | train_loss=0.1379 val_loss=0.0956 P=0.554 R=0.327 F1=0.411 ROC-AUC=0.983 AUPR=0.388 time=66.63s
Epoch 090 | train_loss=0.1318 val_loss=0.0921 P=0.455 R=0.367 F1=0.406 ROC-AUC=0.984 AUPR=0.377 time=66.32s
Epoch 091 | train_loss=0.2416 val_loss=0.1376 P=0.521 R=0.353 F1=0.421 ROC-AUC=0.969 AUPR=0.388 time=66.18s
Epoch 092 | train_loss=0.1193 val_loss=0.0896 P=0.474 R=0.390 F1=0.428 ROC-AUC=0.985 AUPR=0.399 time=66.38s
Epoch 093 | train_loss=0.1163 val_loss=0.1534 P=0.516 R=0.352 F1=0.419 ROC-AUC=0.953 AUPR=0.392 time=66.59s
Epoch 094 | train_loss=0.0967 val_loss=0.0911 P=0.511 R=0.368 F1=0.428 ROC-AUC=0.984 AUPR=0.385 time=64.08s
Epoch 095 | train_loss=0.0961 val_loss=0.0893 P=0.478 R=0.397 F1=0.434 ROC-AUC=0.985 AUPR=0.406 time=65.36s
Epoch 096 | train_loss=0.1021 val_loss=0.0892 P=0.532 R=0.340 F1=0.415 ROC-AUC=0.985 AUPR=0.388 time=65.92s
Epoch 097 | train_loss=0.0965 val_loss=0.0926 P=0.474 R=0.383 F1=0.424 ROC-AUC=0.984 AUPR=0.395 time=67.26s
Epoch 098 | train_loss=0.1012 val_loss=0.0904 P=0.530 R=0.358 F1=0.427 ROC-AUC=0.985 AUPR=0.398 time=66.83s
Epoch 099 | train_loss=0.1444 val_loss=0.0951 P=0.476 R=0.377 F1=0.421 ROC-AUC=0.983 AUPR=0.392 time=66.71s
Epoch 100 | train_loss=0.1432 val_loss=0.0913 P=0.513 R=0.389 F1=0.442 ROC-AUC=0.984 AUPR=0.414 time=67.21s
Epoch 101 | train_loss=0.1190 val_loss=0.0913 P=0.525 R=0.349 F1=0.420 ROC-AUC=0.984 AUPR=0.392 time=67.38s
Epoch 102 | train_loss=0.1041 val_loss=0.0894 P=0.505 R=0.370 F1=0.427 ROC-AUC=0.984 AUPR=0.397 time=67.37s
Epoch 103 | train_loss=0.1262 val_loss=0.0906 P=0.559 R=0.348 F1=0.429 ROC-AUC=0.984 AUPR=0.400 time=66.99s
Epoch 104 | train_loss=0.1503 val_loss=0.0938 P=0.485 R=0.383 F1=0.428 ROC-AUC=0.984 AUPR=0.398 time=66.67s
Epoch 105 | train_loss=0.0918 val_loss=0.0917 P=0.479 R=0.399 F1=0.435 ROC-AUC=0.984 AUPR=0.402 time=66.13s
Epoch 106 | train_loss=0.1370 val_loss=0.0898 P=0.475 R=0.399 F1=0.434 ROC-AUC=0.985 AUPR=0.404 time=67.01s
Epoch 107 | train_loss=0.1088 val_loss=0.0920 P=0.488 R=0.375 F1=0.424 ROC-AUC=0.984 AUPR=0.393 time=65.50s
Epoch 108 | train_loss=0.0939 val_loss=0.0926 P=0.467 R=0.389 F1=0.424 ROC-AUC=0.984 AUPR=0.394 time=66.22s
Epoch 109 | train_loss=0.1311 val_loss=0.0903 P=0.533 R=0.370 F1=0.436 ROC-AUC=0.984 AUPR=0.404 time=67.22s
Epoch 110 | train_loss=0.1447 val_loss=0.0926 P=0.530 R=0.360 F1=0.429 ROC-AUC=0.984 AUPR=0.396 time=67.84s
Epoch 111 | train_loss=0.1054 val_loss=0.0975 P=0.429 R=0.418 F1=0.423 ROC-AUC=0.983 AUPR=0.394 time=66.69s
Epoch 112 | train_loss=0.1987 val_loss=0.0905 P=0.572 R=0.363 F1=0.444 ROC-AUC=0.984 AUPR=0.410 time=67.17s
Epoch 113 | train_loss=0.2002 val_loss=0.0926 P=0.518 R=0.371 F1=0.432 ROC-AUC=0.984 AUPR=0.396 time=67.57s
Epoch 114 | train_loss=0.0862 val_loss=0.0903 P=0.474 R=0.400 F1=0.434 ROC-AUC=0.984 AUPR=0.405 time=66.86s
Epoch 115 | train_loss=0.0850 val_loss=0.0917 P=0.542 R=0.352 F1=0.427 ROC-AUC=0.984 AUPR=0.399 time=67.33s
Epoch 116 | train_loss=0.0968 val_loss=0.0898 P=0.529 R=0.377 F1=0.441 ROC-AUC=0.985 AUPR=0.409 time=66.68s
Epoch 117 | train_loss=0.1214 val_loss=0.0934 P=0.510 R=0.357 F1=0.420 ROC-AUC=0.984 AUPR=0.394 time=66.51s
Epoch 118 | train_loss=0.1084 val_loss=0.0911 P=0.562 R=0.349 F1=0.431 ROC-AUC=0.984 AUPR=0.395 time=66.24s
Epoch 119 | train_loss=0.1128 val_loss=0.0929 P=0.472 R=0.398 F1=0.432 ROC-AUC=0.984 AUPR=0.400 time=66.99s
Epoch 120 | train_loss=0.1297 val_loss=0.0915 P=0.477 R=0.405 F1=0.438 ROC-AUC=0.984 AUPR=0.409 time=67.02s
Epoch 121 | train_loss=0.0945 val_loss=0.0909 P=0.550 R=0.380 F1=0.450 ROC-AUC=0.984 AUPR=0.416 time=66.88s
Epoch 122 | train_loss=0.1375 val_loss=0.0912 P=0.511 R=0.390 F1=0.442 ROC-AUC=0.984 AUPR=0.413 time=66.52s
Epoch 123 | train_loss=0.1153 val_loss=0.0905 P=0.499 R=0.374 F1=0.427 ROC-AUC=0.984 AUPR=0.394 time=66.42s
Epoch 124 | train_loss=0.1046 val_loss=0.0915 P=0.502 R=0.376 F1=0.430 ROC-AUC=0.984 AUPR=0.395 time=67.65s
Epoch 125 | train_loss=0.1034 val_loss=0.3724 P=0.599 R=0.300 F1=0.400 ROC-AUC=0.926 AUPR=0.364 time=65.93s
Epoch 126 | train_loss=0.1246 val_loss=0.0908 P=0.470 R=0.422 F1=0.445 ROC-AUC=0.985 AUPR=0.418 time=64.75s
Epoch 127 | train_loss=0.1210 val_loss=0.0879 P=0.529 R=0.394 F1=0.452 ROC-AUC=0.985 AUPR=0.425 time=67.05s
Epoch 128 | train_loss=0.1072 val_loss=0.0890 P=0.625 R=0.338 F1=0.439 ROC-AUC=0.985 AUPR=0.416 time=67.19s
Epoch 129 | train_loss=0.0862 val_loss=0.1074 P=0.500 R=0.400 F1=0.444 ROC-AUC=0.978 AUPR=0.409 time=65.34s
Epoch 130 | train_loss=0.1569 val_loss=0.0906 P=0.501 R=0.397 F1=0.443 ROC-AUC=0.985 AUPR=0.420 time=65.68s
Epoch 131 | train_loss=0.1168 val_loss=0.0881 P=0.517 R=0.414 F1=0.460 ROC-AUC=0.985 AUPR=0.442 time=67.19s
Epoch 132 | train_loss=0.1072 val_loss=0.0875 P=0.560 R=0.392 F1=0.461 ROC-AUC=0.985 AUPR=0.440 time=66.61s
Epoch 133 | train_loss=0.1185 val_loss=0.0893 P=0.498 R=0.432 F1=0.463 ROC-AUC=0.985 AUPR=0.444 time=66.87s
Epoch 134 | train_loss=0.0987 val_loss=0.0888 P=0.431 R=0.435 F1=0.433 ROC-AUC=0.985 AUPR=0.411 time=67.14s
Epoch 135 | train_loss=0.1122 val_loss=0.0884 P=0.578 R=0.378 F1=0.457 ROC-AUC=0.985 AUPR=0.434 time=64.94s
Epoch 136 | train_loss=0.1396 val_loss=0.0883 P=0.495 R=0.411 F1=0.449 ROC-AUC=0.985 AUPR=0.425 time=65.81s
Epoch 137 | train_loss=0.0850 val_loss=0.0897 P=0.586 R=0.368 F1=0.452 ROC-AUC=0.985 AUPR=0.424 time=67.88s
Epoch 138 | train_loss=0.1163 val_loss=0.0912 P=0.562 R=0.384 F1=0.456 ROC-AUC=0.985 AUPR=0.413 time=65.50s
Epoch 139 | train_loss=0.1137 val_loss=0.0912 P=0.517 R=0.426 F1=0.467 ROC-AUC=0.984 AUPR=0.438 time=67.02s
Epoch 140 | train_loss=0.1295 val_loss=0.0865 P=0.491 R=0.437 F1=0.462 ROC-AUC=0.985 AUPR=0.441 time=66.18s
Epoch 141 | train_loss=0.1048 val_loss=0.0866 P=0.578 R=0.396 F1=0.470 ROC-AUC=0.986 AUPR=0.447 time=67.18s
Epoch 142 | train_loss=0.1295 val_loss=0.0886 P=0.509 R=0.428 F1=0.465 ROC-AUC=0.985 AUPR=0.441 time=65.97s
Epoch 143 | train_loss=0.0895 val_loss=0.0881 P=0.467 R=0.435 F1=0.451 ROC-AUC=0.985 AUPR=0.432 time=65.94s
Epoch 144 | train_loss=0.1075 val_loss=0.0872 P=0.517 R=0.419 F1=0.463 ROC-AUC=0.985 AUPR=0.445 time=66.70s
Epoch 145 | train_loss=0.1356 val_loss=0.0903 P=0.530 R=0.393 F1=0.451 ROC-AUC=0.985 AUPR=0.432 time=66.95s
Epoch 146 | train_loss=0.0969 val_loss=0.0906 P=0.555 R=0.380 F1=0.451 ROC-AUC=0.985 AUPR=0.424 time=66.19s
Epoch 147 | train_loss=0.0996 val_loss=0.0892 P=0.491 R=0.424 F1=0.455 ROC-AUC=0.985 AUPR=0.433 time=66.41s
Epoch 148 | train_loss=0.0983 val_loss=0.0893 P=0.557 R=0.384 F1=0.455 ROC-AUC=0.985 AUPR=0.439 time=65.72s
Epoch 149 | train_loss=0.0840 val_loss=0.0863 P=0.528 R=0.423 F1=0.469 ROC-AUC=0.986 AUPR=0.444 time=65.13s
Epoch 150 | train_loss=0.0907 val_loss=0.0859 P=0.528 R=0.404 F1=0.458 ROC-AUC=0.986 AUPR=0.439 time=68.12s
Epoch 151 | train_loss=0.0865 val_loss=0.0874 P=0.542 R=0.422 F1=0.474 ROC-AUC=0.986 AUPR=0.454 time=66.01s
Epoch 152 | train_loss=0.1073 val_loss=0.0862 P=0.577 R=0.403 F1=0.475 ROC-AUC=0.985 AUPR=0.458 time=66.80s
Epoch 153 | train_loss=0.1031 val_loss=0.0897 P=0.492 R=0.433 F1=0.461 ROC-AUC=0.985 AUPR=0.437 time=67.06s
Epoch 154 | train_loss=0.1096 val_loss=0.0880 P=0.495 R=0.432 F1=0.462 ROC-AUC=0.986 AUPR=0.432 time=65.49s
Epoch 155 | train_loss=0.0896 val_loss=0.0874 P=0.571 R=0.401 F1=0.471 ROC-AUC=0.986 AUPR=0.445 time=66.10s
Epoch 156 | train_loss=0.0930 val_loss=0.0903 P=0.540 R=0.397 F1=0.457 ROC-AUC=0.985 AUPR=0.434 time=66.21s
Epoch 157 | train_loss=0.1324 val_loss=0.0868 P=0.570 R=0.394 F1=0.466 ROC-AUC=0.986 AUPR=0.442 time=65.61s
Epoch 158 | train_loss=0.1023 val_loss=0.0916 P=0.612 R=0.365 F1=0.457 ROC-AUC=0.985 AUPR=0.435 time=66.91s
Epoch 159 | train_loss=0.0939 val_loss=0.0857 P=0.573 R=0.411 F1=0.479 ROC-AUC=0.986 AUPR=0.460 time=65.69s
Epoch 160 | train_loss=0.1095 val_loss=0.0865 P=0.574 R=0.417 F1=0.483 ROC-AUC=0.986 AUPR=0.462 time=67.47s
Epoch 161 | train_loss=0.1088 val_loss=0.0861 P=0.606 R=0.384 F1=0.470 ROC-AUC=0.986 AUPR=0.453 time=66.71s
Epoch 162 | train_loss=0.1139 val_loss=0.0854 P=0.554 R=0.419 F1=0.477 ROC-AUC=0.986 AUPR=0.456 time=64.27s
Epoch 163 | train_loss=0.1193 val_loss=0.0882 P=0.579 R=0.402 F1=0.474 ROC-AUC=0.985 AUPR=0.460 time=66.21s
Epoch 164 | train_loss=0.0913 val_loss=0.0848 P=0.568 R=0.408 F1=0.475 ROC-AUC=0.986 AUPR=0.459 time=65.50s
Epoch 165 | train_loss=0.1151 val_loss=0.8713 P=0.571 R=0.347 F1=0.432 ROC-AUC=0.879 AUPR=0.394 time=65.62s
Epoch 166 | train_loss=0.1746 val_loss=0.0862 P=0.531 R=0.419 F1=0.468 ROC-AUC=0.986 AUPR=0.449 time=66.17s
Epoch 167 | train_loss=0.1044 val_loss=0.0881 P=0.643 R=0.389 F1=0.485 ROC-AUC=0.985 AUPR=0.458 time=67.95s
Epoch 168 | train_loss=0.0991 val_loss=0.0861 P=0.555 R=0.420 F1=0.478 ROC-AUC=0.986 AUPR=0.458 time=65.82s
Epoch 169 | train_loss=0.1327 val_loss=0.0854 P=0.550 R=0.427 F1=0.481 ROC-AUC=0.986 AUPR=0.462 time=67.75s
Epoch 170 | train_loss=0.1250 val_loss=0.3482 P=0.503 R=0.365 F1=0.423 ROC-AUC=0.913 AUPR=0.387 time=65.33s
Epoch 171 | train_loss=0.1041 val_loss=0.0873 P=0.551 R=0.414 F1=0.473 ROC-AUC=0.986 AUPR=0.447 time=63.71s
Epoch 172 | train_loss=0.0914 val_loss=0.0847 P=0.559 R=0.446 F1=0.496 ROC-AUC=0.986 AUPR=0.472 time=66.45s
Epoch 173 | train_loss=0.1244 val_loss=0.4451 P=0.503 R=0.375 F1=0.429 ROC-AUC=0.889 AUPR=0.387 time=65.17s
Epoch 174 | train_loss=0.1784 val_loss=0.0840 P=0.583 R=0.423 F1=0.490 ROC-AUC=0.986 AUPR=0.463 time=65.64s
Epoch 175 | train_loss=0.1292 val_loss=0.0938 P=0.534 R=0.416 F1=0.468 ROC-AUC=0.985 AUPR=0.436 time=65.88s
Epoch 176 | train_loss=0.1211 val_loss=0.0874 P=0.670 R=0.382 F1=0.487 ROC-AUC=0.986 AUPR=0.471 time=66.62s
Epoch 177 | train_loss=0.1050 val_loss=0.0883 P=0.545 R=0.433 F1=0.483 ROC-AUC=0.986 AUPR=0.462 time=66.91s
Epoch 178 | train_loss=0.1041 val_loss=0.0885 P=0.546 R=0.430 F1=0.481 ROC-AUC=0.986 AUPR=0.451 time=67.10s
Epoch 179 | train_loss=0.1288 val_loss=0.0873 P=0.557 R=0.436 F1=0.489 ROC-AUC=0.986 AUPR=0.464 time=65.27s
Epoch 180 | train_loss=0.1357 val_loss=0.0851 P=0.621 R=0.388 F1=0.478 ROC-AUC=0.986 AUPR=0.467 time=67.01s
Epoch 181 | train_loss=0.1185 val_loss=0.0905 P=0.521 R=0.447 F1=0.481 ROC-AUC=0.986 AUPR=0.456 time=66.57s
Epoch 182 | train_loss=0.0871 val_loss=0.0845 P=0.568 R=0.415 F1=0.480 ROC-AUC=0.986 AUPR=0.459 time=66.66s
Epoch 183 | train_loss=0.0886 val_loss=0.0860 P=0.610 R=0.423 F1=0.499 ROC-AUC=0.986 AUPR=0.479 time=68.15s
Epoch 184 | train_loss=0.0912 val_loss=0.0865 P=0.570 R=0.422 F1=0.485 ROC-AUC=0.986 AUPR=0.470 time=66.10s
Epoch 185 | train_loss=0.1109 val_loss=0.0854 P=0.540 R=0.432 F1=0.480 ROC-AUC=0.986 AUPR=0.459 time=67.04s
Epoch 186 | train_loss=0.1385 val_loss=0.0860 P=0.565 R=0.419 F1=0.481 ROC-AUC=0.986 AUPR=0.458 time=67.23s
Epoch 187 | train_loss=0.1542 val_loss=0.0882 P=0.487 R=0.478 F1=0.482 ROC-AUC=0.986 AUPR=0.456 time=66.26s
Epoch 188 | train_loss=0.1432 val_loss=0.0843 P=0.549 R=0.445 F1=0.491 ROC-AUC=0.986 AUPR=0.464 time=66.55s
Epoch 189 | train_loss=0.1080 val_loss=0.0834 P=0.588 R=0.426 F1=0.494 ROC-AUC=0.987 AUPR=0.470 time=66.12s
Epoch 190 | train_loss=0.1192 val_loss=1.0918 P=0.567 R=0.365 F1=0.444 ROC-AUC=0.858 AUPR=0.402 time=65.35s
Epoch 191 | train_loss=0.0915 val_loss=0.0890 P=0.517 R=0.431 F1=0.471 ROC-AUC=0.986 AUPR=0.444 time=66.50s
Epoch 192 | train_loss=0.1381 val_loss=0.0867 P=0.616 R=0.419 F1=0.499 ROC-AUC=0.986 AUPR=0.477 time=66.57s
Epoch 193 | train_loss=0.1063 val_loss=0.0868 P=0.539 R=0.444 F1=0.487 ROC-AUC=0.986 AUPR=0.465 time=66.89s
Epoch 194 | train_loss=0.1626 val_loss=0.3672 P=0.526 R=0.397 F1=0.452 ROC-AUC=0.912 AUPR=0.414 time=65.87s
Epoch 195 | train_loss=0.1471 val_loss=0.0889 P=0.556 R=0.423 F1=0.480 ROC-AUC=0.985 AUPR=0.454 time=66.31s
Epoch 196 | train_loss=0.1568 val_loss=0.0858 P=0.658 R=0.393 F1=0.492 ROC-AUC=0.986 AUPR=0.477 time=63.78s
Epoch 197 | train_loss=0.1260 val_loss=0.0866 P=0.581 R=0.406 F1=0.478 ROC-AUC=0.986 AUPR=0.457 time=67.04s
Epoch 198 | train_loss=0.1285 val_loss=0.0856 P=0.583 R=0.431 F1=0.496 ROC-AUC=0.986 AUPR=0.475 time=66.22s
Epoch 199 | train_loss=0.0843 val_loss=0.0851 P=0.516 R=0.439 F1=0.474 ROC-AUC=0.986 AUPR=0.460 time=66.36s
Epoch 200 | train_loss=0.1327 val_loss=0.0860 P=0.607 R=0.427 F1=0.501 ROC-AUC=0.986 AUPR=0.468 time=67.10s
Epoch 201 | train_loss=0.1013 val_loss=0.0871 P=0.598 R=0.403 F1=0.482 ROC-AUC=0.986 AUPR=0.463 time=66.23s
Epoch 202 | train_loss=0.1192 val_loss=0.0874 P=0.644 R=0.391 F1=0.486 ROC-AUC=0.986 AUPR=0.470 time=64.26s
Epoch 203 | train_loss=0.0824 val_loss=0.0847 P=0.543 R=0.449 F1=0.492 ROC-AUC=0.986 AUPR=0.476 time=65.44s
Epoch 204 | train_loss=0.1616 val_loss=0.0867 P=0.579 R=0.427 F1=0.491 ROC-AUC=0.986 AUPR=0.472 time=66.33s
Epoch 205 | train_loss=0.1432 val_loss=0.0853 P=0.549 R=0.449 F1=0.494 ROC-AUC=0.986 AUPR=0.468 time=67.20s
Epoch 206 | train_loss=0.0849 val_loss=0.0851 P=0.563 R=0.441 F1=0.495 ROC-AUC=0.986 AUPR=0.471 time=66.02s
Epoch 207 | train_loss=0.1400 val_loss=0.0847 P=0.580 R=0.425 F1=0.490 ROC-AUC=0.986 AUPR=0.471 time=66.31s
Epoch 208 | train_loss=0.1508 val_loss=0.0851 P=0.613 R=0.418 F1=0.497 ROC-AUC=0.986 AUPR=0.479 time=65.77s

Early stopping at epoch 208

Total training time: 13824.30s (230.4 min)

Loading best model from epoch 183...
Evaluating final model...
======================================================================
EVALUATION RESULTS: seed4_seed4_experiment TRAIN
======================================================================

STANDARD METRICS:
  Precision:        0.6242
  Recall:           0.4498
  F1-Score:         0.5228
  ROC-AUC:          0.9927
  AUPR:             0.5253
  Balanced Acc:     0.7247

IMBALANCED-AWARE METRICS:
  MCC:              0.5295
  Cohen Kappa:      0.5224
  Specificity:      0.9997

THRESHOLD: 0.970

CONFUSION MATRIX:
  True Negatives:   3043102
  False Positives:  841
  False Negatives:  1709
  True Positives:   1397

TOP-K PRECISION:
  precision_at_100: 1.0000
  precision_at_500: 0.9640
  precision_at_1000: 0.8640
======================================================================
======================================================================
EVALUATION RESULTS: seed4_seed4_experiment VAL
======================================================================

STANDARD METRICS:
  Precision:        0.6100
  Recall:           0.4228
  F1-Score:         0.4994
  ROC-AUC:          0.9863
  AUPR:             0.4795
  Balanced Acc:     0.7113

IMBALANCED-AWARE METRICS:
  MCC:              0.5074
  Cohen Kappa:      0.4990
  Specificity:      0.9997

THRESHOLD: 0.975

CONFUSION MATRIX:
  True Negatives:   1014367
  False Positives:  280
  False Negatives:  598
  True Positives:   438

TOP-K PRECISION:
  precision_at_100: 0.9600
  precision_at_500: 0.7180
  precision_at_1000: 0.4920
======================================================================
======================================================================
EVALUATION RESULTS: seed4_seed4_experiment TEST
======================================================================

STANDARD METRICS:
  Precision:        0.5572
  Recall:           0.4425
  F1-Score:         0.4933
  ROC-AUC:          0.9855
  AUPR:             0.4689
  Balanced Acc:     0.7211

IMBALANCED-AWARE METRICS:
  MCC:              0.4961
  Cohen Kappa:      0.4928
  Specificity:      0.9996

THRESHOLD: 0.965

CONFUSION MATRIX:
  True Negatives:   1014284
  False Positives:  364
  False Negatives:  577
  True Positives:   458

TOP-K PRECISION:
  precision_at_100: 0.9600
  precision_at_500: 0.7140
  precision_at_1000: 0.4920
======================================================================

Saving results...
 Saved metrics to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed4_seed4_experiment\graphsage-t\metrics.json
 Saved prediction probabilities
 Saved experiment config

======================================================================
GraphSAGE-T Training Complete!
Results saved to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed4_seed4_experiment\graphsage-t
======================================================================

================================================================================
Logging ended at: 2026-02-03 08:21:20.912594
================================================================================
