
================================================================================
Logging started at: 2025-12-03 04:50:40.992637
Log file: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed1_ablation_top20_features\dyrep\seed1_ablation_top20_features_20251203_045040.txt
================================================================================

[INFO] Logging to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed1_ablation_top20_features\dyrep\seed1_ablation_top20_features_20251203_045040.txt
================================================================================
EXPERIMENT CONFIG SUMMARY
================================================================================

[DATASET]
  Name:       HI-Small_Trans_RAT_medium
  Theory:     RAT
  Intensity:  medium

[MODEL]
  DyRep
  Hidden dim: 128

[PATHS]
  Graphs:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs\HI-Small_Trans_RAT_medium
  Splits:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits\HI-Small_Trans_RAT_medium
  Results:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed1_ablation_top20_features\dyrep
  Logs:       C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed1_ablation_top20_features\dyrep
================================================================================

[DEVICE] cuda

[INFO] Using default graph directory: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs_dyrep\HI-Small_Trans_RAT_medium__top20_features

======= DYREP-STYLE EVENT MODEL TRAINING (FP32) =======
Graph folder:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs_dyrep\HI-Small_Trans_RAT_medium__top20_features
Splits folder:   C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits_dyrep\HI-Small_Trans_RAT_medium
Results folder:  C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed1_ablation_top20_features\dyrep
Batch size:      8192
Eval batch size: 16384
Device:          cuda
=======================================================

Num nodes:        515,080
Num events/edges: 5,078,415
Node feat dim:    12
Edge feat dim:    20
Event types:      7

Split sizes:
  Train: 3,047,049
  Val:   1,015,683
  Test:  1,015,683

pos_weight (train) = 100.000

Starting training for up to 350 epochs...

Epoch 001 | train_loss=8.9948 val_loss=1.7788 P=0.079 R=0.101 F1=0.088 ROC-AUC=0.825 AUPR=0.041 time=21.39s
Epoch 002 | train_loss=0.9941 val_loss=0.3467 P=0.053 R=0.144 F1=0.077 ROC-AUC=0.823 AUPR=0.014 time=21.97s
Epoch 003 | train_loss=0.5567 val_loss=0.2178 P=0.040 R=0.148 F1=0.062 ROC-AUC=0.917 AUPR=0.020 time=22.01s
Epoch 004 | train_loss=0.6620 val_loss=0.2522 P=0.082 R=0.272 F1=0.126 ROC-AUC=0.902 AUPR=0.054 time=21.55s
Epoch 005 | train_loss=0.5157 val_loss=0.1562 P=0.102 R=0.248 F1=0.145 ROC-AUC=0.965 AUPR=0.079 time=21.93s
Epoch 006 | train_loss=0.3963 val_loss=0.6137 P=0.072 R=0.196 F1=0.105 ROC-AUC=0.889 AUPR=0.051 time=20.88s
Epoch 007 | train_loss=0.3679 val_loss=0.1571 P=0.090 R=0.234 F1=0.130 ROC-AUC=0.957 AUPR=0.062 time=22.08s
Epoch 008 | train_loss=0.6536 val_loss=0.1456 P=0.111 R=0.238 F1=0.152 ROC-AUC=0.966 AUPR=0.080 time=21.84s
Epoch 009 | train_loss=0.3782 val_loss=2.8319 P=0.110 R=0.236 F1=0.150 ROC-AUC=0.863 AUPR=0.076 time=20.76s
Epoch 010 | train_loss=0.4349 val_loss=0.1391 P=0.133 R=0.262 F1=0.177 ROC-AUC=0.972 AUPR=0.100 time=21.78s
Epoch 011 | train_loss=0.2746 val_loss=2.0718 P=0.157 R=0.201 F1=0.176 ROC-AUC=0.862 AUPR=0.098 time=21.43s
Epoch 012 | train_loss=0.3285 val_loss=0.3667 P=0.124 R=0.225 F1=0.160 ROC-AUC=0.910 AUPR=0.084 time=22.10s
Epoch 013 | train_loss=0.2806 val_loss=0.2776 P=0.147 R=0.226 F1=0.178 ROC-AUC=0.911 AUPR=0.107 time=21.76s
Epoch 014 | train_loss=0.3049 val_loss=0.1294 P=0.145 R=0.205 F1=0.170 ROC-AUC=0.973 AUPR=0.097 time=21.65s
Epoch 015 | train_loss=0.2340 val_loss=0.8185 P=0.009 R=0.637 F1=0.019 ROC-AUC=0.921 AUPR=0.006 time=22.55s
Epoch 016 | train_loss=0.1574 val_loss=0.1255 P=0.183 R=0.214 F1=0.197 ROC-AUC=0.975 AUPR=0.126 time=22.06s
Epoch 017 | train_loss=0.2192 val_loss=0.1256 P=0.158 R=0.235 F1=0.189 ROC-AUC=0.974 AUPR=0.105 time=21.51s
Epoch 018 | train_loss=0.3129 val_loss=0.2898 P=0.120 R=0.269 F1=0.166 ROC-AUC=0.911 AUPR=0.090 time=21.57s
Epoch 019 | train_loss=0.2224 val_loss=0.1205 P=0.199 R=0.195 F1=0.197 ROC-AUC=0.976 AUPR=0.119 time=21.97s
Epoch 020 | train_loss=0.2430 val_loss=0.1185 P=0.204 R=0.219 F1=0.211 ROC-AUC=0.976 AUPR=0.137 time=21.78s
Epoch 021 | train_loss=0.1389 val_loss=3.6885 P=0.149 R=0.242 F1=0.184 ROC-AUC=0.865 AUPR=0.105 time=21.49s
Epoch 022 | train_loss=0.1874 val_loss=0.1194 P=0.153 R=0.240 F1=0.187 ROC-AUC=0.977 AUPR=0.106 time=22.04s
Epoch 023 | train_loss=0.1750 val_loss=0.1163 P=0.174 R=0.269 F1=0.212 ROC-AUC=0.978 AUPR=0.129 time=21.96s
Epoch 024 | train_loss=0.1991 val_loss=0.1212 P=0.151 R=0.241 F1=0.186 ROC-AUC=0.976 AUPR=0.108 time=21.85s
Epoch 025 | train_loss=0.1539 val_loss=0.1256 P=0.153 R=0.231 F1=0.184 ROC-AUC=0.975 AUPR=0.104 time=21.86s
Epoch 026 | train_loss=0.2150 val_loss=0.1143 P=0.215 R=0.190 F1=0.202 ROC-AUC=0.978 AUPR=0.128 time=21.81s
Epoch 027 | train_loss=0.1638 val_loss=0.1169 P=0.164 R=0.227 F1=0.191 ROC-AUC=0.977 AUPR=0.112 time=22.04s
Epoch 028 | train_loss=0.2212 val_loss=0.1161 P=0.160 R=0.314 F1=0.212 ROC-AUC=0.977 AUPR=0.144 time=21.86s
Epoch 029 | train_loss=0.1181 val_loss=0.1189 P=0.173 R=0.213 F1=0.191 ROC-AUC=0.977 AUPR=0.112 time=21.00s
Epoch 030 | train_loss=0.1323 val_loss=0.1114 P=0.178 R=0.283 F1=0.219 ROC-AUC=0.979 AUPR=0.143 time=21.76s
Epoch 031 | train_loss=0.1444 val_loss=0.1132 P=0.192 R=0.242 F1=0.214 ROC-AUC=0.979 AUPR=0.138 time=21.64s
Epoch 032 | train_loss=0.1550 val_loss=0.1129 P=0.172 R=0.262 F1=0.208 ROC-AUC=0.979 AUPR=0.129 time=21.90s
Epoch 033 | train_loss=0.1996 val_loss=0.1106 P=0.214 R=0.282 F1=0.243 ROC-AUC=0.979 AUPR=0.171 time=22.07s
Epoch 034 | train_loss=0.1034 val_loss=0.1091 P=0.172 R=0.334 F1=0.227 ROC-AUC=0.980 AUPR=0.160 time=21.15s
Epoch 035 | train_loss=0.1328 val_loss=0.1180 P=0.205 R=0.272 F1=0.234 ROC-AUC=0.977 AUPR=0.156 time=21.82s
Epoch 036 | train_loss=0.1197 val_loss=0.1115 P=0.179 R=0.305 F1=0.225 ROC-AUC=0.979 AUPR=0.161 time=21.82s
Epoch 037 | train_loss=0.1585 val_loss=0.1123 P=0.166 R=0.311 F1=0.216 ROC-AUC=0.980 AUPR=0.135 time=21.72s
Epoch 038 | train_loss=0.0959 val_loss=0.1080 P=0.227 R=0.288 F1=0.254 ROC-AUC=0.980 AUPR=0.186 time=22.05s
Epoch 039 | train_loss=0.1295 val_loss=0.1098 P=0.192 R=0.245 F1=0.215 ROC-AUC=0.979 AUPR=0.146 time=21.48s
Epoch 040 | train_loss=0.1264 val_loss=0.1097 P=0.218 R=0.275 F1=0.243 ROC-AUC=0.979 AUPR=0.173 time=21.65s
Epoch 041 | train_loss=0.2241 val_loss=0.1124 P=0.179 R=0.272 F1=0.216 ROC-AUC=0.979 AUPR=0.138 time=22.07s
Epoch 042 | train_loss=0.1111 val_loss=0.1063 P=0.219 R=0.302 F1=0.254 ROC-AUC=0.981 AUPR=0.191 time=21.71s
Epoch 043 | train_loss=0.1413 val_loss=0.1070 P=0.247 R=0.263 F1=0.255 ROC-AUC=0.980 AUPR=0.195 time=21.22s
Epoch 044 | train_loss=0.0870 val_loss=0.1052 P=0.217 R=0.327 F1=0.261 ROC-AUC=0.980 AUPR=0.196 time=21.44s
Epoch 045 | train_loss=0.1168 val_loss=0.1128 P=0.204 R=0.284 F1=0.237 ROC-AUC=0.978 AUPR=0.169 time=21.59s
Epoch 046 | train_loss=0.0831 val_loss=0.1170 P=0.218 R=0.278 F1=0.244 ROC-AUC=0.977 AUPR=0.193 time=21.62s
Epoch 047 | train_loss=0.0982 val_loss=0.1097 P=0.283 R=0.275 F1=0.279 ROC-AUC=0.979 AUPR=0.224 time=21.69s
Epoch 048 | train_loss=0.1165 val_loss=0.1167 P=0.190 R=0.344 F1=0.245 ROC-AUC=0.978 AUPR=0.175 time=20.89s
Epoch 049 | train_loss=0.0803 val_loss=0.1135 P=0.246 R=0.273 F1=0.259 ROC-AUC=0.978 AUPR=0.212 time=21.84s
Epoch 050 | train_loss=0.1134 val_loss=0.1161 P=0.244 R=0.277 F1=0.260 ROC-AUC=0.977 AUPR=0.213 time=21.44s
Epoch 051 | train_loss=0.0928 val_loss=0.1240 P=0.195 R=0.256 F1=0.221 ROC-AUC=0.975 AUPR=0.154 time=21.87s
Epoch 052 | train_loss=0.1052 val_loss=0.1220 P=0.258 R=0.279 F1=0.268 ROC-AUC=0.977 AUPR=0.221 time=21.57s
Epoch 053 | train_loss=0.0749 val_loss=0.1124 P=0.248 R=0.257 F1=0.252 ROC-AUC=0.979 AUPR=0.192 time=21.75s
Epoch 054 | train_loss=0.2592 val_loss=0.1048 P=0.335 R=0.279 F1=0.305 ROC-AUC=0.980 AUPR=0.272 time=22.07s
Epoch 055 | train_loss=0.1437 val_loss=0.1057 P=0.301 R=0.273 F1=0.286 ROC-AUC=0.981 AUPR=0.255 time=21.28s
Epoch 056 | train_loss=0.0730 val_loss=0.1392 P=0.228 R=0.270 F1=0.247 ROC-AUC=0.974 AUPR=0.210 time=21.63s
Epoch 057 | train_loss=0.0900 val_loss=0.1024 P=0.281 R=0.352 F1=0.313 ROC-AUC=0.981 AUPR=0.286 time=22.11s
Epoch 058 | train_loss=0.1549 val_loss=0.1094 P=0.383 R=0.237 F1=0.293 ROC-AUC=0.979 AUPR=0.256 time=21.01s
Epoch 059 | train_loss=0.0696 val_loss=0.1175 P=0.276 R=0.271 F1=0.273 ROC-AUC=0.977 AUPR=0.244 time=23.78s
Epoch 060 | train_loss=0.1166 val_loss=0.1104 P=0.324 R=0.277 F1=0.299 ROC-AUC=0.979 AUPR=0.272 time=23.82s
Epoch 061 | train_loss=0.0958 val_loss=0.1094 P=0.362 R=0.257 F1=0.300 ROC-AUC=0.979 AUPR=0.262 time=24.03s
Epoch 062 | train_loss=0.0687 val_loss=0.1273 P=0.348 R=0.241 F1=0.285 ROC-AUC=0.976 AUPR=0.253 time=23.71s
Epoch 063 | train_loss=0.1019 val_loss=0.1171 P=0.349 R=0.275 F1=0.308 ROC-AUC=0.979 AUPR=0.272 time=23.74s
Epoch 064 | train_loss=0.0995 val_loss=0.1967 P=0.251 R=0.197 F1=0.221 ROC-AUC=0.959 AUPR=0.169 time=22.35s
Epoch 065 | train_loss=0.1474 val_loss=0.1212 P=0.317 R=0.306 F1=0.312 ROC-AUC=0.978 AUPR=0.272 time=23.71s
Epoch 066 | train_loss=0.1281 val_loss=0.1137 P=0.313 R=0.303 F1=0.308 ROC-AUC=0.979 AUPR=0.271 time=22.94s
Epoch 067 | train_loss=0.0835 val_loss=0.1145 P=0.353 R=0.275 F1=0.309 ROC-AUC=0.979 AUPR=0.274 time=22.74s
Epoch 068 | train_loss=0.1800 val_loss=0.1123 P=0.318 R=0.267 F1=0.290 ROC-AUC=0.979 AUPR=0.257 time=22.93s
Epoch 069 | train_loss=0.2228 val_loss=0.1500 P=0.318 R=0.256 F1=0.284 ROC-AUC=0.969 AUPR=0.234 time=21.73s
Epoch 070 | train_loss=0.0903 val_loss=0.1770 P=0.247 R=0.245 F1=0.246 ROC-AUC=0.964 AUPR=0.196 time=21.60s
Epoch 071 | train_loss=0.0703 val_loss=0.1140 P=0.386 R=0.281 F1=0.325 ROC-AUC=0.978 AUPR=0.282 time=21.92s
Epoch 072 | train_loss=0.0677 val_loss=0.1546 P=0.237 R=0.264 F1=0.250 ROC-AUC=0.968 AUPR=0.203 time=21.51s

Early stopping at epoch 72 (no val AUPR improvement for 15 epochs)

Total training time: 1587.97s (26.5 min)

Loading best model from epoch 57...
Evaluating final model on train/val/test...
======================================================================
EVALUATION RESULTS: seed1_ablation_top20_features TRAIN
======================================================================

STANDARD METRICS:
  Precision:        0.5166
  Recall:           0.4661
  F1-Score:         0.4900
  ROC-AUC:          0.9880
  AUPR:             0.4861
  Balanced Acc:     0.7329

IMBALANCED-AWARE METRICS:
  MCC:              0.4903
  Cohen Kappa:      0.4897
  Specificity:      0.9997

THRESHOLD: 0.960

CONFUSION MATRIX:
  True Negatives:   3043749
  False Positives:  1002
  False Negatives:  1227
  True Positives:   1071

TOP-K PRECISION:
  precision_at_100: 0.9600
  precision_at_500: 0.8960
  precision_at_1000: 0.7160
======================================================================
======================================================================
EVALUATION RESULTS: seed1_ablation_top20_features VAL
======================================================================

STANDARD METRICS:
  Precision:        0.2814
  Recall:           0.3521
  F1-Score:         0.3128
  ROC-AUC:          0.9813
  AUPR:             0.2858
  Balanced Acc:     0.6756

IMBALANCED-AWARE METRICS:
  MCC:              0.3140
  Cohen Kappa:      0.3120
  Specificity:      0.9990

THRESHOLD: 0.956

CONFUSION MATRIX:
  True Negatives:   1013628
  False Positives:  973
  False Negatives:  701
  True Positives:   381

TOP-K PRECISION:
  precision_at_100: 0.8600
  precision_at_500: 0.4820
  precision_at_1000: 0.3230
======================================================================
======================================================================
EVALUATION RESULTS: seed1_ablation_top20_features TEST
======================================================================

STANDARD METRICS:
  Precision:        0.3848
  Recall:           0.3756
  F1-Score:         0.3802
  ROC-AUC:          0.9846
  AUPR:             0.3508
  Balanced Acc:     0.6873

IMBALANCED-AWARE METRICS:
  MCC:              0.3791
  Cohen Kappa:      0.3791
  Specificity:      0.9989

THRESHOLD: 0.970

CONFUSION MATRIX:
  True Negatives:   1012807
  False Positives:  1079
  False Negatives:  1122
  True Positives:   675

TOP-K PRECISION:
  precision_at_100: 0.9200
  precision_at_500: 0.6720
  precision_at_1000: 0.5000
======================================================================

Saving results...
  - Saved metrics to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed1_ablation_top20_features\dyrep\metrics.json
  - Saved prediction probabilities
  - Saved experiment config

======================================================================
DyRep-style Training Complete!
Results saved to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed1_ablation_top20_features\dyrep
======================================================================

================================================================================
Logging ended at: 2025-12-03 05:18:22.324627
================================================================================
