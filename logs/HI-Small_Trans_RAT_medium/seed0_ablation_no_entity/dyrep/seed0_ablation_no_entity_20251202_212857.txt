
================================================================================
Logging started at: 2025-12-02 21:28:57.444011
Log file: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed0_ablation_no_entity\dyrep\seed0_ablation_no_entity_20251202_212857.txt
================================================================================

[INFO] Logging to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed0_ablation_no_entity\dyrep\seed0_ablation_no_entity_20251202_212857.txt
================================================================================
EXPERIMENT CONFIG SUMMARY
================================================================================

[DATASET]
  Name:       HI-Small_Trans_RAT_medium
  Theory:     RAT
  Intensity:  medium

[MODEL]
  DyRep
  Hidden dim: 128

[PATHS]
  Graphs:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs\HI-Small_Trans_RAT_medium
  Splits:     C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits\HI-Small_Trans_RAT_medium
  Results:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed0_ablation_no_entity\dyrep
  Logs:       C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\logs\HI-Small_Trans_RAT_medium\seed0_ablation_no_entity\dyrep
================================================================================

[DEVICE] cuda

[INFO] Using default graph directory: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs_dyrep\HI-Small_Trans_RAT_medium__no_entity

======= DYREP-STYLE EVENT MODEL TRAINING (FP32) =======
Graph folder:    C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\graphs_dyrep\HI-Small_Trans_RAT_medium__no_entity
Splits folder:   C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\splits_dyrep\HI-Small_Trans_RAT_medium
Results folder:  C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed0_ablation_no_entity\dyrep
Batch size:      8192
Eval batch size: 16384
Device:          cuda
=======================================================

Num nodes:        515,080
Num events/edges: 5,078,415
Node feat dim:    12
Edge feat dim:    53
Event types:      7

Split sizes:
  Train: 3,047,049
  Val:   1,015,683
  Test:  1,015,683

pos_weight (train) = 100.000

Starting training for up to 350 epochs...

Epoch 001 | train_loss=10.7629 val_loss=1.0586 P=0.033 R=0.505 F1=0.061 ROC-AUC=0.798 AUPR=0.020 time=21.25s
Epoch 002 | train_loss=0.7489 val_loss=0.2077 P=0.043 R=0.299 F1=0.075 ROC-AUC=0.921 AUPR=0.029 time=21.50s
Epoch 003 | train_loss=0.6494 val_loss=0.1741 P=0.068 R=0.274 F1=0.109 ROC-AUC=0.949 AUPR=0.051 time=21.45s
Epoch 004 | train_loss=0.7427 val_loss=0.1925 P=0.104 R=0.134 F1=0.117 ROC-AUC=0.932 AUPR=0.053 time=22.28s
Epoch 005 | train_loss=0.5635 val_loss=0.1617 P=0.106 R=0.247 F1=0.149 ROC-AUC=0.955 AUPR=0.077 time=21.20s
Epoch 006 | train_loss=0.6125 val_loss=0.1502 P=0.128 R=0.247 F1=0.169 ROC-AUC=0.960 AUPR=0.080 time=21.36s
Epoch 007 | train_loss=0.4599 val_loss=0.6243 P=0.193 R=0.201 F1=0.197 ROC-AUC=0.889 AUPR=0.126 time=21.08s
Epoch 008 | train_loss=0.4401 val_loss=0.2266 P=0.152 R=0.229 F1=0.183 ROC-AUC=0.911 AUPR=0.096 time=21.64s
Epoch 009 | train_loss=0.3508 val_loss=0.8315 P=0.115 R=0.294 F1=0.166 ROC-AUC=0.876 AUPR=0.103 time=22.10s
Epoch 010 | train_loss=0.4260 val_loss=0.1330 P=0.237 R=0.204 F1=0.219 ROC-AUC=0.973 AUPR=0.146 time=22.05s
Epoch 011 | train_loss=0.4579 val_loss=0.1327 P=0.195 R=0.201 F1=0.198 ROC-AUC=0.972 AUPR=0.130 time=21.99s
Epoch 012 | train_loss=0.2765 val_loss=0.2578 P=0.170 R=0.287 F1=0.213 ROC-AUC=0.912 AUPR=0.149 time=21.66s
Epoch 013 | train_loss=0.5320 val_loss=0.8181 P=0.008 R=0.518 F1=0.016 ROC-AUC=0.917 AUPR=0.006 time=22.91s
Epoch 014 | train_loss=0.3134 val_loss=0.1190 P=0.259 R=0.246 F1=0.252 ROC-AUC=0.977 AUPR=0.182 time=21.97s
Epoch 015 | train_loss=0.3006 val_loss=0.1135 P=0.223 R=0.294 F1=0.253 ROC-AUC=0.979 AUPR=0.184 time=21.77s
Epoch 016 | train_loss=0.3971 val_loss=0.1160 P=0.187 R=0.286 F1=0.226 ROC-AUC=0.978 AUPR=0.134 time=22.53s
Epoch 017 | train_loss=0.2629 val_loss=0.1475 P=0.211 R=0.253 F1=0.230 ROC-AUC=0.974 AUPR=0.140 time=21.55s
Epoch 018 | train_loss=0.3121 val_loss=0.1128 P=0.246 R=0.284 F1=0.264 ROC-AUC=0.980 AUPR=0.197 time=21.86s
Epoch 019 | train_loss=0.1770 val_loss=0.1112 P=0.219 R=0.283 F1=0.247 ROC-AUC=0.979 AUPR=0.167 time=21.47s
Epoch 020 | train_loss=0.2105 val_loss=7.4812 P=0.224 R=0.259 F1=0.240 ROC-AUC=0.866 AUPR=0.154 time=21.51s
Epoch 021 | train_loss=0.3142 val_loss=0.1140 P=0.276 R=0.265 F1=0.270 ROC-AUC=0.978 AUPR=0.206 time=21.79s
Epoch 022 | train_loss=0.1239 val_loss=0.1093 P=0.289 R=0.238 F1=0.261 ROC-AUC=0.981 AUPR=0.193 time=21.48s
Epoch 023 | train_loss=0.2145 val_loss=0.1092 P=0.237 R=0.262 F1=0.249 ROC-AUC=0.980 AUPR=0.185 time=21.67s
Epoch 024 | train_loss=0.2175 val_loss=0.1160 P=0.227 R=0.293 F1=0.256 ROC-AUC=0.978 AUPR=0.169 time=21.56s
Epoch 025 | train_loss=0.1815 val_loss=0.1073 P=0.293 R=0.281 F1=0.287 ROC-AUC=0.981 AUPR=0.213 time=21.57s
Epoch 026 | train_loss=0.3458 val_loss=0.1083 P=0.263 R=0.310 F1=0.284 ROC-AUC=0.980 AUPR=0.219 time=21.09s
Epoch 027 | train_loss=0.1349 val_loss=0.1054 P=0.318 R=0.261 F1=0.286 ROC-AUC=0.981 AUPR=0.213 time=21.05s
Epoch 028 | train_loss=0.1412 val_loss=0.1062 P=0.290 R=0.269 F1=0.279 ROC-AUC=0.981 AUPR=0.224 time=21.83s
Epoch 029 | train_loss=0.1250 val_loss=0.1098 P=0.356 R=0.246 F1=0.291 ROC-AUC=0.982 AUPR=0.229 time=21.86s
Epoch 030 | train_loss=0.3963 val_loss=0.1050 P=0.396 R=0.250 F1=0.307 ROC-AUC=0.981 AUPR=0.242 time=21.90s
Epoch 031 | train_loss=0.1125 val_loss=0.1165 P=0.207 R=0.306 F1=0.247 ROC-AUC=0.980 AUPR=0.194 time=21.56s
Epoch 032 | train_loss=0.1052 val_loss=0.1060 P=0.376 R=0.239 F1=0.293 ROC-AUC=0.982 AUPR=0.223 time=21.86s
Epoch 033 | train_loss=0.1498 val_loss=0.1119 P=0.276 R=0.243 F1=0.258 ROC-AUC=0.979 AUPR=0.189 time=21.87s
Epoch 034 | train_loss=0.1268 val_loss=0.1072 P=0.318 R=0.273 F1=0.294 ROC-AUC=0.982 AUPR=0.214 time=22.04s
Epoch 035 | train_loss=0.1241 val_loss=0.1042 P=0.281 R=0.350 F1=0.312 ROC-AUC=0.982 AUPR=0.258 time=21.87s
Epoch 036 | train_loss=0.1087 val_loss=0.1038 P=0.359 R=0.278 F1=0.313 ROC-AUC=0.982 AUPR=0.263 time=21.72s
Epoch 037 | train_loss=0.1188 val_loss=0.1106 P=0.286 R=0.341 F1=0.311 ROC-AUC=0.981 AUPR=0.256 time=21.67s
Epoch 038 | train_loss=0.1034 val_loss=0.1048 P=0.280 R=0.299 F1=0.289 ROC-AUC=0.982 AUPR=0.217 time=23.65s
Epoch 039 | train_loss=0.0880 val_loss=0.1164 P=0.325 R=0.229 F1=0.269 ROC-AUC=0.978 AUPR=0.201 time=31.03s
Epoch 040 | train_loss=0.1407 val_loss=0.1014 P=0.361 R=0.280 F1=0.315 ROC-AUC=0.983 AUPR=0.252 time=40.82s
Epoch 041 | train_loss=0.0858 val_loss=0.0997 P=0.304 R=0.306 F1=0.305 ROC-AUC=0.983 AUPR=0.248 time=40.23s
Epoch 042 | train_loss=0.1205 val_loss=0.1003 P=0.362 R=0.295 F1=0.325 ROC-AUC=0.983 AUPR=0.280 time=39.80s
Epoch 043 | train_loss=0.1009 val_loss=0.1047 P=0.343 R=0.297 F1=0.318 ROC-AUC=0.982 AUPR=0.263 time=36.23s
Epoch 044 | train_loss=0.1006 val_loss=0.1301 P=0.365 R=0.247 F1=0.294 ROC-AUC=0.981 AUPR=0.242 time=35.84s
Epoch 045 | train_loss=0.1024 val_loss=0.1069 P=0.357 R=0.246 F1=0.291 ROC-AUC=0.981 AUPR=0.234 time=35.19s
Epoch 046 | train_loss=0.1850 val_loss=0.1194 P=0.295 R=0.244 F1=0.267 ROC-AUC=0.977 AUPR=0.205 time=33.02s
Epoch 047 | train_loss=0.1069 val_loss=1.2808 P=0.310 R=0.287 F1=0.298 ROC-AUC=0.879 AUPR=0.249 time=33.50s
Epoch 048 | train_loss=0.0884 val_loss=0.1041 P=0.333 R=0.267 F1=0.297 ROC-AUC=0.982 AUPR=0.250 time=33.09s
Epoch 049 | train_loss=0.1796 val_loss=1.1491 P=0.306 R=0.303 F1=0.304 ROC-AUC=0.893 AUPR=0.253 time=32.84s
Epoch 050 | train_loss=0.1141 val_loss=0.1001 P=0.356 R=0.315 F1=0.334 ROC-AUC=0.983 AUPR=0.291 time=33.36s
Epoch 051 | train_loss=0.1013 val_loss=0.1025 P=0.340 R=0.335 F1=0.337 ROC-AUC=0.981 AUPR=0.291 time=32.79s
Epoch 052 | train_loss=0.0811 val_loss=0.1066 P=0.354 R=0.302 F1=0.326 ROC-AUC=0.982 AUPR=0.283 time=32.21s
Epoch 053 | train_loss=0.1116 val_loss=0.0976 P=0.315 R=0.341 F1=0.328 ROC-AUC=0.983 AUPR=0.289 time=37.74s
Epoch 054 | train_loss=0.1418 val_loss=1.4150 P=0.378 R=0.287 F1=0.326 ROC-AUC=0.888 AUPR=0.285 time=41.31s
Epoch 055 | train_loss=0.1283 val_loss=1.6444 P=0.308 R=0.313 F1=0.310 ROC-AUC=0.874 AUPR=0.259 time=41.15s
Epoch 056 | train_loss=0.0928 val_loss=0.1048 P=0.297 R=0.317 F1=0.307 ROC-AUC=0.982 AUPR=0.267 time=37.47s
Epoch 057 | train_loss=0.0969 val_loss=0.1119 P=0.339 R=0.283 F1=0.308 ROC-AUC=0.980 AUPR=0.261 time=35.90s
Epoch 058 | train_loss=0.0981 val_loss=0.0980 P=0.370 R=0.293 F1=0.327 ROC-AUC=0.983 AUPR=0.293 time=36.17s
Epoch 059 | train_loss=0.0860 val_loss=0.1099 P=0.345 R=0.304 F1=0.323 ROC-AUC=0.981 AUPR=0.290 time=34.66s
Epoch 060 | train_loss=0.1920 val_loss=0.0993 P=0.383 R=0.287 F1=0.328 ROC-AUC=0.983 AUPR=0.283 time=33.81s
Epoch 061 | train_loss=0.1534 val_loss=0.1073 P=0.457 R=0.252 F1=0.325 ROC-AUC=0.981 AUPR=0.288 time=33.73s
Epoch 062 | train_loss=0.1005 val_loss=0.1050 P=0.373 R=0.283 F1=0.322 ROC-AUC=0.982 AUPR=0.280 time=32.70s
Epoch 063 | train_loss=0.0792 val_loss=0.1094 P=0.333 R=0.258 F1=0.291 ROC-AUC=0.981 AUPR=0.251 time=33.41s
Epoch 064 | train_loss=0.1102 val_loss=0.0995 P=0.460 R=0.261 F1=0.333 ROC-AUC=0.983 AUPR=0.290 time=32.93s
Epoch 065 | train_loss=0.1135 val_loss=0.1102 P=0.378 R=0.270 F1=0.315 ROC-AUC=0.981 AUPR=0.279 time=32.36s
Epoch 066 | train_loss=0.1311 val_loss=0.0953 P=0.462 R=0.285 F1=0.352 ROC-AUC=0.984 AUPR=0.317 time=33.12s
Epoch 067 | train_loss=0.0856 val_loss=0.1206 P=0.367 R=0.245 F1=0.294 ROC-AUC=0.978 AUPR=0.240 time=40.38s
Epoch 068 | train_loss=0.0740 val_loss=0.0982 P=0.378 R=0.300 F1=0.335 ROC-AUC=0.983 AUPR=0.305 time=39.54s
Epoch 069 | train_loss=0.0874 val_loss=0.2710 P=0.381 R=0.228 F1=0.285 ROC-AUC=0.947 AUPR=0.242 time=40.10s
Epoch 070 | train_loss=0.1013 val_loss=0.1641 P=0.451 R=0.336 F1=0.385 ROC-AUC=0.970 AUPR=0.310 time=37.08s
Epoch 071 | train_loss=0.0731 val_loss=0.1107 P=0.439 R=0.233 F1=0.304 ROC-AUC=0.980 AUPR=0.266 time=37.15s
Epoch 072 | train_loss=0.0745 val_loss=0.1168 P=0.349 R=0.269 F1=0.304 ROC-AUC=0.978 AUPR=0.267 time=35.81s
Epoch 073 | train_loss=0.1134 val_loss=0.1154 P=0.413 R=0.261 F1=0.320 ROC-AUC=0.978 AUPR=0.282 time=34.18s
Epoch 074 | train_loss=0.0939 val_loss=0.1114 P=0.392 R=0.325 F1=0.355 ROC-AUC=0.980 AUPR=0.319 time=33.06s
Epoch 075 | train_loss=0.0741 val_loss=0.1114 P=0.365 R=0.336 F1=0.350 ROC-AUC=0.980 AUPR=0.319 time=33.04s
Epoch 076 | train_loss=0.0864 val_loss=0.1016 P=0.435 R=0.302 F1=0.357 ROC-AUC=0.982 AUPR=0.329 time=33.31s
Epoch 077 | train_loss=0.0658 val_loss=0.1282 P=0.345 R=0.274 F1=0.306 ROC-AUC=0.976 AUPR=0.269 time=33.35s
Epoch 078 | train_loss=0.3825 val_loss=0.1495 P=0.364 R=0.258 F1=0.302 ROC-AUC=0.973 AUPR=0.263 time=32.94s
Epoch 079 | train_loss=0.0683 val_loss=0.1225 P=0.500 R=0.250 F1=0.334 ROC-AUC=0.977 AUPR=0.304 time=23.78s
Epoch 080 | train_loss=0.0666 val_loss=0.1184 P=0.483 R=0.271 F1=0.347 ROC-AUC=0.978 AUPR=0.323 time=22.68s
Epoch 081 | train_loss=0.0667 val_loss=0.1068 P=0.394 R=0.355 F1=0.374 ROC-AUC=0.981 AUPR=0.347 time=23.15s
Epoch 082 | train_loss=0.1868 val_loss=0.1828 P=0.431 R=0.242 F1=0.310 ROC-AUC=0.964 AUPR=0.259 time=22.22s
Epoch 083 | train_loss=0.0612 val_loss=0.1094 P=0.398 R=0.326 F1=0.359 ROC-AUC=0.981 AUPR=0.327 time=22.48s
Epoch 084 | train_loss=0.0638 val_loss=0.1225 P=0.393 R=0.353 F1=0.372 ROC-AUC=0.977 AUPR=0.340 time=38.15s
Epoch 085 | train_loss=0.0908 val_loss=0.1029 P=0.505 R=0.311 F1=0.384 ROC-AUC=0.982 AUPR=0.354 time=36.99s
Epoch 086 | train_loss=0.2008 val_loss=0.1571 P=0.445 R=0.294 F1=0.354 ROC-AUC=0.969 AUPR=0.327 time=35.50s
Epoch 087 | train_loss=0.0709 val_loss=0.1539 P=0.374 R=0.305 F1=0.336 ROC-AUC=0.970 AUPR=0.293 time=37.16s
Epoch 088 | train_loss=0.1071 val_loss=0.1271 P=0.440 R=0.309 F1=0.363 ROC-AUC=0.977 AUPR=0.334 time=37.83s
Epoch 089 | train_loss=0.1480 val_loss=0.1577 P=0.456 R=0.306 F1=0.366 ROC-AUC=0.969 AUPR=0.328 time=35.57s
Epoch 090 | train_loss=0.0916 val_loss=0.1151 P=0.372 R=0.372 F1=0.372 ROC-AUC=0.978 AUPR=0.353 time=36.22s
Epoch 091 | train_loss=0.2010 val_loss=0.1080 P=0.475 R=0.325 F1=0.386 ROC-AUC=0.980 AUPR=0.360 time=36.29s
Epoch 092 | train_loss=0.0799 val_loss=0.1342 P=0.466 R=0.343 F1=0.395 ROC-AUC=0.974 AUPR=0.360 time=34.36s
Epoch 093 | train_loss=0.0741 val_loss=0.1764 P=0.412 R=0.287 F1=0.338 ROC-AUC=0.966 AUPR=0.281 time=33.49s
Epoch 094 | train_loss=0.2748 val_loss=0.1014 P=0.539 R=0.312 F1=0.396 ROC-AUC=0.982 AUPR=0.376 time=33.57s
Epoch 095 | train_loss=0.1933 val_loss=0.1248 P=0.354 R=0.325 F1=0.339 ROC-AUC=0.975 AUPR=0.313 time=37.25s
Epoch 096 | train_loss=0.0671 val_loss=0.1019 P=0.462 R=0.304 F1=0.367 ROC-AUC=0.982 AUPR=0.344 time=40.86s
Epoch 097 | train_loss=0.2151 val_loss=0.1354 P=0.548 R=0.318 F1=0.402 ROC-AUC=0.974 AUPR=0.374 time=41.39s
Epoch 098 | train_loss=0.0745 val_loss=0.1934 P=0.318 R=0.294 F1=0.305 ROC-AUC=0.961 AUPR=0.249 time=37.50s
Epoch 099 | train_loss=0.3458 val_loss=0.1428 P=0.435 R=0.277 F1=0.339 ROC-AUC=0.971 AUPR=0.299 time=36.57s
Epoch 100 | train_loss=0.1346 val_loss=0.1391 P=0.438 R=0.309 F1=0.362 ROC-AUC=0.972 AUPR=0.321 time=36.77s
Epoch 101 | train_loss=0.2133 val_loss=0.1409 P=0.339 R=0.281 F1=0.307 ROC-AUC=0.970 AUPR=0.266 time=35.64s
Epoch 102 | train_loss=0.0759 val_loss=0.1172 P=0.408 R=0.330 F1=0.365 ROC-AUC=0.977 AUPR=0.326 time=34.35s
Epoch 103 | train_loss=0.2875 val_loss=0.1900 P=0.414 R=0.241 F1=0.305 ROC-AUC=0.961 AUPR=0.252 time=35.22s
Epoch 104 | train_loss=0.0692 val_loss=0.2375 P=0.232 R=0.248 F1=0.240 ROC-AUC=0.951 AUPR=0.174 time=23.26s
Epoch 105 | train_loss=0.1593 val_loss=0.2342 P=0.455 R=0.276 F1=0.344 ROC-AUC=0.950 AUPR=0.272 time=23.43s
Epoch 106 | train_loss=0.1698 val_loss=0.1650 P=0.414 R=0.313 F1=0.357 ROC-AUC=0.967 AUPR=0.309 time=22.86s
Epoch 107 | train_loss=0.0894 val_loss=0.1244 P=0.443 R=0.314 F1=0.368 ROC-AUC=0.975 AUPR=0.332 time=22.06s
Epoch 108 | train_loss=0.0893 val_loss=0.1741 P=0.351 R=0.363 F1=0.357 ROC-AUC=0.964 AUPR=0.303 time=22.76s
Epoch 109 | train_loss=0.2913 val_loss=0.1321 P=0.428 R=0.313 F1=0.362 ROC-AUC=0.974 AUPR=0.317 time=21.80s

Early stopping at epoch 109 (no val AUPR improvement for 15 epochs)

Total training time: 3243.58s (54.1 min)

Loading best model from epoch 94...
Evaluating final model on train/val/test...
======================================================================
EVALUATION RESULTS: seed0_ablation_no_entity TRAIN
======================================================================

STANDARD METRICS:
  Precision:        0.6405
  Recall:           0.6110
  F1-Score:         0.6254
  ROC-AUC:          0.9904
  AUPR:             0.6372
  Balanced Acc:     0.8054

IMBALANCED-AWARE METRICS:
  MCC:              0.6253
  Cohen Kappa:      0.6251
  Specificity:      0.9997

THRESHOLD: 0.970

CONFUSION MATRIX:
  True Negatives:   3043963
  False Positives:  788
  False Negatives:  894
  True Positives:   1404

TOP-K PRECISION:
  precision_at_100: 1.0000
  precision_at_500: 0.9360
  precision_at_1000: 0.8320
======================================================================
======================================================================
EVALUATION RESULTS: seed0_ablation_no_entity VAL
======================================================================

STANDARD METRICS:
  Precision:        0.5391
  Recall:           0.3124
  F1-Score:         0.3956
  ROC-AUC:          0.9817
  AUPR:             0.3757
  Balanced Acc:     0.6560

IMBALANCED-AWARE METRICS:
  MCC:              0.4099
  Cohen Kappa:      0.3951
  Specificity:      0.9997

THRESHOLD: 0.970

CONFUSION MATRIX:
  True Negatives:   1014312
  False Positives:  289
  False Negatives:  744
  True Positives:   338

TOP-K PRECISION:
  precision_at_100: 0.9800
  precision_at_500: 0.6100
  precision_at_1000: 0.4050
======================================================================
======================================================================
EVALUATION RESULTS: seed0_ablation_no_entity TEST
======================================================================

STANDARD METRICS:
  Precision:        0.4975
  Recall:           0.4374
  F1-Score:         0.4655
  ROC-AUC:          0.9834
  AUPR:             0.4615
  Balanced Acc:     0.7183

IMBALANCED-AWARE METRICS:
  MCC:              0.4656
  Cohen Kappa:      0.4646
  Specificity:      0.9992

THRESHOLD: 0.941

CONFUSION MATRIX:
  True Negatives:   1013092
  False Positives:  794
  False Negatives:  1011
  True Positives:   786

TOP-K PRECISION:
  precision_at_100: 0.9600
  precision_at_500: 0.8060
  precision_at_1000: 0.6350
======================================================================

Saving results...
  - Saved metrics to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed0_ablation_no_entity\dyrep\metrics.json
  - Saved prediction probabilities
  - Saved experiment config

======================================================================
DyRep-style Training Complete!
Results saved to: C:\Users\yasmi\OneDrive\Desktop\Uni - Master's\Fall 2025\MLR 570\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\results\HI-Small_Trans_RAT_medium\seed0_ablation_no_entity\dyrep
======================================================================

================================================================================
Logging ended at: 2025-12-02 22:24:14.416403
================================================================================
