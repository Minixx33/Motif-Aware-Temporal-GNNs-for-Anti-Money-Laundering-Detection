{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39ea1d8",
   "metadata": {},
   "source": [
    "# Training a PyG Temporal Graph\n",
    "\n",
    "This notebook is for training a PyTorch Geometric Temporal (PYG-TGN/TGAT)\n",
    "\n",
    "> !NOTE\n",
    "> MUST REFERENCE THIS PAPER: https://arxiv.org/abs/2006.10637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caacdc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: c:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up 3 levels: rat → ibm_transactions_scripts → scripts → ROOT\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../../../\"))\n",
    "print(\"Root directory:\", ROOT_DIR)\n",
    "\n",
    "# Add root directory to Python path\n",
    "sys.path.append(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269041c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 23 00:10:20 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.29                 Driver Version: 581.29         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   56C    P5             27W /  159W |    1076MiB /  12282MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2372    C+G   ....0.3595.90\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            3732    C+G   ...N\\v4.2.2\\ProtonVPN.Client.exe      N/A      |\n",
      "|    0   N/A  N/A            4588    C+G   ...yApp\\MicrosoftSecurityApp.exe      N/A      |\n",
      "|    0   N/A  N/A            7004    C+G   ...AcrobatNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A            8692    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           11376    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           14664    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           15964    C+G   ...2txyewy\\CrossDeviceResume.exe      N/A      |\n",
      "|    0   N/A  N/A           17476    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17628    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           20060    C+G   ....0.3595.90\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           20512    C+G   ....0.3595.90\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           20944    C+G   ...1g1gvanyjgm\\WhatsApp.Root.exe      N/A      |\n",
      "|    0   N/A  N/A           21000    C+G   ...mba6cd70vzyy\\ArmouryCrate.exe      N/A      |\n",
      "|    0   N/A  N/A           24140    C+G   ...rvices\\BlueStacksServices.exe      N/A      |\n",
      "|    0   N/A  N/A           26456    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           28392    C+G   ...lpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A           30632    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           32612    C+G   ...64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A           34132    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           42868    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A           44364    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           51528    C+G   ...ogram Files\\Zotero\\zotero.exe      N/A      |\n",
      "|    0   N/A  N/A           57448    C+G   ....0.3595.94\\msedgewebview2.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "print(subprocess.getoutput(\"nvidia-smi\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53ddabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA version: 12.1\n",
      "Is CUDA available: True\n",
      "Device: NVIDIA GeForce RTX 4080 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7560854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_15432\\1901266164.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edge_index = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\edge_index.pt\")\n",
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_15432\\1901266164.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\x.pt\")\n",
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_15432\\1901266164.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edge_attr = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\edge_attr.pt\")\n",
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_15432\\1901266164.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  timestamps = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\timestamps.pt\")\n",
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_15432\\1901266164.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_edge = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\y_edge.pt\")\n",
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_15432\\1901266164.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_node = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\y_node.pt\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tgn.modules.memory import Memory\n",
    "from tgn.model.tgn import TGN\n",
    "\n",
    "edge_index = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\edge_index.pt\")\n",
    "x = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\x.pt\")\n",
    "edge_attr = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\edge_attr.pt\")\n",
    "timestamps = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\timestamps.pt\")\n",
    "y_edge = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\y_edge.pt\")\n",
    "y_node = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\y_node.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37857ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index: torch.Size([2, 5082345])\n",
      "x: torch.Size([515080, 27])\n",
      "edge_attr: torch.Size([5082345, 3])\n",
      "timestamps: torch.Size([5082345])\n",
      "y_edge: torch.Size([5082345])\n",
      "y_node: torch.Size([515080])\n",
      "labels distribution: tensor([5073168,    9177])\n"
     ]
    }
   ],
   "source": [
    "print(\"edge_index:\", edge_index.shape)\n",
    "print(\"x:\", x.shape)\n",
    "print(\"edge_attr:\", edge_attr.shape)\n",
    "print(\"timestamps:\", timestamps.shape)\n",
    "print(\"y_edge:\", y_edge.shape)\n",
    "print(\"y_node:\", y_node.shape)\n",
    "\n",
    "print(\"labels distribution:\", y_edge.bincount())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af1aa4",
   "metadata": {},
   "source": [
    "## Create a time-sorted view + train/val/test split\n",
    "\n",
    "TGN is temporal, so splitting must be chronological, not random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffbe3b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num edges (sorted): 5082345\n",
      "Train edges: 3557641\n",
      "Val edges: 762352\n",
      "Test edges: 762352\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Sort edges by time (important for temporal models)\n",
    "sorted_idx = torch.argsort(timestamps)\n",
    "\n",
    "edge_index_sorted = edge_index[:, sorted_idx]\n",
    "edge_attr_sorted  = edge_attr[sorted_idx]\n",
    "timestamps_sorted = timestamps[sorted_idx]\n",
    "y_edge_sorted     = y_edge[sorted_idx]\n",
    "\n",
    "num_edges = edge_index_sorted.size(1)\n",
    "print(\"Num edges (sorted):\", num_edges)\n",
    "\n",
    "# Temporal split: 70% train, 15% val, 15% test\n",
    "train_ratio = 0.7\n",
    "val_ratio   = 0.15\n",
    "\n",
    "train_end = int(train_ratio * num_edges)\n",
    "val_end   = int((train_ratio + val_ratio) * num_edges)\n",
    "\n",
    "train_slice = slice(0, train_end)\n",
    "val_slice   = slice(train_end, val_end)\n",
    "test_slice  = slice(val_end, num_edges)\n",
    "\n",
    "print(\"Train edges:\", train_end)\n",
    "print(\"Val edges:\", val_end - train_end)\n",
    "print(\"Test edges:\", num_edges - val_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f100b0",
   "metadata": {},
   "source": [
    "## Build a tiny helper “dataset” class for TGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0258a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeSequence:\n",
    "    \"\"\"\n",
    "    Thin wrapper around your sorted edge tensors.\n",
    "    This matches the typical TGN-style interface:\n",
    "      - sources\n",
    "      - destinations\n",
    "      - timestamps\n",
    "      - edge_features\n",
    "      - labels\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_index, edge_attr, timestamps, labels):\n",
    "        # edge_index: [2, E]\n",
    "        self.sources      = edge_index[0]      # [E]\n",
    "        self.destinations = edge_index[1]      # [E]\n",
    "        self.timestamps   = timestamps         # [E]\n",
    "        self.edge_features = edge_attr         # [E, D_e]\n",
    "        self.labels       = labels             # [E]\n",
    "\n",
    "        self.num_edges = self.sources.size(0)\n",
    "\n",
    "    def get_batch(self, start, end):\n",
    "        \"\"\"\n",
    "        Return a slice batch [start:end] as\n",
    "        (src, dst, t, edge_feat, labels)\n",
    "        \"\"\"\n",
    "        s = slice(start, end)\n",
    "        return (self.sources[s],\n",
    "                self.destinations[s],\n",
    "                self.timestamps[s],\n",
    "                self.edge_features[s],\n",
    "                self.labels[s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac40379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train edges: 3557641\n",
      "Val edges: 762352\n",
      "Test edges: 762352\n"
     ]
    }
   ],
   "source": [
    "train_data = EdgeSequence(\n",
    "    edge_index_sorted[:, train_slice],\n",
    "    edge_attr_sorted[train_slice],\n",
    "    timestamps_sorted[train_slice],\n",
    "    y_edge_sorted[train_slice]\n",
    ")\n",
    "\n",
    "val_data = EdgeSequence(\n",
    "    edge_index_sorted[:, val_slice],\n",
    "    edge_attr_sorted[val_slice],\n",
    "    timestamps_sorted[val_slice],\n",
    "    y_edge_sorted[val_slice]\n",
    ")\n",
    "\n",
    "test_data = EdgeSequence(\n",
    "    edge_index_sorted[:, test_slice],\n",
    "    edge_attr_sorted[test_slice],\n",
    "    timestamps_sorted[test_slice],\n",
    "    y_edge_sorted[test_slice]\n",
    ")\n",
    "\n",
    "print(\"Train edges:\", train_data.num_edges)\n",
    "print(\"Val edges:\", val_data.num_edges)\n",
    "print(\"Test edges:\", test_data.num_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69421d93",
   "metadata": {},
   "source": [
    "## Plugging into TGN implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffeba33",
   "metadata": {},
   "source": [
    "#### Creating a tiny MLP link predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696353c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * in_dim, in_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, src_emb, dst_emb):\n",
    "        x = torch.cat([src_emb, dst_emb], dim=-1)\n",
    "        return torch.sigmoid(self.mlp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea045770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Convert node & edge features to numpy for TGN\n",
    "node_features_np = x.cpu().numpy().astype(np.float32)\n",
    "edge_features_np = edge_attr_sorted.cpu().numpy().astype(np.float32)\n",
    "\n",
    "num_nodes = node_features_np.shape[0]\n",
    "num_edges = edge_features_np.shape[0]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. Build NeighborFinder (REQUIRED BY TGN)\n",
    "# ----------------------------------------------------\n",
    "from tgn.utils.neighbor_finder import NeighborFinder\n",
    "\n",
    "src_np = edge_index_sorted[0].cpu().numpy()\n",
    "dst_np = edge_index_sorted[1].cpu().numpy()\n",
    "ts_np  = timestamps_sorted.cpu().numpy()\n",
    "eid_np = np.arange(num_edges)\n",
    "\n",
    "adj_list = [[] for _ in range(num_nodes)]\n",
    "for s, d, t, eid in zip(src_np, dst_np, ts_np, eid_np):\n",
    "    adj_list[s].append((d, eid, t))\n",
    "    adj_list[d].append((s, eid, t))   # IBM is undirected temporal\n",
    "\n",
    "neighbor_finder = NeighborFinder(adj_list, uniform=True)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Create TGN model properly\n",
    "# ----------------------------------------------------\n",
    "from tgn.model.tgn import TGN\n",
    "\n",
    "tgn = TGN(\n",
    "    neighbor_finder=neighbor_finder,\n",
    "    node_features=node_features_np,\n",
    "    edge_features=edge_features_np,\n",
    "    device=device,\n",
    "    n_layers=2,\n",
    "    n_heads=2,\n",
    "    dropout=0.1,\n",
    "    use_memory=True,\n",
    "    memory_update_at_start=True,\n",
    "\n",
    "    # MUST MATCH feature dimensions\n",
    "    message_dimension=edge_features_np.shape[1],     # e.g., ~27–50\n",
    "    memory_dimension=node_features_np.shape[1],      # = 27\n",
    "\n",
    "    embedding_module_type=\"graph_attention\",\n",
    "    message_function=\"mlp\",\n",
    "    n_neighbors=20,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. Link predictor MLP\n",
    "# ----------------------------------------------------\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(emb_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, src, dst):\n",
    "        return self.mlp(torch.cat([src, dst], dim=-1)).squeeze(-1)\n",
    "\n",
    "link_predictor = LinkPredictor(emb_dim=node_features_np.shape[1]).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(list(tgn.parameters()) + list(link_predictor.parameters()), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c90a9da",
   "metadata": {},
   "source": [
    "## Building training dataset with negative sampling\n",
    "\n",
    "TGN requires training triplets:\n",
    "(source_node, positive_destination_node, negative_destination_node)\n",
    "at timestamp t\n",
    "\n",
    "This means we need to construct:\n",
    "\n",
    "- src_np — source nodes\n",
    "\n",
    "- dst_np — destination nodes\n",
    "\n",
    "- neg_dst_np — randomly sampled negative nodes\n",
    "\n",
    "- ts_np — timestamps\n",
    "\n",
    "- eid_np — edge indices\n",
    "\n",
    "- y_np — labels (1 for real edges, 0 for negative edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936a4f4",
   "metadata": {},
   "source": [
    "#### Creating training triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de39b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_edges = edge_index_sorted.shape[1]\n",
    "num_nodes = x.shape[0]\n",
    "\n",
    "# Positive edges\n",
    "src = edge_index_sorted[0].cpu().numpy()\n",
    "dst = edge_index_sorted[1].cpu().numpy()\n",
    "ts  = timestamps_sorted.cpu().numpy()\n",
    "eid = np.arange(num_edges)\n",
    "\n",
    "# Negative sampling: sample random destination nodes\n",
    "neg_dst = np.random.randint(0, num_nodes, size=num_edges)\n",
    "\n",
    "# Convert to tensors for TGN\n",
    "src_t = torch.from_numpy(src).long().to(device)\n",
    "dst_t = torch.from_numpy(dst).long().to(device)\n",
    "neg_t = torch.from_numpy(neg_dst).long().to(device)\n",
    "ts_t  = torch.from_numpy(ts).float().to(device)\n",
    "eid_t = torch.from_numpy(eid).long().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58b2c0",
   "metadata": {},
   "source": [
    "### Build a DataLoader for batching\n",
    "TGN must process interactions in temporal order, so a simple sequential batch loader works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bb55344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch_indices(batch_size, total):\n",
    "    return [(i, min(i+batch_size, total)) for i in range(0, total, batch_size)]\n",
    "\n",
    "batches = get_batch_indices(20000, num_edges)\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1921dab",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2a7471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20,000 edges for debug training\n",
      "Total batches per epoch: 20\n",
      "\n",
      "=== Epoch 1/1 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 62\u001b[0m\n\u001b[0;32m     57\u001b[0m eid_b \u001b[38;5;241m=\u001b[39m eid_debug[start:end]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Forward pass through TGN (TGN expects numpy arrays)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m pos_scores, neg_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtgn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_edge_probabilities\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdst_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneg_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mts_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43meid_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Move back to device for loss computation\u001b[39;00m\n\u001b[0;32m     71\u001b[0m pos_scores \u001b[38;5;241m=\u001b[39m pos_scores\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\tgn\\model\\tgn.py:210\u001b[0m, in \u001b[0;36mTGN.compute_edge_probabilities\u001b[1;34m(self, source_nodes, destination_nodes, negative_nodes, edge_times, edge_idxs, n_neighbors)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03mCompute probabilities for edges between sources and destination and between sources and\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03mnegatives by first computing temporal embeddings using the TGN encoder and then feeding them\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m:return: Probabilities for both the positive and negative edges\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    209\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(source_nodes)\n\u001b[1;32m--> 210\u001b[0m source_node_embedding, destination_node_embedding, negative_node_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_temporal_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m  \u001b[49m\u001b[43msource_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffinity_score(torch\u001b[38;5;241m.\u001b[39mcat([source_node_embedding, source_node_embedding], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    214\u001b[0m                             torch\u001b[38;5;241m.\u001b[39mcat([destination_node_embedding,\n\u001b[0;32m    215\u001b[0m                                        negative_node_embedding]))\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    216\u001b[0m pos_score \u001b[38;5;241m=\u001b[39m score[:n_samples]\n",
      "File \u001b[1;32mc:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\tgn\\model\\tgn.py:148\u001b[0m, in \u001b[0;36mTGN.compute_temporal_embeddings\u001b[1;34m(self, source_nodes, destination_nodes, negative_nodes, edge_times, edge_idxs, n_neighbors)\u001b[0m\n\u001b[0;32m    144\u001b[0m   time_diffs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([source_time_diffs, destination_time_diffs, negative_time_diffs],\n\u001b[0;32m    145\u001b[0m                          dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Compute the embeddings using the embedding module\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m node_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43msource_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mtimestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mtime_diffs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_diffs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m source_node_embedding \u001b[38;5;241m=\u001b[39m node_embedding[:n_samples]\n\u001b[0;32m    156\u001b[0m destination_node_embedding \u001b[38;5;241m=\u001b[39m node_embedding[n_samples: \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m n_samples]\n",
      "File \u001b[1;32mc:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\tgn\\modules\\embedding_module.py:124\u001b[0m, in \u001b[0;36mGraphEmbedding.compute_embedding\u001b[1;34m(self, memory, source_nodes, timestamps, n_layers, n_neighbors, time_diffs, use_time_proj)\u001b[0m\n\u001b[0;32m    121\u001b[0m edge_deltas_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(edge_deltas)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    123\u001b[0m neighbors \u001b[38;5;241m=\u001b[39m neighbors\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m--> 124\u001b[0m neighbor_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestamps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m effective_n_neighbors \u001b[38;5;241m=\u001b[39m n_neighbors \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    131\u001b[0m neighbor_embeddings \u001b[38;5;241m=\u001b[39m neighbor_embeddings\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(source_nodes), effective_n_neighbors, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\tgn\\modules\\embedding_module.py:110\u001b[0m, in \u001b[0;36mGraphEmbedding.compute_embedding\u001b[1;34m(self, memory, source_nodes, timestamps, n_layers, n_neighbors, time_diffs, use_time_proj)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m   source_node_conv_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_embedding(memory,\n\u001b[0;32m    105\u001b[0m                                                        source_nodes,\n\u001b[0;32m    106\u001b[0m                                                        timestamps,\n\u001b[0;32m    107\u001b[0m                                                        n_layers\u001b[38;5;241m=\u001b[39mn_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    108\u001b[0m                                                        n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors)\n\u001b[1;32m--> 110\u001b[0m   neighbors, edge_idxs, edge_times \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbor_finder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_temporal_neighbor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m   neighbors_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(neighbors)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    117\u001b[0m   edge_idxs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(edge_idxs)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\tgn\\utils\\neighbor_finder.py:37\u001b[0m, in \u001b[0;36mNeighborFinder.get_temporal_neighbor\u001b[1;34m(self, source_nodes, timestamps, n_neighbors)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m src, ts \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(source_nodes, timestamps):\n\u001b[0;32m     36\u001b[0m     neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj_list[src]\n\u001b[1;32m---> 37\u001b[0m     past_neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_before\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(past_neighbors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;66;03m# No neighbors -> return dummy 0\u001b[39;00m\n\u001b[0;32m     41\u001b[0m         out_neighbors\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m n_neighbors)\n",
      "File \u001b[1;32mc:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\tgn\\utils\\neighbor_finder.py:21\u001b[0m, in \u001b[0;36mNeighborFinder.find_before\u001b[1;34m(self, neighbors, cut_time)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_before\u001b[39m(\u001b[38;5;28mself\u001b[39m, neighbors, cut_time):\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    Returns all neighbors with timestamp < cut_time.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m neighbors \u001b[38;5;28;01mif\u001b[39;00m n[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m<\u001b[39m cut_time]\n",
      "File \u001b[1;32mc:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\tgn\\utils\\neighbor_finder.py:21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_before\u001b[39m(\u001b[38;5;28mself\u001b[39m, neighbors, cut_time):\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    Returns all neighbors with timestamp < cut_time.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m neighbors \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mn\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcut_time\u001b[49m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import torch.nn as nn\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG: much smaller subset + smaller batches for debugging\n",
    "# ============================================================\n",
    "MAX_EDGES_DEBUG = 20_000    # <-- try 20k first, then you can scale up\n",
    "BATCH_SIZE      = 1_000     # <-- smaller batch so each step is visible\n",
    "NUM_EPOCHS      = 1         # <-- start with 1 epoch just to verify it runs\n",
    "LR              = 1e-4\n",
    "\n",
    "# Slice tensors to a manageable size\n",
    "src_debug = src_t[:MAX_EDGES_DEBUG]\n",
    "dst_debug = dst_t[:MAX_EDGES_DEBUG]\n",
    "neg_debug = neg_t[:MAX_EDGES_DEBUG]\n",
    "ts_debug  = ts_t[:MAX_EDGES_DEBUG]\n",
    "eid_debug = eid_t[:MAX_EDGES_DEBUG]\n",
    "\n",
    "num_edges_debug = src_debug.size(0)\n",
    "print(f\"Using {num_edges_debug:,} edges for debug training\")\n",
    "\n",
    "# Build batches over the debug subset\n",
    "batches = [\n",
    "    (start, min(start + BATCH_SIZE, num_edges_debug))\n",
    "    for start in range(0, num_edges_debug, BATCH_SIZE)\n",
    "]\n",
    "print(f\"Total batches per epoch: {len(batches)}\")\n",
    "\n",
    "# ============================================================\n",
    "# LOSS + OPTIMIZER\n",
    "# ============================================================\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(tgn.parameters(), lr=LR)\n",
    "\n",
    "tgn.train()\n",
    "losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n=== Epoch {epoch + 1}/{NUM_EPOCHS} ===\")\n",
    "\n",
    "    # Reset memory at epoch start\n",
    "    if tgn.use_memory:\n",
    "        tgn.memory.__init_memory__()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_start = time.perf_counter()\n",
    "\n",
    "    for batch_idx, (start, end) in enumerate(batches):\n",
    "        batch_start = time.perf_counter()\n",
    "\n",
    "        # Select batch window from the *debug* tensors\n",
    "        src_b = src_debug[start:end]\n",
    "        dst_b = dst_debug[start:end]\n",
    "        neg_b = neg_debug[start:end]\n",
    "        ts_b  = ts_debug[start:end]\n",
    "        eid_b = eid_debug[start:end]\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # Forward pass through TGN (TGN expects numpy arrays)\n",
    "        # ----------------------------------------------------\n",
    "        pos_scores, neg_scores = tgn.compute_edge_probabilities(\n",
    "            src_b.cpu().numpy(),\n",
    "            dst_b.cpu().numpy(),\n",
    "            neg_b.cpu().numpy(),\n",
    "            ts_b.cpu().numpy(),\n",
    "            eid_b.cpu().numpy(),\n",
    "        )\n",
    "\n",
    "        # Move back to device for loss computation\n",
    "        pos_scores = pos_scores.to(device)\n",
    "        neg_scores = neg_scores.to(device)\n",
    "\n",
    "        # Labels\n",
    "        pos_y = torch.ones_like(pos_scores)\n",
    "        neg_y = torch.zeros_like(neg_scores)\n",
    "\n",
    "        # Combine\n",
    "        scores = torch.cat([pos_scores, neg_scores], dim=0)\n",
    "        labels = torch.cat([pos_y, neg_y], dim=0)\n",
    "\n",
    "        # Loss + backward\n",
    "        loss = criterion(scores, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        batch_time = time.perf_counter() - batch_start\n",
    "        print(\n",
    "            f\"  Batch {batch_idx + 1}/{len(batches)} \"\n",
    "            f\"[edges {start}:{end}] \"\n",
    "            f\"loss={loss.item():.4f}  \"\n",
    "            f\"time={batch_time:.3f}s\"\n",
    "        )\n",
    "\n",
    "    epoch_time = time.perf_counter() - epoch_start\n",
    "    print(f\"Epoch {epoch + 1} total loss: {epoch_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch + 1} time: {epoch_time:.2f}s\")\n",
    "\n",
    "    losses.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e80bc21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_raw_features: cuda:0\n",
      "edge_raw_features: cuda:0\n",
      "time_encoder: cuda:0\n",
      "memory.memory: cuda:0\n",
      "memory.last_update: cuda:0\n",
      "message_aggregator: cuda\n",
      "message_function device (if any): cuda:0\n",
      "embedding_module type: <class 'tgn.modules.embedding_module.GraphAttentionEmbedding'>\n"
     ]
    }
   ],
   "source": [
    "print(\"node_raw_features:\", tgn.node_raw_features.device)\n",
    "print(\"edge_raw_features:\", tgn.edge_raw_features.device)\n",
    "print(\"time_encoder:\", next(tgn.time_encoder.parameters()).device)\n",
    "\n",
    "print(\"memory.memory:\", tgn.memory.memory.device)\n",
    "print(\"memory.last_update:\", tgn.memory.last_update.device)\n",
    "\n",
    "print(\"message_aggregator:\", tgn.message_aggregator.device)\n",
    "print(\"message_function device (if any):\", \n",
    "      tgn.message_function.mlp[0].weight.device if hasattr(tgn.message_function, 'mlp') else \"N/A\")\n",
    "\n",
    "print(\"embedding_module type:\", type(tgn.embedding_module))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
