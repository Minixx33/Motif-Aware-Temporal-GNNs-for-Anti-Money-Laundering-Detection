{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39ea1d8",
   "metadata": {},
   "source": [
    "# Training a GRAPH-SAGE-T\n",
    "\n",
    "This notebook is for training a GRAPHSAGE-T GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caacdc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: c:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up 3 levels: rat → ibm_transactions_scripts → scripts → ROOT\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../../../\"))\n",
    "print(\"Root directory:\", ROOT_DIR)\n",
    "\n",
    "# Add root directory to Python path\n",
    "sys.path.append(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269041c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 24 01:03:09 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.29                 Driver Version: 581.29         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   54C    P0             29W /  159W |    1293MiB /  12282MiB |     22%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2372    C+G   ....0.3595.90\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            3732    C+G   ...N\\v4.2.2\\ProtonVPN.Client.exe      N/A      |\n",
      "|    0   N/A  N/A            4588    C+G   ...yApp\\MicrosoftSecurityApp.exe      N/A      |\n",
      "|    0   N/A  N/A            7004    C+G   ...AcrobatNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A           11376    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           14664    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           15432      C   ...3\\envs\\aml_project\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           15964    C+G   ...2txyewy\\CrossDeviceResume.exe      N/A      |\n",
      "|    0   N/A  N/A           17476    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17628    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           20060    C+G   ....0.3595.90\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           20512    C+G   ....0.3595.90\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           20944    C+G   ...1g1gvanyjgm\\WhatsApp.Root.exe      N/A      |\n",
      "|    0   N/A  N/A           21000    C+G   ...mba6cd70vzyy\\ArmouryCrate.exe      N/A      |\n",
      "|    0   N/A  N/A           21228    C+G   ....0.3595.90\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           24140    C+G   ...rvices\\BlueStacksServices.exe      N/A      |\n",
      "|    0   N/A  N/A           26456    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           28392    C+G   ...lpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A           30632    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           32612    C+G   ...64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A           34132    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           42868    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A           43660    C+G   ....0.3595.94\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           44364    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           52528    C+G   ...p\\app-3.5.4\\GitHubDesktop.exe      N/A      |\n",
      "|    0   N/A  N/A           57448    C+G   ....0.3595.94\\msedgewebview2.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "print(subprocess.getoutput(\"nvidia-smi\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53ddabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA version: 12.1\n",
      "Is CUDA available: True\n",
      "Device: NVIDIA GeForce RTX 4080 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7560854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_56252\\1901266164.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edge_index = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\edge_index.pt\")\n",
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_56252\\1901266164.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\x.pt\")\n",
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_56252\\1901266164.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edge_attr = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\edge_attr.pt\")\n",
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_56252\\1901266164.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  timestamps = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\timestamps.pt\")\n",
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_56252\\1901266164.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_edge = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\y_edge.pt\")\n",
      "C:\\Users\\yasmi\\AppData\\Local\\Temp\\ipykernel_56252\\1901266164.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_node = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\y_node.pt\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tgn.modules.memory import Memory\n",
    "from tgn.model.tgn import TGN\n",
    "\n",
    "edge_index = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\edge_index.pt\")\n",
    "x = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\x.pt\")\n",
    "edge_attr = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\edge_attr.pt\")\n",
    "timestamps = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\timestamps.pt\")\n",
    "y_edge = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\y_edge.pt\")\n",
    "y_node = torch.load(r\"C:\\Users\\yasmi\\OneDrive\\Desktop\\Uni - Master's\\Fall 2025\\MLR 570\\Motif-Aware-Temporal-GNNs-for-Anti-Money-Laundering-Detection\\ibm_transcations_datasets\\RAT\\pyg_graph_hismall\\y_node.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37857ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index: torch.Size([2, 5082345])\n",
      "x: torch.Size([515080, 27])\n",
      "edge_attr: torch.Size([5082345, 3])\n",
      "timestamps: torch.Size([5082345])\n",
      "y_edge: torch.Size([5082345])\n",
      "y_node: torch.Size([515080])\n",
      "labels distribution: tensor([5073168,    9177])\n"
     ]
    }
   ],
   "source": [
    "print(\"edge_index:\", edge_index.shape)\n",
    "print(\"x:\", x.shape)\n",
    "print(\"edge_attr:\", edge_attr.shape)\n",
    "print(\"timestamps:\", timestamps.shape)\n",
    "print(\"y_edge:\", y_edge.shape)\n",
    "print(\"y_node:\", y_node.shape)\n",
    "\n",
    "print(\"labels distribution:\", y_edge.bincount())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac8e64",
   "metadata": {},
   "source": [
    "## Subsample to 1-2M edges + stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ddef397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Total edges in full graph: 5082345\n",
      "Using 1,000,000 edges for debug subset\n",
      "Total positives: 9,177, negatives: 5,073,168\n",
      "Subset edges: 1,000,000\n",
      "  Positives in subset: 1805\n",
      "  Negatives in subset: 998195\n",
      "edge_index_sub shape: torch.Size([2, 1000000])\n",
      "timestamps_sub shape: torch.Size([1000000])\n",
      "y_edge_sub shape: torch.Size([1000000])\n",
      "Subset edges: 1000000\n",
      "Positives in subset: 1805\n",
      "Negatives in subset: 998195\n",
      "Train=699999, Val=99999, Test=200002\n",
      "  Train positives: 1263\n",
      "  Val positives:   180\n",
      "  Test positives:  362\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1. Choose how many edges you want to debug on\n",
    "#    (set to 1_000_000 or 2_000_000 as you like)\n",
    "# --------------------------------------------------------\n",
    "MAX_EDGES = 1_000_000   # change to 2_000_000 if you want\n",
    "\n",
    "E_total = edge_index.size(1)\n",
    "print(\"Total edges in full graph:\", E_total)\n",
    "\n",
    "num_keep = min(MAX_EDGES, E_total)\n",
    "print(f\"Using {num_keep:,} edges for debug subset\")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. Stratified subsampling by label (keep fraction of edges)\n",
    "# --------------------------------------------------------\n",
    "y_edge = y_edge.long()\n",
    "pos_mask = (y_edge == 1)\n",
    "neg_mask = (y_edge == 0)\n",
    "\n",
    "pos_idx_all = pos_mask.nonzero(as_tuple=True)[0]\n",
    "neg_idx_all = neg_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "num_pos = pos_idx_all.numel()\n",
    "num_neg = neg_idx_all.numel()\n",
    "\n",
    "print(f\"Total positives: {num_pos:,}, negatives: {num_neg:,}\")\n",
    "\n",
    "# keep same positive ratio in the subset\n",
    "pos_ratio = num_pos / float(E_total)\n",
    "num_pos_keep = int(pos_ratio * num_keep)\n",
    "num_neg_keep = num_keep - num_pos_keep\n",
    "\n",
    "pos_perm = pos_idx_all[torch.randperm(num_pos)]\n",
    "neg_perm = neg_idx_all[torch.randperm(num_neg)]\n",
    "\n",
    "pos_keep = pos_perm[:min(num_pos_keep, num_pos)]\n",
    "neg_keep = neg_perm[:min(num_neg_keep, num_neg)]\n",
    "\n",
    "subset_idx = torch.cat([pos_keep, neg_keep])\n",
    "subset_idx = subset_idx[torch.randperm(subset_idx.size(0))]\n",
    "\n",
    "print(f\"Subset edges: {subset_idx.numel():,}\")\n",
    "print(\"  Positives in subset:\", (y_edge[subset_idx] == 1).sum().item())\n",
    "print(\"  Negatives in subset:\", (y_edge[subset_idx] == 0).sum().item())\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. Build subset tensors\n",
    "# --------------------------------------------------------\n",
    "edge_index_sub = edge_index[:, subset_idx]\n",
    "timestamps_sub = timestamps[subset_idx]\n",
    "y_edge_sub     = y_edge[subset_idx].float()\n",
    "\n",
    "print(\"edge_index_sub shape:\", edge_index_sub.shape)\n",
    "print(\"timestamps_sub shape:\", timestamps_sub.shape)\n",
    "print(\"y_edge_sub shape:\", y_edge_sub.shape)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4. Normalize node features (important)\n",
    "# --------------------------------------------------------\n",
    "x_d = x.to(device).float()\n",
    "edge_index_d = edge_index_sub.to(device).long()\n",
    "ts_d = timestamps_sub.to(device).float()\n",
    "y_d = y_edge_sub.to(device).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    mean = x_d.mean(dim=0, keepdim=True)\n",
    "    std  = x_d.std(dim=0, keepdim=True) + 1e-6\n",
    "    x_d  = (x_d - mean) / std\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5. Stratified train/val/test split on the subset\n",
    "# --------------------------------------------------------\n",
    "num_edges = y_d.shape[0]\n",
    "print(\"Subset edges:\", num_edges)\n",
    "\n",
    "pos_idx = (y_d == 1).nonzero(as_tuple=True)[0]\n",
    "neg_idx = (y_d == 0).nonzero(as_tuple=True)[0]\n",
    "\n",
    "print(\"Positives in subset:\", pos_idx.numel())\n",
    "print(\"Negatives in subset:\", neg_idx.numel())\n",
    "\n",
    "# Split each class separately: 70% / 10% / 20%\n",
    "def stratified_split(idx_tensor):\n",
    "    n = idx_tensor.numel()\n",
    "    perm = idx_tensor[torch.randperm(n)]\n",
    "    n_train = int(0.7 * n)\n",
    "    n_val   = int(0.1 * n)\n",
    "    train = perm[:n_train]\n",
    "    val   = perm[n_train : n_train + n_val]\n",
    "    test  = perm[n_train + n_val :]\n",
    "    return train, val, test\n",
    "\n",
    "train_pos, val_pos, test_pos = stratified_split(pos_idx)\n",
    "train_neg, val_neg, test_neg = stratified_split(neg_idx)\n",
    "\n",
    "train_idx = torch.cat([train_pos, train_neg])\n",
    "val_idx   = torch.cat([val_pos,   val_neg])\n",
    "test_idx  = torch.cat([test_pos,  test_neg])\n",
    "\n",
    "# shuffle within each split\n",
    "train_idx = train_idx[torch.randperm(train_idx.size(0))]\n",
    "val_idx   = val_idx[torch.randperm(val_idx.size(0))]\n",
    "test_idx  = test_idx[torch.randperm(test_idx.size(0))]\n",
    "\n",
    "print(f\"Train={len(train_idx)}, Val={len(val_idx)}, Test={len(test_idx)}\")\n",
    "print(\"  Train positives:\", (y_d[train_idx] == 1).sum().item())\n",
    "print(\"  Val positives:  \", (y_d[val_idx]   == 1).sum().item())\n",
    "print(\"  Test positives: \", (y_d[test_idx]  == 1).sum().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8078a1",
   "metadata": {},
   "source": [
    "## GraphSAGE-T Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d8ba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\aml_project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# GraphSAGE-T  (GraphSAGE + sinusoidal time encoding)\n",
    "# ------------------------------------------------------------\n",
    "class TimeEncode(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        # Frequencies (log-spaced)\n",
    "        self.w = nn.Parameter(torch.exp(\n",
    "            torch.linspace(0, 3, dim)\n",
    "        ), requires_grad=True)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # t: shape [E] or [N]\n",
    "        t = t.unsqueeze(-1)                     # [E, 1]\n",
    "        out = torch.cat([torch.sin(t * self.w),\n",
    "                         torch.cos(t * self.w)], dim=-1)\n",
    "        return out.float()                      # [E, 2*dim]\n",
    "\n",
    "\n",
    "class GraphSageT(nn.Module):\n",
    "    def __init__(self, node_feat_dim, time_dim, hidden_dim=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        self.time_encoder = TimeEncode(time_dim)\n",
    "\n",
    "        # first layer takes node features + time features\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(\n",
    "            SAGEConv(node_feat_dim + 2*time_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(\n",
    "                SAGEConv(hidden_dim, hidden_dim)\n",
    "            )\n",
    "\n",
    "    def forward(self, x, edge_index, timestamps):\n",
    "        \"\"\"\n",
    "        x:           [N, F]\n",
    "        edge_index:  [2, E]\n",
    "        timestamps:  [E] on same device\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute time encodings per edge\n",
    "        t_enc = self.time_encoder(timestamps)        # [E, 2*time_dim]\n",
    "\n",
    "        # Scatter time encodings to nodes by averaging incoming edges\n",
    "        N = x.size(0)\n",
    "        T = torch.zeros((N, t_enc.size(1)),\n",
    "                        device=x.device)\n",
    "        dst = edge_index[1]\n",
    "\n",
    "        # accumulate encodings per node\n",
    "        T.index_add_(0, dst, t_enc)\n",
    "\n",
    "        # normalize by degree\n",
    "        deg = torch.bincount(dst, minlength=N).clamp(min=1).unsqueeze(-1)\n",
    "        T = T / deg\n",
    "\n",
    "        # concatenate: x || time\n",
    "        h = torch.cat([x, T], dim=1)\n",
    "\n",
    "        # run GraphSAGE layers\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index)\n",
    "            h = torch.relu(h)\n",
    "\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f402770",
   "metadata": {},
   "source": [
    "## Training + evaluation (full-batch per epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219f1b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Epoch 01 | train_loss=0.9363 val_loss=0.7760 P=0.002 R=0.844 F1=0.003 ROC-AUC=0.578 AUPR=0.003\n",
      "Epoch 02 | train_loss=0.7757 val_loss=0.6952 P=0.002 R=0.761 F1=0.003 ROC-AUC=0.488 AUPR=0.002\n",
      "Epoch 03 | train_loss=0.6954 val_loss=0.6501 P=0.001 R=0.533 F1=0.002 ROC-AUC=0.413 AUPR=0.002\n",
      "Epoch 04 | train_loss=0.6508 val_loss=0.6198 P=0.001 R=0.439 F1=0.002 ROC-AUC=0.385 AUPR=0.002\n",
      "Epoch 05 | train_loss=0.6207 val_loss=0.5974 P=0.001 R=0.383 F1=0.002 ROC-AUC=0.365 AUPR=0.001\n",
      "Epoch 06 | train_loss=0.5984 val_loss=0.5791 P=0.001 R=0.311 F1=0.002 ROC-AUC=0.365 AUPR=0.001\n",
      "Epoch 07 | train_loss=0.5802 val_loss=0.5634 P=0.001 R=0.278 F1=0.002 ROC-AUC=0.371 AUPR=0.001\n",
      "Epoch 08 | train_loss=0.5646 val_loss=0.5500 P=0.001 R=0.200 F1=0.002 ROC-AUC=0.371 AUPR=0.001\n",
      "Epoch 09 | train_loss=0.5513 val_loss=0.5371 P=0.001 R=0.122 F1=0.002 ROC-AUC=0.375 AUPR=0.001\n",
      "Epoch 10 | train_loss=0.5384 val_loss=0.5259 P=0.001 R=0.056 F1=0.002 ROC-AUC=0.376 AUPR=0.001\n",
      "Epoch 11 | train_loss=0.5273 val_loss=0.5152 P=0.001 R=0.028 F1=0.002 ROC-AUC=0.377 AUPR=0.001\n",
      "Epoch 12 | train_loss=0.5166 val_loss=0.5050 P=0.002 R=0.006 F1=0.003 ROC-AUC=0.376 AUPR=0.001\n",
      "Epoch 13 | train_loss=0.5064 val_loss=0.4959 P=0.000 R=0.000 F1=0.000 ROC-AUC=0.375 AUPR=0.001\n",
      "Epoch 14 | train_loss=0.4974 val_loss=0.4877 P=0.000 R=0.000 F1=0.000 ROC-AUC=0.371 AUPR=0.001\n",
      "Epoch 15 | train_loss=0.4892 val_loss=0.4787 P=0.000 R=0.000 F1=0.000 ROC-AUC=0.369 AUPR=0.001\n",
      "Epoch 16 | train_loss=0.4802 val_loss=0.4692 P=0.000 R=0.000 F1=0.000 ROC-AUC=0.377 AUPR=0.001\n",
      "Epoch 17 | train_loss=0.4707 val_loss=0.4609 P=0.000 R=0.000 F1=0.000 ROC-AUC=0.374 AUPR=0.001\n",
      "Epoch 18 | train_loss=0.4624 val_loss=0.4529 P=0.000 R=0.000 F1=0.000 ROC-AUC=0.373 AUPR=0.001\n",
      "Epoch 19 | train_loss=0.4544 val_loss=0.4443 P=0.000 R=0.000 F1=0.000 ROC-AUC=0.372 AUPR=0.001\n",
      "Epoch 20 | train_loss=0.4459 val_loss=0.4354 P=0.000 R=0.000 F1=0.000 ROC-AUC=0.374 AUPR=0.001\n",
      "\n",
      "=== FINAL TEST METRICS (subset) ===\n",
      "Test loss : 0.4360\n",
      "Precision : 0.000\n",
      "Recall    : 0.000\n",
      "F1-score  : 0.000\n",
      "ROC-AUC   : 0.394\n",
      "AUC-PR    : 0.001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1. Model + link predictor\n",
    "# --------------------------------------------------------\n",
    "hidden_dim = 64\n",
    "\n",
    "model = GraphSageT(\n",
    "    node_feat_dim=x_d.shape[1],\n",
    "    time_dim=8,        # matches your TimeEncode(dim=8) usage\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=2,\n",
    ").to(device)\n",
    "\n",
    "link_pred = nn.Sequential(\n",
    "    nn.Linear(2 * hidden_dim, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 1),\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(model.parameters()) + list(link_pred.parameters()),\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-5,\n",
    ")\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. Helper: evaluate on a given split\n",
    "# --------------------------------------------------------\n",
    "def evaluate(indices):\n",
    "    model.eval()\n",
    "    link_pred.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # full-graph forward once\n",
    "        h = model(x_d, edge_index_d, ts_d)\n",
    "\n",
    "        src = edge_index_d[0, indices]\n",
    "        dst = edge_index_d[1, indices]\n",
    "        labels = y_d[indices]\n",
    "\n",
    "        logits = link_pred(torch.cat([h[src], h[dst]], dim=-1)).squeeze(-1)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        loss = criterion(logits, labels).item()\n",
    "\n",
    "        scores = probs.cpu().numpy()\n",
    "        y_true = labels.cpu().numpy()\n",
    "\n",
    "    # 0.5 threshold for hard predictions\n",
    "    y_pred = (scores >= 0.5).astype(int)\n",
    "\n",
    "    # metrics (binary)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        roc = roc_auc_score(y_true, scores)\n",
    "    except ValueError:\n",
    "        roc = float(\"nan\")\n",
    "\n",
    "    try:\n",
    "        aupr = average_precision_score(y_true, scores)\n",
    "    except ValueError:\n",
    "        aupr = float(\"nan\")\n",
    "\n",
    "    return loss, prec, rec, f1, roc, aupr\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. Training loop (full-batch over train edges)\n",
    "# --------------------------------------------------------\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    link_pred.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward once over whole subset graph\n",
    "    h = model(x_d, edge_index_d, ts_d)\n",
    "\n",
    "    src = edge_index_d[0, train_idx]\n",
    "    dst = edge_index_d[1, train_idx]\n",
    "    labels = y_d[train_idx]\n",
    "\n",
    "    logits = link_pred(torch.cat([h[src], h[dst]], dim=-1)).squeeze(-1)\n",
    "    loss = criterion(logits, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # validation\n",
    "    val_loss, prec, rec, f1, roc, aupr = evaluate(val_idx)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"train_loss={loss.item():.4f} val_loss={val_loss:.4f} \"\n",
    "        f\"P={prec:.3f} R={rec:.3f} F1={f1:.3f} \"\n",
    "        f\"ROC-AUC={roc:.3f} AUPR={aupr:.3f}\"\n",
    "    )\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4. Final test evaluation\n",
    "# --------------------------------------------------------\n",
    "test_loss, prec_t, rec_t, f1_t, roc_t, aupr_t = evaluate(test_idx)\n",
    "\n",
    "print(\"\\n=== FINAL TEST METRICS (subset) ===\")\n",
    "print(f\"Test loss : {test_loss:.4f}\")\n",
    "print(f\"Precision : {prec_t:.3f}\")\n",
    "print(f\"Recall    : {rec_t:.3f}\")\n",
    "print(f\"F1-score  : {f1_t:.3f}\")\n",
    "print(f\"ROC-AUC   : {roc_t:.3f}\")\n",
    "print(f\"AUC-PR    : {aupr_t:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
